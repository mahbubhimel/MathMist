{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12931549,"sourceType":"datasetVersion","datasetId":8147915}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-05T02:17:01.151680Z","iopub.execute_input":"2025-09-05T02:17:01.152013Z","iopub.status.idle":"2025-09-05T02:17:01.555505Z","shell.execute_reply.started":"2025-09-05T02:17:01.151991Z","shell.execute_reply":"2025-09-05T02:17:01.554750Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!curl -fsSL https://ollama.com/install.sh | sh","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T02:17:01.556646Z","iopub.execute_input":"2025-09-05T02:17:01.556989Z","iopub.status.idle":"2025-09-05T02:17:36.042149Z","shell.execute_reply.started":"2025-09-05T02:17:01.556971Z","shell.execute_reply":"2025-09-05T02:17:36.041171Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import subprocess\nprocess = subprocess.Popen(\"ollama serve\", shell=True) #runs on a different thread\n#Download model\n!pip install ollama","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T02:17:36.043214Z","iopub.execute_input":"2025-09-05T02:17:36.043480Z","iopub.status.idle":"2025-09-05T02:17:40.403320Z","shell.execute_reply.started":"2025-09-05T02:17:36.043455Z","shell.execute_reply":"2025-09-05T02:17:40.402182Z"},"scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!ollama pull mathstral:7b","metadata":{"trusted":true,"scrolled":true,"execution":{"iopub.status.busy":"2025-09-05T02:17:40.405271Z","iopub.execute_input":"2025-09-05T02:17:40.405506Z","iopub.status.idle":"2025-09-05T02:18:21.450293Z","shell.execute_reply.started":"2025-09-05T02:17:40.405482Z","shell.execute_reply":"2025-09-05T02:18:21.449345Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import json\nimport os\nimport re\nfrom datetime import datetime\nfrom tqdm import tqdm\n\n# Replace Hugging Face with Ollama\ntry:\n    import ollama\nexcept Exception as e:\n    raise ImportError(\"The 'ollama' package is required. Install it and make sure the Ollama daemon is running.\") from e\n\n# -------------------------\n# Answer type normalization\n# -------------------------\n_CANONICAL_TYPES = {\"symbolic\", \"numerical\", \"proof\"}\n\n_ANSWER_TYPE_MAP_SIMPLE = {\n    # Proof variants\n    \"proof\": \"proof\", \"prove\": \"proof\",\n    # Numerical variants\n    \"numerical\": \"numerical\", \"numeric\": \"numerical\", \"number\": \"numerical\", \"calculation\": \"numerical\",\n    # Symbolic variants\n    \"symbolic\": \"symbolic\", \"symbol\": \"symbolic\", \"equation\": \"symbolic\", \"algebraic\": \"symbolic\",\n}\n\n\ndef normalize_answer_type(raw_label: str, question_text: str = \"\", exact_answer: str = \"\") -> str:\n    def _clean_label(lbl: str) -> str:\n        if not lbl:\n            return \"\"\n        s = lbl.strip().lower()\n        s = re.sub(r'[^0-9a-z\\s]', ' ', s)\n        s = re.sub(r'\\s+', ' ', s).strip()\n        return s\n\n    s = _clean_label(raw_label)\n\n    if s in _ANSWER_TYPE_MAP_SIMPLE:\n        return _ANSWER_TYPE_MAP_SIMPLE[s]\n\n    for k, v in _ANSWER_TYPE_MAP_SIMPLE.items():\n        if k in s:\n            return v\n\n    q = (question_text or \"\").lower()\n    a = (exact_answer or \"\").lower()\n\n    if re.search(r'prove|show that|prove that', q) or 'proof' in s:\n        return \"proof\"\n\n    if re.search(r'\\b(log|ln|logarithm)\\b', q) or re.search(r'\\blog\\b', a):\n        if re.search(r'\\d', a):\n            return \"numerical\"\n        return \"symbolic\"\n\n    if re.search(r'set|subset|\\bunion\\b|\\bintersection\\b', q):\n        return \"symbolic\"\n\n    if re.search(r'meter|m\\b|cm|kg|liter|l\\b|unit|units|km|mile', q + \" \" + a):\n        return \"numerical\"\n\n    if re.search(r'equation|solve for|solve|= x|x\\s*=', q) or re.search(r'= x|= \\d', a):\n        return \"symbolic\"\n\n    if re.search(r'trig|sin|cos|tan|geometry|triangle|circle', q):\n        if re.search(r'\\d', a):\n            return \"numerical\"\n        return \"symbolic\"\n\n    if re.search(r'\\d', q) or re.search(r'find the value|compute|calculate|evaluate', q):\n        return \"numerical\"\n\n    if re.search(r'[0-9]|\\\\frac|\\\\sqrt', a):\n        if re.search(r'\\\\frac|\\\\sqrt|\\{|\\\\', a):\n            return \"symbolic\"\n        return \"numerical\"\n\n    return \"symbolic\"\n\n\n# -------------------------\n# Simplified Answer Extractor (merged cleaning improvements)\n# -------------------------\nclass SimplifiedAnswerExtractor:\n    @staticmethod\n    def _clean_answer(answer: str) -> str:\n        if not answer:\n            return \"\"\n        # Start with a trimmed answer and normalize whitespace\n        a = answer.strip()\n        # collapse whitespace\n        a = re.sub(r'\\s+', ' ', a)\n\n        # remove outer $$ if present (multiline)\n        a = re.sub(r'^\\$\\$(.*)\\$\\$$', r'\\1', a, flags=re.DOTALL)\n        # remove surrounding single $ if the whole string is wrapped\n        a = re.sub(r'^\\$(.*)\\$$', r'\\1', a, flags=re.DOTALL)\n\n        # strip standalone leading/trailing $ characters and spaces\n        a = a.strip('$ ')\n\n        # Remove common prefixes (kept after stripping $ to catch cases like \"$Final Answer: ...$\")\n        prefixes_to_remove = [\n            r'Final Answer:\\s*',\n            r'Answer:\\s*',\n            r'The answer is\\s*',\n            r'Therefore,?\\s*',\n            r'Thus,?\\s*',\n            r'Hence,?\\s*',\n            r'So,?\\s*',\n            r'∴\\s*',\n        ]\n        for prefix in prefixes_to_remove:\n            a = re.sub(f'^{prefix}', '', a, flags=re.IGNORECASE)\n\n        # remove various boxed wrappers with optional backslashes and optional surrounding $\n        # e.g. $$\\boxed{...}$$, $\\boxed{...}$, \\boxed{...}\n        a = re.sub(r'\\$?\\s*(?:\\\\){0,3}boxed\\{([^}]*)\\}\\s*\\$?', r'\\1', a, flags=re.DOTALL | re.IGNORECASE)\n        # also ensure plain \\boxed{...} is unwrapped (redundant but safe)\n        a = re.sub(r'\\\\boxed\\{([^}]*)\\}', r'\\1', a)\n\n        # convert common LaTeX to readable forms\n        a = re.sub(r'\\\\frac\\{([^}]*)\\}\\{([^}]*)\\}', r'(\\1)/(\\2)', a)\n        a = re.sub(r'\\\\sqrt\\{([^}]*)\\}', r'√(\\1)', a)\n\n        # remove bold/italic wrappers\n        a = re.sub(r'\\*\\*([^*]+)\\*\\*', r'\\1', a)\n        a = re.sub(r'\\*([^*]+)\\*', r'\\1', a)\n\n        # collapse multiple spaces again (in case replacements introduced them)\n        a = re.sub(r'\\s+', ' ', a).strip()\n\n        # trim trailing punctuation/words\n        a = a.rstrip(' \\t\\n.,;:')\n\n        # remove trailing words like \"proved\" or \"the answer\"\n        a = re.sub(r'\\b(proved|completed|finished|the answer)\\b[.\\s]*$', '', a, flags=re.IGNORECASE).strip()\n\n        return a\n\n    @staticmethod\n    def _is_valid_answer(answer: str) -> bool:\n        if not answer:\n            return False\n        if re.match(r'^[\\W_]+$', answer):\n            return False\n        if not re.search(r'[0-9A-Za-z\\\\]', answer):\n            return False\n        if len(answer) > 1000:\n            return False\n        blacklist = [r'therefore$', r'thus$', r'hence$', r'so$', r'we get$', r'we have$']\n        for b in blacklist:\n            if re.search(b, answer.strip(), flags=re.IGNORECASE):\n                return False\n        return True\n\n    @staticmethod\n    def extract_final_answer_simple(text: str) -> str:\n        \"\"\"\n        Primary method: Extract final answer using the last lines approach,\n        with fallback to pattern-based extraction.\n        \"\"\"\n        if not text:\n            return \"\"\n        \n        # Clean the text and split into lines\n        lines = [line.strip() for line in text.strip().split('\\n') if line.strip()]\n        \n        # Strategy 1: Try last two lines combined\n        if len(lines) >= 2:\n            last_two = ' '.join(lines[-2:])\n            cleaned = SimplifiedAnswerExtractor._clean_answer(last_two)\n            if SimplifiedAnswerExtractor._is_valid_answer(cleaned):\n                return cleaned\n        \n        # Strategy 2: Try last line only\n        if lines:\n            cleaned = SimplifiedAnswerExtractor._clean_answer(lines[-1])\n            if SimplifiedAnswerExtractor._is_valid_answer(cleaned):\n                return cleaned\n        \n        # Strategy 3: Try last 3 lines if we have them (sometimes answers span multiple lines)\n        if len(lines) >= 3:\n            last_three = ' '.join(lines[-3:])\n            cleaned = SimplifiedAnswerExtractor._clean_answer(last_three)\n            if SimplifiedAnswerExtractor._is_valid_answer(cleaned) and len(cleaned) < 500:\n                return cleaned\n        \n        # Strategy 4: Fallback to pattern-based extraction\n        return SimplifiedAnswerExtractor._extract_with_patterns(text)\n\n    @staticmethod\n    def _extract_with_patterns(text: str) -> str:\n        \"\"\"\n        Pattern-based extraction as fallback method.\n        \"\"\"\n        # Check for <final> tags\n        raw_matches = re.findall(r'<final>(.*?)</final>', text, re.DOTALL | re.IGNORECASE)\n        for m in raw_matches:\n            c = SimplifiedAnswerExtractor._clean_answer(m)\n            if SimplifiedAnswerExtractor._is_valid_answer(c):\n                return c\n\n        # Try common answer patterns\n        patterns = [\n            r'\\*\\*Final Answer:\\*\\*\\s*(.+?)(?:\\n|$)',\n            r'Final Answer:\\s*(.+?)(?:\\n|$)',\n            r'Therefore[,:\\s]*(.+?)(?:\\.|$|\\n)',\n            r'Hence[,:\\s]*(.+?)(?:\\.|$|\\n)',\n            r'Thus[,:\\s]*(.+?)(?:\\.|$|\\n)',\n            r'Answer[:\\s]*(.+?)(?:\\n|$)',\n            r'∴\\s*(.+?)(?:\\.|$|\\n)',\n        ]\n        \n        for pat in patterns:\n            matches = re.findall(pat, text, re.MULTILINE | re.DOTALL | re.IGNORECASE)\n            if matches:\n                answer = matches[-1].strip()\n                cleaned = SimplifiedAnswerExtractor._clean_answer(answer)\n                if SimplifiedAnswerExtractor._is_valid_answer(cleaned):\n                    return cleaned\n\n        # Try boxed math expressions\n        boxed_patterns = [\n            r'\\$\\$\\s*(?:\\\\){0,3}boxed\\{(.+?)\\}\\s*\\$\\$',\n            r'\\$\\s*(?:\\\\){0,3}boxed\\{(.+?)\\}\\s*\\$',\n            r'(?:\\\\){0,3}boxed\\{(.+?)\\}',\n        ]\n        \n        for pat in boxed_patterns:\n            m = re.search(pat, text, re.DOTALL | re.IGNORECASE)\n            if m:\n                cand = SimplifiedAnswerExtractor._clean_answer(m.group(1))\n                if SimplifiedAnswerExtractor._is_valid_answer(cand):\n                    return cand\n        \n        return \"\"\n\n    @staticmethod\n    def extract_all_final_answers(generated_solution: str) -> list:\n        \"\"\"\n        Extract multiple final answers using simplified approach.\n        Returns a list (possibly empty) of cleaned answers found inside all <final>...</final> tags.\n        Falls back to the single simplified extraction if no tags are found.\n        \"\"\"\n        if not generated_solution:\n            return []\n\n        # Find all <final>...</final> (non-greedy)\n        raw_matches = re.findall(r'<final>(.*?)</final>', generated_solution, re.DOTALL | re.IGNORECASE)\n        cleaned = []\n        for m in raw_matches:\n            c = SimplifiedAnswerExtractor._clean_answer(m)\n            if SimplifiedAnswerExtractor._is_valid_answer(c):\n                cleaned.append(c)\n\n        if cleaned:\n            return cleaned\n\n        # Fallback: try to extract a single final using the simpler logic\n        simple_answer = SimplifiedAnswerExtractor.extract_final_answer_simple(generated_solution)\n        if simple_answer:\n            return [simple_answer]\n\n        return []\n\n\n# -------------------------\n# Adapter / compatibility layer\n# So existing code that expects methods like extract_final_answer and extract_all_final_answers\n# can use the simplified extractor transparently.\n# -------------------------\nclass AnswerExtractor(SimplifiedAnswerExtractor):\n    @staticmethod\n    def extract_final_answer(text: str) -> str:\n        return SimplifiedAnswerExtractor.extract_final_answer_simple(text)\n\n    @staticmethod\n    def extract_all_final_answers(text: str) -> list:\n        return SimplifiedAnswerExtractor.extract_all_final_answers(text)\n\n\n# -------------------------\n# Ollama-based English Math Solver (no temperature/max_tokens passed)\n# -------------------------\nclass OllamaMathSolver:\n    \"\"\"\n    Math solver that uses the Ollama daemon via the Python client.\n    It mirrors the previous EnglishMathSolver API but delegates generation to ollama.Client.chat.\n    \"\"\"\n\n    def __init__(self, model_name=\"mathstral:7b\"):\n        \"\"\"\n        model_name: the Ollama model reference (e.g., \"mathstral:7b\")\n        \"\"\"\n        self.model_name = model_name\n        self.client = self._load_client()\n\n    def _load_client(self):\n        \"\"\"\n        Initialize Ollama client.\n        (The ollama.Client() usually connects to the local Ollama daemon.)\n        \"\"\"\n        print(f\"Initializing Ollama client for model: {self.model_name}\")\n        client = ollama.Client()\n        return client\n\n    def cleanup(self):\n        # nothing special required for Ollama client; remove references\n        if hasattr(self, 'client'):\n            del self.client\n\n    def _get_format_instructions(self, answer_type):\n        \"\"\"\n        Keep the same formatting instruction generator as before.\n        \"\"\"\n        t = (answer_type or \"symbolic\").strip().lower()\n        if t not in _CANONICAL_TYPES:\n            t = \"symbolic\"\n\n        base = \"\"\"\nCRITICAL ANSWER FORMATTING REQUIREMENTS:\nYou MUST end your solution with the final answer in the exact format below.\nFirst provide a human-readable final line starting with 'Final Answer:'.\nImmediately after that line include a machine-readable final tag: <final>...</final>.\nThe content inside <final> should be concise and contain only the final answer (no extra reasoning).\n\"\"\"\n\n        if t == \"proof\":\n            return base + \"\"\"\nFINAL ANSWER FORMAT FOR PROOFS:\nAfter the proof, write exactly:\n\nFinal Answer:\n[Concise English conclusion]\n\nThen the machine-readable tag on its own line:\n\n<final>[Concise English conclusion]</final>\n\"\"\"\n        elif t == \"numerical\":\n            return base + \"\"\"\nFINAL ANSWER FORMAT FOR NUMERICAL RESULTS:\nAfter the calculation, write exactly:\n\nFinal Answer:\n[Numeric result in exact form or decimal]\n\nThen the machine-readable tag on its own line:\n\n<final>[Numeric result]</final>\n\nFormatting rules:\n- If an exact symbolic value exists, return exact (fraction or radical).\n- Otherwise return a decimal rounded to 4 decimal places.\n\"\"\"\n        else:  # symbolic\n            return base + \"\"\"\nFINAL ANSWER FORMAT FOR SYMBOLIC RESULTS:\nAfter the manipulations, write exactly:\n\nFinal Answer:\n[Final symbolic expression; prefer LaTeX for clarity]\n\nThen the machine-readable tag on its own line:\n\n<final>[LaTeX expression or boxed LaTeX]</final>\n\"\"\"\n\n    def _create_prompt(self, question, answer_type=\"General\"):\n        format_instructions = self._get_format_instructions(answer_type)\n\n        solution_approach_block = \"\"\"\nSOLUTION APPROACH:\n\n1. PROBLEM UNDERSTANDING:\n   - Carefully read and understand what the problem is asking\n   - Identify the type of mathematical problem (proof, calculation, algebraic manipulation, etc.)\n   - Note any given conditions, constraints, or assumptions\n\n2. MATHEMATICAL ANALYSIS:\n   - Break down the problem into smaller, manageable steps\n   - Identify relevant mathematical theorems, formulas, or principles\n   - Plan your solution strategy\n\n3. STEP-BY-STEP SOLUTION:\n   - Show all mathematical work clearly\n   - Use proper mathematical notation and symbols\n   - Explain each step of your reasoning\n   - For proofs: Use logical argumentation and contradiction methods when appropriate\n   - For calculations: Show all arithmetic operations\n   - For algebraic problems: Show all algebraic manipulations\n\n4. VERIFICATION:\n   - Check your work for mathematical accuracy\n   - Ensure your solution directly answers the question asked\n   - Verify that your reasoning is logically sound\n\"\"\"\n\n        math_notation_block = \"\"\"\nMATHEMATICAL NOTATION GUIDELINES:\n- Use $$ for displayed equations and $ for inline expressions.\n- Use LaTeX commands like \\\\frac{num}{den}, \\\\sqrt{...}, \\\\pm, \\\\le, \\\\ge where appropriate.\n- Use proper mathematical symbols: √, ∴, ∵, ≠, ≤, ≥, etc.\n\"\"\"\n\n        prompt = f\"\"\"You are an expert mathematician who solves mathematical problems in English.\nSolve the problem step-by-step and follow the formatting rules strictly.\n\nMATHEMATICAL PROBLEM:\n{question}\n\n{solution_approach_block}\n\n{math_notation_block}\n\n{format_instructions}\n\nImportant: Write the full solution in English. Show reasoning and intermediate steps according to the SOLUTION APPROACH above.\nAfter finishing the reasoning, include the final answer EXACTLY as specified in the formatting instructions (a human-readable 'Final Answer:' line followed immediately by a machine-readable <final>...</final> tag).\n\nBegin your solution now:\n\"\"\"\n        return prompt\n\n    def _generate_once(self, prompt_text: str, enable_thinking: bool = False, deterministic: bool = False) -> str:\n        \"\"\"\n        Use Ollama client.chat to produce a response string.\n\n        IMPORTANT: we do NOT pass temperature= or max_tokens= to the client.\n        Deterministic requests are simulated by prepending a short instruction to the prompt_text.\n        \"\"\"\n        # If deterministic requested, prepend an explicit instruction so the model is told to be deterministic.\n        final_prompt = prompt_text\n        if deterministic:\n            deterministic_header = (\n                \"DETERMINISTIC MODE: Respond deterministically and DO NOT sample. \"\n                \"Output exactly what is requested. (This is an instruction to the model; \"\n                \"no API-level temperature parameter is available.)\\n\\n\"\n            )\n            final_prompt = deterministic_header + prompt_text\n\n        # Build messages list; put the full prompt as a single user message.\n        messages = [{\"role\": \"user\", \"content\": final_prompt}]\n\n        # Call Ollama without temperature or max_tokens arguments\n        try:\n            resp = self.client.chat(\n                model=self.model_name,\n                messages=messages,\n                think=enable_thinking\n            )\n        except TypeError:\n            # If client's signature is slightly different, try the positional form\n            # (avoid passing temperature/max_tokens)\n            try:\n                resp = self.client.chat(self.model_name, messages=messages, think=enable_thinking)\n            except Exception:\n                # Last resort: call with only model and messages\n                resp = self.client.chat(self.model_name, messages)\n\n        # Extract the text from the response (handle a few common shapes)\n        full_output = \"\"\n        if isinstance(resp, dict):\n            if 'message' in resp and isinstance(resp['message'], dict) and 'content' in resp['message']:\n                full_output = resp['message']['content']\n            elif 'choices' in resp and isinstance(resp['choices'], (list, tuple)) and resp['choices']:\n                choice = resp['choices'][0]\n                if isinstance(choice, dict) and 'message' in choice and isinstance(choice['message'], dict):\n                    full_output = choice['message'].get('content', '')\n                else:\n                    full_output = str(choice)\n            else:\n                full_output = str(resp)\n        else:\n            # resp might be an object with attributes\n            try:\n                full_output = resp.message.content  # common attribute access\n            except Exception:\n                full_output = str(resp)\n\n        if isinstance(full_output, bytes):\n            full_output = full_output.decode('utf-8', errors='ignore')\n        return (full_output or \"\").strip()\n\n    def _parse_thinking_output(self, full_output: str):\n        \"\"\"\n        String-based parsing for thinking blocks:\n        - If model returned <think>...</think> blocks, extract them.\n        - Otherwise return empty thinking_content and the full output as content.\n        \"\"\"\n        if not full_output:\n            return \"\", \"\"\n        if \"<think>\" in full_output and \"</think>\" in full_output:\n            parts = full_output.split(\"<think>\", 1)\n            if len(parts) > 1:\n                thinking_part = parts[1].split(\"</think>\", 1)\n                if len(thinking_part) > 1:\n                    thinking_content = thinking_part[0].strip()\n                    content = thinking_part[1].strip()\n                else:\n                    thinking_content = thinking_part[0].strip()\n                    content = \"\"\n            else:\n                thinking_content = \"\"\n                content = full_output\n            return thinking_content, content\n        # No explicit thinking tags\n        return \"\", full_output\n\n    def solve_problem(self, question, answer_type=\"symbolic\", enable_thinking=False, two_pass=True):\n        \"\"\"\n        Solve the problem using Ollama.\n        answer_type should be one of 'symbolic', 'numerical', or 'proof'.\n        If two_pass=True, performs a second pass (with a deterministic instruction header) to produce only the <final> tag when needed.\n        \"\"\"\n        prompt = self._create_prompt(question, answer_type)\n\n        full_output = self._generate_once(prompt, enable_thinking=enable_thinking, deterministic=False)\n        thinking_content, remainder_content = self._parse_thinking_output(full_output)\n        generated_answer = remainder_content if thinking_content else full_output\n\n        final_tag_output = \"\"\n        extracted_final_answer = AnswerExtractor.extract_final_answer(generated_answer)\n\n        # If two-pass enabled and extraction failed, request deterministic final-only emission\n        if two_pass and not extracted_final_answer:\n            prompt2 = (\n                \"Below is the previously generated full solution (including reasoning). \"\n                \"You must now output ONLY the concise final answer and nothing else, \"\n                \"enclosed in a single machine-readable tag <final>...</final>. \"\n                \"Do not include any other text or explanation. If the final answer is textual, \"\n                \"start the text inside <final> with 'Answer:' then the concise answer.\\n\\n\"\n                \"IMPORTANT: This is a deterministic instruction — do NOT sample. Output exactly one <final> tag and nothing else.\\n\\n\"\n                \"PREVIOUS SOLUTION:\\n\\n\"\n                f\"{full_output}\\n\\n\"\n                \"OUTPUT FORMAT EXAMPLE:\\n\"\n                \"<final>Answer: √10 is irrational.</final>\\n\"\n            )\n            final_tag_output = self._generate_once(prompt2, enable_thinking=False, deterministic=True)\n            extracted_final_answer = AnswerExtractor.extract_final_answer(final_tag_output)\n\n        return {\n            \"thinking_content\": thinking_content,\n            \"generated_answer\": generated_answer,\n            \"final_tag_output\": final_tag_output,\n            \"extracted_final_answer\": extracted_final_answer\n        }\n\n\n# -------------------------\n# Dataset Processor\n# (uses SimplifiedAnswerExtractor via AnswerExtractor adapter)\n# -------------------------\nclass DatasetProcessor:\n    def __init__(self, solver: OllamaMathSolver, failed_folder=None):\n        self.solver = solver\n        self.extractor = AnswerExtractor  # static adapter\n        self.failed_folder = failed_folder or \"failed_extractions\"\n        os.makedirs(self.failed_folder, exist_ok=True)\n\n    def process_dataset(self, dataset_path, output_base_path, start_idx=0, end_idx=None,\n                        folder_name=None, create_timestamped_folder=True, two_pass=True):\n        dataset = self._load_dataset(dataset_path)\n        if end_idx is None:\n            end_idx = len(dataset)\n\n        output_folder = self._create_output_folder(output_base_path, folder_name, start_idx, end_idx, create_timestamped_folder)\n        results = []\n\n        print(f\"Processing problems {start_idx} to {end_idx-1} ({end_idx-start_idx} total)\")\n        print(f\"Output will be saved in: {output_folder}\")\n\n        for idx in tqdm(range(start_idx, min(end_idx, len(dataset)))):\n            problem = dataset[idx]\n            try:\n                result_entry = self._process_single_problem(idx, problem, two_pass=two_pass)\n                results.append(result_entry)\n                self._print_progress(idx, result_entry)\n                if (idx - start_idx + 1) % 10 == 0:\n                    self._save_intermediate_results(results, output_folder, idx - start_idx + 1)\n            except Exception as e:\n                print(f\"Error processing problem {idx+1}: {str(e)}\")\n                error_entry = self._create_error_entry(idx, problem, str(e))\n                results.append(error_entry)\n\n        final_output_path = self._save_final_results(results, output_folder, start_idx, end_idx)\n        self._create_summary_file(results, output_folder, dataset_path, start_idx, end_idx)\n        return results, output_folder\n\n    def _create_output_folder(self, base_path, folder_name, start_idx, end_idx, add_timestamp):\n        if folder_name is None:\n            folder_name = f\"results_{start_idx}_to_{end_idx-1}\"\n        if add_timestamp:\n            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n            folder_name = f\"{folder_name}_{timestamp}\"\n        output_folder = os.path.join(base_path, folder_name)\n        os.makedirs(output_folder, exist_ok=True)\n        return output_folder\n\n    def _load_dataset(self, dataset_path):\n        dataset = []\n        with open(dataset_path, 'r', encoding='utf-8') as f:\n            for line in f:\n                if line.strip():\n                    dataset.append(json.loads(line))\n        return dataset\n\n    def _process_single_problem(self, idx, problem, two_pass=True):\n        language = problem.get(\"Language\", \"\")\n        chapter_num = problem.get(\"Chapter Number\", \"\")\n        example_num = problem.get(\"Example Number\", \"\")\n        question = problem.get(\"Question\", \"\")\n        exact_answer = problem.get(\"Exact Answer\", \"\")\n        raw_answer_type = problem.get(\"Answer Type\", \"\") or \"\"\n\n        # Normalize/infer canonical answer type: 'symbolic', 'numerical', 'proof'\n        canonical_type = normalize_answer_type(raw_answer_type, question_text=question, exact_answer=exact_answer)\n\n        # If exact_answer strongly indicates numeric, prefer numerical\n        if exact_answer and re.search(r'\\d', str(exact_answer)):\n            # if exact contains LaTeX expressions like \\frac or \\sqrt, keep symbolic\n            if re.search(r'\\\\frac|\\\\sqrt|\\\\boxed', str(exact_answer)):\n                pass\n            else:\n                canonical_type = \"numerical\"\n\n        print(f\"\\nProcessing Problem {idx+1}: Chapter {chapter_num}, Example {example_num}\")\n        print(f\"Raw Answer Type: '{raw_answer_type}'  --> canonical: '{canonical_type}'\")\n\n        # Generate solution (use canonical_type)\n        solution_result = self.solver.solve_problem(question, answer_type=canonical_type, enable_thinking=False, two_pass=two_pass)\n        generated_answer = solution_result.get('generated_answer', '')\n        thinking_content = solution_result.get('thinking_content', '')\n        final_tag_output = solution_result.get('final_tag_output', '')\n\n        # --- Use simplified extractor (supports single final & multi finals via adapter) ---\n        all_finals = AnswerExtractor.extract_all_final_answers(generated_answer)\n        extracted_final_answer = \"\"\n        extracted_final_answers = []\n\n        # If none found in generated_answer, try final_tag_output (second pass raw)\n        if not all_finals and final_tag_output:\n            all_finals = AnswerExtractor.extract_all_final_answers(final_tag_output)\n\n        # If still none, fall back to single-answer extractor (old behavior)\n        if not all_finals:\n            single = AnswerExtractor.extract_final_answer(generated_answer)\n            if single:\n                extracted_final_answer = single\n                extracted_final_answers = [single]\n            else:\n                # try whole combined text (thinking + generated + final_tag)\n                combined = \"\\n\".join([thinking_content or \"\", generated_answer or \"\", final_tag_output or \"\"])\n                single = AnswerExtractor.extract_final_answer(combined)\n                if single:\n                    extracted_final_answer = single\n                    extracted_final_answers = [single]\n                else:\n                    extracted_final_answer = \"\"\n                    extracted_final_answers = []\n        else:\n            # we have one or more finals\n            extracted_final_answers = all_finals\n            if len(all_finals) == 1:\n                extracted_final_answer = all_finals[0]\n            else:\n                # store a machine-readable concatenation: JSON array string\n                try:\n                    extracted_final_answer = json.dumps(all_finals, ensure_ascii=False)\n                except Exception:\n                    extracted_final_answer = \" ||| \".join(all_finals)\n\n        # If still empty, save a failed extraction example for inspection\n        if not extracted_final_answer:\n            fname = f\"failed_{idx}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n            fpath = os.path.join(self.failed_folder, fname)\n            with open(fpath, 'w', encoding='utf-8') as f:\n                json.dump({\n                    \"index\": idx,\n                    \"question\": question,\n                    \"generated_answer\": generated_answer,\n                    \"thinking_content\": thinking_content,\n                    \"final_tag_output\": final_tag_output,\n                    \"exact_answer\": exact_answer,\n                    \"canonical_type\": canonical_type,\n                    \"extracted_final_answer\": extracted_final_answer,\n                    \"extracted_final_answers\": extracted_final_answers\n                }, f, ensure_ascii=False, indent=2)\n            print(f\"Saved failed extraction example to {fpath}\")\n\n        result_entry = {\n            \"problem_index\": idx,\n            \"language\": language,\n            \"chapter_number\": chapter_num,\n            \"example_number\": example_num,\n            \"question\": question,\n            \"generated_answer\": generated_answer,\n            \"thinking_content\": thinking_content,\n            \"final_tag_output\": final_tag_output,\n            \"extracted_final_answer\": extracted_final_answer,       # string (or JSON array string)\n            \"extracted_final_answers\": extracted_final_answers,     # list (empty / single / many)\n            \"exact_answer\": exact_answer,\n            \"raw_answer_type\": raw_answer_type,\n            \"canonical_answer_type\": canonical_type,\n            \"evaluation_method\": problem.get(\"Evaluation Method\", \"\")\n        }\n        return result_entry\n\n    def _create_error_entry(self, idx, problem, error_msg):\n        return {\n            \"problem_index\": idx,\n            \"language\": problem.get(\"Language\", \"\"),\n            \"chapter_number\": problem.get(\"Chapter Number\", \"\"),\n            \"example_number\": problem.get(\"Example Number\", \"\"),\n            \"question\": problem.get(\"Question\", \"\"),\n            \"generated_answer\": f\"ERROR: {error_msg}\",\n            \"thinking_content\": \"\",\n            \"final_tag_output\": \"\",\n            \"extracted_final_answer\": \"\",\n            \"extracted_final_answers\": [],\n            \"exact_answer\": problem.get(\"Exact Answer\", \"\"),\n            \"raw_answer_type\": problem.get(\"Answer Type\", \"\"),\n            \"canonical_answer_type\": \"\",\n            \"evaluation_method\": problem.get(\"Evaluation Method\", \"\")\n        }\n\n    def _print_progress(self, idx, result_entry):\n        print(f\"Generated answer length: {len(result_entry['generated_answer']) if result_entry['generated_answer'] else 0}\")\n        print(f\"Extracted final answer: '{result_entry['extracted_final_answer']}'\")\n        print(f\"Extracted final answers (list): {result_entry.get('extracted_final_answers', [])}\")\n        print(f\"Expected answer: '{result_entry['exact_answer']}'\")\n\n    def _save_intermediate_results(self, results, output_folder, count):\n        temp_filename = f'intermediate_results_{count}.json'\n        temp_output_path = os.path.join(output_folder, temp_filename)\n        with open(temp_output_path, 'w', encoding='utf-8') as f:\n            json.dump(results, f, ensure_ascii=False, indent=2)\n        print(f\"Saved intermediate results to {temp_output_path}\")\n\n    def _save_final_results(self, results, output_folder, start_idx, end_idx):\n        final_filename = f'final_results_{start_idx}_to_{end_idx-1}.json'\n        final_output_path = os.path.join(output_folder, final_filename)\n        with open(final_output_path, 'w', encoding='utf-8') as f:\n            json.dump(results, f, ensure_ascii=False, indent=2)\n        print(f\"\\nProcessing complete. Results saved to {final_output_path}\")\n        print(f\"Total problems processed: {len(results)}\")\n        return final_output_path\n\n    def _create_summary_file(self, results, output_folder, dataset_path, start_idx, end_idx):\n        successful_extractions = len([r for r in results if r.get('extracted_final_answer', '').strip()])\n        summary_data = {\n            \"processing_info\": {\n                \"dataset_path\": dataset_path,\n                \"start_index\": start_idx,\n                \"end_index\": end_idx - 1,\n                \"total_processed\": len(results),\n                \"processing_timestamp\": datetime.now().isoformat(),\n                \"output_folder\": output_folder\n            },\n            \"statistics\": {\n                \"successful_problems\": len([r for r in results if not r['generated_answer'].startswith('ERROR:')]),\n                \"failed_problems\": len([r for r in results if r['generated_answer'].startswith('ERROR:')]),\n                \"successful_extractions\": successful_extractions,\n                \"extraction_success_rate\": f\"{(successful_extractions/len(results)*100):.1f}%\" if results else \"0%\",\n                \"average_answer_length\": sum(len(r['generated_answer']) for r in results) / len(results) if results else 0,\n                \"chapters_processed\": list(set(r['chapter_number'] for r in results if r['chapter_number'])),\n                \"raw_answer_types\": list(set(r['raw_answer_type'] for r in results if r.get('raw_answer_type'))),\n                \"canonical_answer_types\": list(set(r['canonical_answer_type'] for r in results if r.get('canonical_answer_type')))\n            }\n        }\n        summary_path = os.path.join(output_folder, 'processing_summary.json')\n        with open(summary_path, 'w', encoding='utf-8') as f:\n            json.dump(summary_data, f, ensure_ascii=False, indent=2)\n        print(f\"Processing summary saved to {summary_path}\")\n        print(f\"Answer extraction success rate: {summary_data['statistics']['extraction_success_rate']}\")\n\n\n# -------------------------\n# Main (example usage)\n# -------------------------\ndef main():\n    # NOTE: update dataset_path and output_base_path to match your environment\n    dataset_path = \"/kaggle/input/nctb-dataset/English_Final_Corpus.jsonl\"  # source format unchanged; questions are English\n    output_base_path = \"/kaggle/working/\"\n\n    # Use OllamaMathSolver (model reference must match a model available locally via Ollama)\n    solver = OllamaMathSolver(model_name=\"mathstral:7b\")\n    processor = DatasetProcessor(solver, failed_folder=os.path.join(output_base_path, \"failed_extractions\"))\n\n    # For quick testing, process only first few problems\n    results, out_folder = processor.process_dataset(\n        dataset_path,\n        output_base_path,\n        start_idx=0,\n        end_idx=1445,\n        two_pass=True\n    )\n    print(\"Done. Results saved to:\", out_folder)\n\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T02:24:35.207380Z","iopub.execute_input":"2025-09-05T02:24:35.207679Z","iopub.status.idle":"2025-09-05T02:26:50.775208Z","shell.execute_reply.started":"2025-09-05T02:24:35.207659Z","shell.execute_reply":"2025-09-05T02:26:50.774384Z"},"scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import json\n# import os\n# import re\n# from datetime import datetime\n# from tqdm import tqdm\n\n# # Replace Hugging Face with Ollama\n# try:\n#     import ollama\n# except Exception as e:\n#     raise ImportError(\"The 'ollama' package is required. Install it and make sure the Ollama daemon is running.\") from e\n\n# # -------------------------\n# # Answer type normalization\n# # -------------------------\n# # Canonical set\n# _CANONICAL_TYPES = {\"symbolic\", \"numerical\", \"proof\"}\n\n# # mapping common noisy labels to canonical\n# _ANSWER_TYPE_MAP_SIMPLE = {\n#     # Proof variants\n#     \"proof\": \"proof\", \"prove\": \"proof\",\n#     # Numerical variants\n#     \"numerical\": \"numerical\", \"numeric\": \"numerical\", \"number\": \"numerical\", \"calculation\": \"numerical\",\n#     # Symbolic variants\n#     \"symbolic\": \"symbolic\", \"symbol\": \"symbolic\", \"equation\": \"symbolic\", \"algebraic\": \"symbolic\",\n# }\n\n\n# def normalize_answer_type(raw_label: str, question_text: str = \"\", exact_answer: str = \"\") -> str:\n#     \"\"\"\n#     Normalize a dataset label to one of: 'symbolic', 'numerical', 'proof'.\n#     Heuristics:\n#       - Direct mapping from known strings (English)\n#       - If dataset field missing or noisy, infer from question or exact_answer\n#       - Final fallback: 'symbolic'\n#     \"\"\"\n#     # Helper to clean label\n#     def _clean_label(lbl: str) -> str:\n#         if not lbl:\n#             return \"\"\n#         s = lbl.strip().lower()\n#         s = re.sub(r'[^0-9a-z\\s]', ' ', s)\n#         s = re.sub(r'\\s+', ' ', s).strip()\n#         return s\n\n#     s = _clean_label(raw_label)\n\n#     # direct mapping\n#     if s in _ANSWER_TYPE_MAP_SIMPLE:\n#         return _ANSWER_TYPE_MAP_SIMPLE[s]\n\n#     # partial matches\n#     for k, v in _ANSWER_TYPE_MAP_SIMPLE.items():\n#         if k in s:\n#             return v\n\n#     # heuristics using question or exact_answer\n#     q = (question_text or \"\").lower()\n#     a = (exact_answer or \"\").lower()\n\n#     if re.search(r'prove|show that|prove that', q) or 'proof' in s:\n#         return \"proof\"\n\n#     if re.search(r'\\b(log|ln|logarithm)\\b', q) or re.search(r'\\blog\\b', a):\n#         # default to symbolic but prefer numerical if exact answer contains digits\n#         if re.search(r'\\d', a):\n#             return \"numerical\"\n#         return \"symbolic\"\n\n#     if re.search(r'set|subset|\\bunion\\b|\\bintersection\\b', q):\n#         return \"symbolic\"\n\n#     if re.search(r'meter|m\\b|cm|kg|liter|l\\b|unit|units|km|mile', q + \" \" + a):\n#         return \"numerical\"\n\n#     # equation-solving heuristics\n#     if re.search(r'equation|solve for|solve|= x|x\\s*=', q) or re.search(r'= x|= \\d', a):\n#         return \"symbolic\"\n\n#     if re.search(r'trig|sin|cos|tan|geometry|triangle|circle', q):\n#         if re.search(r'\\d', a):\n#             return \"numerical\"\n#         return \"symbolic\"\n\n#     # numeric indicators -> numerical\n#     if re.search(r'\\d', q) or re.search(r'find the value|compute|calculate|evaluate', q):\n#         return \"numerical\"\n\n#     # If exact_answer looks numeric, prefer numerical\n#     if re.search(r'[0-9]|\\\\frac|\\\\sqrt', a):\n#         if re.search(r'\\\\frac|\\\\sqrt|\\{|\\\\', a):\n#             return \"symbolic\"\n#         return \"numerical\"\n\n#     # fallback\n#     return \"symbolic\"\n\n# # -------------------------\n# # Enhanced answer extractor\n# # -------------------------\n# class EnhancedAnswerExtractor:\n#     \"\"\"\n#     Robust final-answer extractor:\n#     - Prefers explicit <final> tags and JSON-like answers\n#     - Falls back to boxed math, $$...$$, inline $...$, \\boxed{}, conclusion markers and last meaningful content\n#     - Safe cleaning rules that avoid removing substantive answer phrases\n#     \"\"\"\n\n#     @staticmethod\n#     def extract_all_final_answers(generated_solution: str) -> list:\n#         \"\"\"\n#         Return a list of cleaned strings found inside all <final>...</final> tags.\n#         If none found, returns [].\n#         \"\"\"\n#         if not generated_solution:\n#             return []\n#         text = generated_solution\n#         # Find all <final>...</final> (non-greedy)\n#         raw_matches = re.findall(r'<final>(.*?)</final>', text, re.DOTALL | re.IGNORECASE)\n#         cleaned = []\n#         for m in raw_matches:\n#             c = EnhancedAnswerExtractor._clean_answer(m)\n#             if EnhancedAnswerExtractor._is_valid_answer(c):\n#                 cleaned.append(c)\n#         return cleaned\n\n#     @staticmethod\n#     def extract_final_answer(generated_solution: str) -> str:\n#         \"\"\"\n#         Backwards-compatible extractor:\n#         - If one or more <final> tags exist -> prefer them.\n#           * If exactly 1 tag -> return its cleaned string.\n#           * If multiple tags -> return a JSON array string (ensure_ascii=False).\n#             Note: consumer can also call extract_all_final_answers to get the list.\n#         - If no <final> tags, fallback to standard extraction behavior.\n#         \"\"\"\n#         # 1) Prefer explicit <final> tags (can be multiple)\n#         finals = EnhancedAnswerExtractor.extract_all_final_answers(generated_solution)\n#         if finals:\n#             if len(finals) == 1:\n#                 return finals[0]\n#             # multiple finals: return JSON array string for compatibility/saveability\n#             try:\n#                 return json.dumps(finals, ensure_ascii=False)\n#             except Exception:\n#                 # fallback: join with a clear delimiter\n#                 return \" ||| \".join(finals)\n\n#         # 2) existing fallback logic (conclusion markers, math blocks, last meaningful)\n#         text = (generated_solution or \"\").strip()\n\n#         # Standardized format\n#         final_answer = EnhancedAnswerExtractor._extract_standardized_format(text)\n#         if final_answer:\n#             return final_answer\n\n#         # Math expressions\n#         final_answer = EnhancedAnswerExtractor._extract_math_expressions(text)\n#         if final_answer:\n#             return final_answer\n\n#         # Conclusion markers\n#         final_answer = EnhancedAnswerExtractor._extract_conclusion_markers(text)\n#         if final_answer:\n#             return final_answer\n\n#         # Last meaningful content\n#         final_answer = EnhancedAnswerExtractor._extract_last_meaningful_content(text)\n#         if final_answer:\n#             return final_answer\n\n#         return \"\"\n\n#     @staticmethod\n#     def _extract_standardized_format(text: str) -> str:\n#         patterns = [\n#             r'<final>(.*?)</final>',\n#             r'\\*\\*Final Answer:\\*\\*\\s*(.+?)(?:\\n|$)',\n#             r'\\*\\*Final Answer\\*\\*:\\s*(.+?)(?:\\n|$)',\n#             r'Final Answer:\\s*(.+?)(?:\\n|$)',\n#             r'Final Answer\\s*[:\\-]\\s*(.+?)(?:\\n|$)',\n#         ]\n#         for pat in patterns:\n#             m = re.search(pat, text, re.DOTALL | re.IGNORECASE)\n#             if m:\n#                 answer = m.group(1).strip()\n#                 cleaned = EnhancedAnswerExtractor._clean_answer(answer)\n#                 if EnhancedAnswerExtractor._is_valid_answer(cleaned):\n#                     return cleaned\n#         return \"\"\n\n#     @staticmethod\n#     def _extract_conclusion_markers(text: str) -> str:\n#         conclusion_patterns = [\n#             r'Therefore[,:\\s]*(.+?)(?:\\.|$|\\n)',\n#             r'Hence[,:\\s]*(.+?)(?:\\.|$|\\n)',\n#             r'Thus[,:\\s]*(.+?)(?:\\.|$|\\n)',\n#             r'∴\\s*(.+?)(?:\\.|$|\\n)',\n#             r'Proved\\s*(?:that)?[:,\\s]*(.+?)(?:\\.|$|\\n)',\n#             r'Answer[:\\s]*(.+?)(?:\\n|$)',\n#             r'Solution[:\\s]*(.+?)(?:\\n|$)',\n#             r'Result[:\\s]*(.+?)(?:\\n|$)',\n#         ]\n#         for pat in conclusion_patterns:\n#             matches = re.findall(pat, text, re.MULTILINE | re.DOTALL | re.IGNORECASE)\n#             if matches:\n#                 answer = matches[-1].strip()\n#                 cleaned = EnhancedAnswerExtractor._clean_answer(answer)\n#                 if EnhancedAnswerExtractor._is_valid_answer(cleaned):\n#                     return cleaned\n#         return \"\"\n\n#     @staticmethod\n#     def _extract_math_expressions(text: str) -> str:\n#         # \\boxed{}\n#         m = re.search(r'\\\\boxed\\{(.+?)\\}', text, re.DOTALL)\n#         if m:\n#             cand = EnhancedAnswerExtractor._clean_answer(m.group(1))\n#             if EnhancedAnswerExtractor._is_valid_answer(cand):\n#                 return cand\n\n#         # $$ ... $$\n#         displays = re.findall(r'\\$\\$(.+?)\\$\\$', text, re.DOTALL)\n#         if displays:\n#             for block in reversed(displays):\n#                 cand = EnhancedAnswerExtractor._clean_answer(block)\n#                 if EnhancedAnswerExtractor._is_valid_answer(cand):\n#                     return cand\n\n#         # Inline $...$\n#         inlines = re.findall(r'\\$(.+?)\\$', text)\n#         if inlines:\n#             for block in reversed(inlines):\n#                 cand = EnhancedAnswerExtractor._clean_answer(block)\n#                 if EnhancedAnswerExtractor._is_valid_answer(cand):\n#                     return cand\n\n#         # equals patterns\n#         eq_patterns = [r'=\\s*([^\\n\\.]+)', r'x\\s*=\\s*([^\\n\\.]+)', r'Answer[:\\s]*([^\\n\\.]+)']\n#         for pat in eq_patterns:\n#             matches = re.findall(pat, text)\n#             if matches:\n#                 for candidate in reversed(matches[-3:]):\n#                     cand = EnhancedAnswerExtractor._clean_answer(candidate)\n#                     if EnhancedAnswerExtractor._is_valid_answer(cand) and len(cand) < 400:\n#                         return cand\n#         return \"\"\n\n#     @staticmethod\n#     def _extract_last_meaningful_content(text: str) -> str:\n#         parts = [p.strip() for p in re.split(r'[\\n\\r]+', text) if p.strip()]\n#         for part in reversed(parts[-6:]):\n#             if EnhancedAnswerExtractor._contains_answer_indicators(part):\n#                 cand = EnhancedAnswerExtractor._clean_answer(part)\n#                 if EnhancedAnswerExtractor._is_valid_answer(cand):\n#                     return cand\n#         sentences = re.split(r'[.\\n]', text)\n#         for sentence in reversed([s.strip() for s in sentences if s.strip()]):\n#             cand = EnhancedAnswerExtractor._clean_answer(sentence)\n#             if EnhancedAnswerExtractor._is_valid_answer(cand):\n#                 return cand\n#         return \"\"\n\n#     @staticmethod\n#     def _clean_answer(answer: str) -> str:\n#         if not answer:\n#             return \"\"\n#         a = answer.strip()\n#         # collapse whitespace\n#         a = re.sub(r'\\s+', ' ', a)\n#         # remove outer $$ if present\n#         a = re.sub(r'^\\$\\$(.*)\\$\\$$', r'\\1', a)\n#         a = a.strip('$ ')\n#         # unwrap boxed\n#         a = re.sub(r'\\\\boxed\\{([^}]*)\\}', r'\\1', a)\n#         # convert common LaTeX to readable forms\n#         a = re.sub(r'\\\\frac\\{([^}]*)\\}\\{([^}]*)\\}', r'(\\1)/(\\2)', a)\n#         a = re.sub(r'\\\\sqrt\\{([^}]*)\\}', r'√(\\1)', a)\n#         a = re.sub(r'\\*\\*([^*]+)\\*\\*', r'\\1', a)\n#         a = re.sub(r'\\*([^*]+)\\*', r'\\1', a)\n#         # trim trailing punctuation/words\n#         a = a.rstrip(' \\t\\n.,;:')\n#         a = re.sub(r'\\b(proved|completed|finished|the answer)\\b[.\\s]*$', '', a, flags=re.IGNORECASE).strip()\n#         return a\n\n#     @staticmethod\n#     def _is_valid_answer(answer: str) -> bool:\n#         if not answer:\n#             return False\n#         # not only punctuation\n#         if re.match(r'^[\\W_]+$', answer):\n#             return False\n#         # contains at least some alphanumeric characters (or common math symbols like \\, sqrt, frac)\n#         if not re.search(r'[0-9A-Za-z\\\\]', answer):\n#             return False\n#         # length sanity\n#         if len(answer) > 1000:\n#             return False\n#         # avoid answers that end with only concluding words\n#         blacklist = [r'therefore$', r'thus$', r'hence$']\n#         for b in blacklist:\n#             if re.search(b, answer.strip(), flags=re.IGNORECASE):\n#                 return False\n#         return True\n\n#     @staticmethod\n#     def _contains_answer_indicators(text: str) -> bool:\n#         indicators = [\n#             'Final Answer', 'Final', 'Answer', 'Therefore', 'Thus', 'Hence', 'Proved', 'Result',\n#             'Conclusion', 'Solution', '=', '\\\\boxed', '√', '$$', '\\\\frac', '{', '}'\n#         ]\n#         return any(ind in text for ind in indicators)\n\n# # -------------------------\n# # Ollama-based English Math Solver (no temperature/max_tokens passed)\n# # -------------------------\n# class OllamaMathSolver:\n#     \"\"\"\n#     Math solver that uses the Ollama daemon via the Python client.\n#     It mirrors the previous EnglishMathSolver API but delegates generation to ollama.Client.chat.\n#     \"\"\"\n\n#     def __init__(self, model_name=\"mathstral:7b\"):\n#         \"\"\"\n#         model_name: the Ollama model reference (e.g., \"mathstral:7b\")\n#         \"\"\"\n#         self.model_name = model_name\n#         self.client = self._load_client()\n\n#     def _load_client(self):\n#         \"\"\"\n#         Initialize Ollama client.\n#         (The ollama.Client() usually connects to the local Ollama daemon.)\n#         \"\"\"\n#         print(f\"Initializing Ollama client for model: {self.model_name}\")\n#         client = ollama.Client()\n#         return client\n\n#     def cleanup(self):\n#         # nothing special required for Ollama client; remove references\n#         if hasattr(self, 'client'):\n#             del self.client\n\n#     def _get_format_instructions(self, answer_type):\n#         \"\"\"\n#         Keep the same formatting instruction generator as before.\n#         \"\"\"\n#         t = (answer_type or \"symbolic\").strip().lower()\n#         if t not in _CANONICAL_TYPES:\n#             t = \"symbolic\"\n\n#         base = \"\"\"\n# CRITICAL ANSWER FORMATTING REQUIREMENTS:\n# You MUST end your solution with the final answer in the exact format below.\n# First provide a human-readable final line starting with 'Final Answer:'.\n# Immediately after that line include a machine-readable final tag: <final>...</final>.\n# The content inside <final> should be concise and contain only the final answer (no extra reasoning).\n# \"\"\"\n\n#         if t == \"proof\":\n#             return base + \"\"\"\n# FINAL ANSWER FORMAT FOR PROOFS:\n# After the proof, write exactly:\n\n# Final Answer:\n# [Concise English conclusion]\n\n# Then the machine-readable tag on its own line:\n\n# <final>[Concise English conclusion]</final>\n# \"\"\"\n#         elif t == \"numerical\":\n#             return base + \"\"\"\n# FINAL ANSWER FORMAT FOR NUMERICAL RESULTS:\n# After the calculation, write exactly:\n\n# Final Answer:\n# [Numeric result in exact form or decimal]\n\n# Then the machine-readable tag on its own line:\n\n# <final>[Numeric result]</final>\n\n# Formatting rules:\n# - If an exact symbolic value exists, return exact (fraction or radical).\n# - Otherwise return a decimal rounded to 4 decimal places.\n# \"\"\"\n#         else:  # symbolic\n#             return base + \"\"\"\n# FINAL ANSWER FORMAT FOR SYMBOLIC RESULTS:\n# After the manipulations, write exactly:\n\n# Final Answer:\n# [Final symbolic expression; prefer LaTeX for clarity]\n\n# Then the machine-readable tag on its own line:\n\n# <final>[LaTeX expression or boxed LaTeX]</final>\n# \"\"\"\n\n#     def _create_prompt(self, question, answer_type=\"General\"):\n#         format_instructions = self._get_format_instructions(answer_type)\n\n#         solution_approach_block = \"\"\"\n# SOLUTION APPROACH:\n\n# 1. PROBLEM UNDERSTANDING:\n#    - Carefully read and understand what the problem is asking\n#    - Identify the type of mathematical problem (proof, calculation, algebraic manipulation, etc.)\n#    - Note any given conditions, constraints, or assumptions\n\n# 2. MATHEMATICAL ANALYSIS:\n#    - Break down the problem into smaller, manageable steps\n#    - Identify relevant mathematical theorems, formulas, or principles\n#    - Plan your solution strategy\n\n# 3. STEP-BY-STEP SOLUTION:\n#    - Show all mathematical work clearly\n#    - Use proper mathematical notation and symbols\n#    - Explain each step of your reasoning\n#    - For proofs: Use logical argumentation and contradiction methods when appropriate\n#    - For calculations: Show all arithmetic operations\n#    - For algebraic problems: Show all algebraic manipulations\n\n# 4. VERIFICATION:\n#    - Check your work for mathematical accuracy\n#    - Ensure your solution directly answers the question asked\n#    - Verify that your reasoning is logically sound\n# \"\"\"\n\n#         math_notation_block = \"\"\"\n# MATHEMATICAL NOTATION GUIDELINES:\n# - Use $$ for displayed equations and $ for inline expressions.\n# - Use LaTeX commands like \\\\frac{num}{den}, \\\\sqrt{...}, \\\\pm, \\\\le, \\\\ge where appropriate.\n# - Use proper mathematical symbols: √, ∴, ∵, ≠, ≤, ≥, etc.\n# \"\"\"\n\n#         prompt = f\"\"\"You are an expert mathematician who solves mathematical problems in English.\n# Solve the problem step-by-step and follow the formatting rules strictly.\n\n# MATHEMATICAL PROBLEM:\n# {question}\n\n# {solution_approach_block}\n\n# {math_notation_block}\n\n# {format_instructions}\n\n# Important: Write the full solution in English. Show reasoning and intermediate steps according to the SOLUTION APPROACH above.\n# After finishing the reasoning, include the final answer EXACTLY as specified in the formatting instructions (a human-readable 'Final Answer:' line followed immediately by a machine-readable <final>...</final> tag).\n\n# Begin your solution now:\n# \"\"\"\n#         return prompt\n\n#     def _generate_once(self, prompt_text: str, enable_thinking: bool = False, deterministic: bool = False) -> str:\n#         \"\"\"\n#         Use Ollama client.chat to produce a response string.\n\n#         IMPORTANT: we do NOT pass temperature= or max_tokens= to the client.\n#         Deterministic requests are simulated by prepending a short instruction to the prompt_text.\n#         \"\"\"\n#         # If deterministic requested, prepend an explicit instruction so the model is told to be deterministic.\n#         final_prompt = prompt_text\n#         if deterministic:\n#             deterministic_header = (\n#                 \"DETERMINISTIC MODE: Respond deterministically and DO NOT sample. \"\n#                 \"Output exactly what is requested. (This is an instruction to the model; \"\n#                 \"no API-level temperature parameter is available.)\\n\\n\"\n#             )\n#             final_prompt = deterministic_header + prompt_text\n\n#         # Build messages list; put the full prompt as a single user message.\n#         messages = [{\"role\": \"user\", \"content\": final_prompt}]\n\n#         # Call Ollama without temperature or max_tokens arguments\n#         try:\n#             resp = self.client.chat(\n#                 model=self.model_name,\n#                 messages=messages,\n#                 think=enable_thinking\n#             )\n#         except TypeError:\n#             # If client's signature is slightly different, try the positional form\n#             # (avoid passing temperature/max_tokens)\n#             try:\n#                 resp = self.client.chat(self.model_name, messages=messages, think=enable_thinking)\n#             except Exception:\n#                 # Last resort: call with only model and messages\n#                 resp = self.client.chat(self.model_name, messages)\n\n#         # Extract the text from the response (handle a few common shapes)\n#         full_output = \"\"\n#         if isinstance(resp, dict):\n#             if 'message' in resp and isinstance(resp['message'], dict) and 'content' in resp['message']:\n#                 full_output = resp['message']['content']\n#             elif 'choices' in resp and isinstance(resp['choices'], (list, tuple)) and resp['choices']:\n#                 choice = resp['choices'][0]\n#                 if isinstance(choice, dict) and 'message' in choice and isinstance(choice['message'], dict):\n#                     full_output = choice['message'].get('content', '')\n#                 else:\n#                     full_output = str(choice)\n#             else:\n#                 full_output = str(resp)\n#         else:\n#             # resp might be an object with attributes\n#             try:\n#                 full_output = resp.message.content  # common attribute access\n#             except Exception:\n#                 full_output = str(resp)\n\n#         if isinstance(full_output, bytes):\n#             full_output = full_output.decode('utf-8', errors='ignore')\n#         return (full_output or \"\").strip()\n\n#     def _parse_thinking_output(self, full_output: str):\n#         \"\"\"\n#         String-based parsing for thinking blocks:\n#         - If model returned <think>...</think> blocks, extract them.\n#         - Otherwise return empty thinking_content and the full output as content.\n#         \"\"\"\n#         if not full_output:\n#             return \"\", \"\"\n#         if \"<think>\" in full_output and \"</think>\" in full_output:\n#             parts = full_output.split(\"<think>\", 1)\n#             if len(parts) > 1:\n#                 thinking_part = parts[1].split(\"</think>\", 1)\n#                 if len(thinking_part) > 1:\n#                     thinking_content = thinking_part[0].strip()\n#                     content = thinking_part[1].strip()\n#                 else:\n#                     thinking_content = thinking_part[0].strip()\n#                     content = \"\"\n#             else:\n#                 thinking_content = \"\"\n#                 content = full_output\n#             return thinking_content, content\n#         # No explicit thinking tags\n#         return \"\", full_output\n\n#     def solve_problem(self, question, answer_type=\"symbolic\", enable_thinking=False, two_pass=True):\n#         \"\"\"\n#         Solve the problem using Ollama.\n#         answer_type should be one of 'symbolic', 'numerical', or 'proof'.\n#         If two_pass=True, performs a second pass (with a deterministic instruction header) to produce only the <final> tag when needed.\n#         \"\"\"\n#         prompt = self._create_prompt(question, answer_type)\n\n#         full_output = self._generate_once(prompt, enable_thinking=enable_thinking, deterministic=False)\n#         thinking_content, remainder_content = self._parse_thinking_output(full_output)\n#         generated_answer = remainder_content if thinking_content else full_output\n\n#         final_tag_output = \"\"\n#         extracted_final_answer = EnhancedAnswerExtractor.extract_final_answer(generated_answer)\n\n#         # If two-pass enabled and extraction failed, request deterministic final-only emission\n#         if two_pass and not extracted_final_answer:\n#             prompt2 = (\n#                 \"Below is the previously generated full solution (including reasoning). \"\n#                 \"You must now output ONLY the concise final answer and nothing else, \"\n#                 \"enclosed in a single machine-readable tag <final>...</final>. \"\n#                 \"Do not include any other text or explanation. If the final answer is textual, \"\n#                 \"start the text inside <final> with 'Answer:' then the concise answer.\\n\\n\"\n#                 \"IMPORTANT: This is a deterministic instruction — do NOT sample. Output exactly one <final> tag and nothing else.\\n\\n\"\n#                 \"PREVIOUS SOLUTION:\\n\\n\"\n#                 f\"{full_output}\\n\\n\"\n#                 \"OUTPUT FORMAT EXAMPLE:\\n\"\n#                 \"<final>Answer: √10 is irrational.</final>\\n\"\n#             )\n#             final_tag_output = self._generate_once(prompt2, enable_thinking=False, deterministic=True)\n#             extracted_final_answer = EnhancedAnswerExtractor.extract_final_answer(final_tag_output)\n\n#         return {\n#             \"thinking_content\": thinking_content,\n#             \"generated_answer\": generated_answer,\n#             \"final_tag_output\": final_tag_output,\n#             \"extracted_final_answer\": extracted_final_answer\n#         }\n\n# # -------------------------\n# # Dataset Processor\n# # (unchanged aside from solver type)\n# # -------------------------\n# class DatasetProcessor:\n#     def __init__(self, solver: OllamaMathSolver, failed_folder=None):\n#         self.solver = solver\n#         self.extractor = EnhancedAnswerExtractor()\n#         self.failed_folder = failed_folder or \"failed_extractions\"\n#         os.makedirs(self.failed_folder, exist_ok=True)\n\n#     def process_dataset(self, dataset_path, output_base_path, start_idx=0, end_idx=None,\n#                         folder_name=None, create_timestamped_folder=True, two_pass=True):\n#         dataset = self._load_dataset(dataset_path)\n#         if end_idx is None:\n#             end_idx = len(dataset)\n\n#         output_folder = self._create_output_folder(output_base_path, folder_name, start_idx, end_idx, create_timestamped_folder)\n#         results = []\n\n#         print(f\"Processing problems {start_idx} to {end_idx-1} ({end_idx-start_idx} total)\")\n#         print(f\"Output will be saved in: {output_folder}\")\n\n#         for idx in tqdm(range(start_idx, min(end_idx, len(dataset)))):\n#             problem = dataset[idx]\n#             try:\n#                 result_entry = self._process_single_problem(idx, problem, two_pass=two_pass)\n#                 results.append(result_entry)\n#                 self._print_progress(idx, result_entry)\n#                 if (idx - start_idx + 1) % 10 == 0:\n#                     self._save_intermediate_results(results, output_folder, idx - start_idx + 1)\n#             except Exception as e:\n#                 print(f\"Error processing problem {idx+1}: {str(e)}\")\n#                 error_entry = self._create_error_entry(idx, problem, str(e))\n#                 results.append(error_entry)\n\n#         final_output_path = self._save_final_results(results, output_folder, start_idx, end_idx)\n#         self._create_summary_file(results, output_folder, dataset_path, start_idx, end_idx)\n#         return results, output_folder\n\n#     def _create_output_folder(self, base_path, folder_name, start_idx, end_idx, add_timestamp):\n#         if folder_name is None:\n#             folder_name = f\"results_{start_idx}_to_{end_idx-1}\"\n#         if add_timestamp:\n#             timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n#             folder_name = f\"{folder_name}_{timestamp}\"\n#         output_folder = os.path.join(base_path, folder_name)\n#         os.makedirs(output_folder, exist_ok=True)\n#         return output_folder\n\n#     def _load_dataset(self, dataset_path):\n#         dataset = []\n#         with open(dataset_path, 'r', encoding='utf-8') as f:\n#             for line in f:\n#                 if line.strip():\n#                     dataset.append(json.loads(line))\n#         return dataset\n\n#     def _process_single_problem(self, idx, problem, two_pass=True):\n#         language = problem.get(\"Language\", \"\")\n#         chapter_num = problem.get(\"Chapter Number\", \"\")\n#         example_num = problem.get(\"Example Number\", \"\")\n#         question = problem.get(\"Question\", \"\")\n#         exact_answer = problem.get(\"Exact Answer\", \"\")\n#         raw_answer_type = problem.get(\"Answer Type\", \"\") or \"\"\n\n#         # Normalize/infer canonical answer type: 'symbolic', 'numerical', 'proof'\n#         canonical_type = normalize_answer_type(raw_answer_type, question_text=question, exact_answer=exact_answer)\n\n#         # If exact_answer strongly indicates numeric, prefer numerical\n#         if exact_answer and re.search(r'\\d', str(exact_answer)):\n#             # if exact contains LaTeX expressions like \\frac or \\sqrt, keep symbolic\n#             if re.search(r'\\\\frac|\\\\sqrt|\\\\boxed', str(exact_answer)):\n#                 pass\n#             else:\n#                 canonical_type = \"numerical\"\n\n#         print(f\"\\nProcessing Problem {idx+1}: Chapter {chapter_num}, Example {example_num}\")\n#         print(f\"Raw Answer Type: '{raw_answer_type}'  --> canonical: '{canonical_type}'\")\n\n#         # Generate solution (use canonical_type)\n#         solution_result = self.solver.solve_problem(question, answer_type=canonical_type, enable_thinking=False, two_pass=two_pass)\n#         generated_answer = solution_result.get('generated_answer', '')\n#         thinking_content = solution_result.get('thinking_content', '')\n#         final_tag_output = solution_result.get('final_tag_output', '')\n\n#         # --- NEW extraction logic: keep both forms (single string & list) ---\n#         # Try to get all <final> answers first (preferred)\n#         all_finals = EnhancedAnswerExtractor.extract_all_final_answers(generated_answer)\n#         extracted_final_answer = \"\"\n#         extracted_final_answers = []\n\n#         # If none found in generated_answer, try final_tag_output (second pass raw)\n#         if not all_finals and final_tag_output:\n#             all_finals = EnhancedAnswerExtractor.extract_all_final_answers(final_tag_output)\n\n#         # If still none, fall back to single-answer extractor (old behavior)\n#         if not all_finals:\n#             single = EnhancedAnswerExtractor.extract_final_answer(generated_answer)\n#             if single:\n#                 extracted_final_answer = single\n#                 extracted_final_answers = [single]\n#             else:\n#                 # try whole combined text (thinking + generated + final_tag)\n#                 combined = \"\\n\".join([thinking_content or \"\", generated_answer or \"\", final_tag_output or \"\"])\n#                 single = EnhancedAnswerExtractor.extract_final_answer(combined)\n#                 if single:\n#                     extracted_final_answer = single\n#                     extracted_final_answers = [single]\n#                 else:\n#                     extracted_final_answer = \"\"\n#                     extracted_final_answers = []\n#         else:\n#             # we have one or more finals\n#             extracted_final_answers = all_finals\n#             if len(all_finals) == 1:\n#                 extracted_final_answer = all_finals[0]\n#             else:\n#                 # store a machine-readable concatenation: JSON array string\n#                 try:\n#                     extracted_final_answer = json.dumps(all_finals, ensure_ascii=False)\n#                 except Exception:\n#                     extracted_final_answer = \" ||| \".join(all_finals)\n\n#         # If still empty, save a failed extraction example for inspection\n#         if not extracted_final_answer:\n#             fname = f\"failed_{idx}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n#             fpath = os.path.join(self.failed_folder, fname)\n#             with open(fpath, 'w', encoding='utf-8') as f:\n#                 json.dump({\n#                     \"index\": idx,\n#                     \"question\": question,\n#                     \"generated_answer\": generated_answer,\n#                     \"thinking_content\": thinking_content,\n#                     \"final_tag_output\": final_tag_output,\n#                     \"exact_answer\": exact_answer,\n#                     \"canonical_type\": canonical_type,\n#                     \"extracted_final_answer\": extracted_final_answer,\n#                     \"extracted_final_answers\": extracted_final_answers\n#                 }, f, ensure_ascii=False, indent=2)\n#             print(f\"Saved failed extraction example to {fpath}\")\n\n#         result_entry = {\n#             \"problem_index\": idx,\n#             \"language\": language,\n#             \"chapter_number\": chapter_num,\n#             \"example_number\": example_num,\n#             \"question\": question,\n#             \"generated_answer\": generated_answer,\n#             \"thinking_content\": thinking_content,\n#             \"final_tag_output\": final_tag_output,\n#             \"extracted_final_answer\": extracted_final_answer,       # string (or JSON array string)\n#             \"extracted_final_answers\": extracted_final_answers,     # list (empty / single / many)\n#             \"exact_answer\": exact_answer,\n#             \"raw_answer_type\": raw_answer_type,\n#             \"canonical_answer_type\": canonical_type,\n#             \"evaluation_method\": problem.get(\"Evaluation Method\", \"\")\n#         }\n#         return result_entry\n\n#     def _create_error_entry(self, idx, problem, error_msg):\n#         return {\n#             \"problem_index\": idx,\n#             \"language\": problem.get(\"Language\", \"\"),\n#             \"chapter_number\": problem.get(\"Chapter Number\", \"\"),\n#             \"example_number\": problem.get(\"Example Number\", \"\"),\n#             \"question\": problem.get(\"Question\", \"\"),\n#             \"generated_answer\": f\"ERROR: {error_msg}\",\n#             \"thinking_content\": \"\",\n#             \"final_tag_output\": \"\",\n#             \"extracted_final_answer\": \"\",\n#             \"extracted_final_answers\": [],\n#             \"exact_answer\": problem.get(\"Exact Answer\", \"\"),\n#             \"raw_answer_type\": problem.get(\"Answer Type\", \"\"),\n#             \"canonical_answer_type\": \"\",\n#             \"evaluation_method\": problem.get(\"Evaluation Method\", \"\")\n#         }\n\n#     def _print_progress(self, idx, result_entry):\n#         print(f\"Generated answer length: {len(result_entry['generated_answer']) if result_entry['generated_answer'] else 0}\")\n#         print(f\"Extracted final answer: '{result_entry['extracted_final_answer']}'\")\n#         print(f\"Extracted final answers (list): {result_entry.get('extracted_final_answers', [])}\")\n#         print(f\"Expected answer: '{result_entry['exact_answer']}'\")\n\n#     def _save_intermediate_results(self, results, output_folder, count):\n#         temp_filename = f'intermediate_results_{count}.json'\n#         temp_output_path = os.path.join(output_folder, temp_filename)\n#         with open(temp_output_path, 'w', encoding='utf-8') as f:\n#             json.dump(results, f, ensure_ascii=False, indent=2)\n#         print(f\"Saved intermediate results to {temp_output_path}\")\n\n#     def _save_final_results(self, results, output_folder, start_idx, end_idx):\n#         final_filename = f'final_results_{start_idx}_to_{end_idx-1}.json'\n#         final_output_path = os.path.join(output_folder, final_filename)\n#         with open(final_output_path, 'w', encoding='utf-8') as f:\n#             json.dump(results, f, ensure_ascii=False, indent=2)\n#         print(f\"\\nProcessing complete. Results saved to {final_output_path}\")\n#         print(f\"Total problems processed: {len(results)}\")\n#         return final_output_path\n\n#     def _create_summary_file(self, results, output_folder, dataset_path, start_idx, end_idx):\n#         successful_extractions = len([r for r in results if r.get('extracted_final_answer', '').strip()])\n#         summary_data = {\n#             \"processing_info\": {\n#                 \"dataset_path\": dataset_path,\n#                 \"start_index\": start_idx,\n#                 \"end_index\": end_idx - 1,\n#                 \"total_processed\": len(results),\n#                 \"processing_timestamp\": datetime.now().isoformat(),\n#                 \"output_folder\": output_folder\n#             },\n#             \"statistics\": {\n#                 \"successful_problems\": len([r for r in results if not r['generated_answer'].startswith('ERROR:')]),\n#                 \"failed_problems\": len([r for r in results if r['generated_answer'].startswith('ERROR:')]),\n#                 \"successful_extractions\": successful_extractions,\n#                 \"extraction_success_rate\": f\"{(successful_extractions/len(results)*100):.1f}%\" if results else \"0%\",\n#                 \"average_answer_length\": sum(len(r['generated_answer']) for r in results) / len(results) if results else 0,\n#                 \"chapters_processed\": list(set(r['chapter_number'] for r in results if r['chapter_number'])),\n#                 \"raw_answer_types\": list(set(r['raw_answer_type'] for r in results if r.get('raw_answer_type'))),\n#                 \"canonical_answer_types\": list(set(r['canonical_answer_type'] for r in results if r.get('canonical_answer_type')))\n#             }\n#         }\n#         summary_path = os.path.join(output_folder, 'processing_summary.json')\n#         with open(summary_path, 'w', encoding='utf-8') as f:\n#             json.dump(summary_data, f, ensure_ascii=False, indent=2)\n#         print(f\"Processing summary saved to {summary_path}\")\n#         print(f\"Answer extraction success rate: {summary_data['statistics']['extraction_success_rate']}\")\n\n# # -------------------------\n# # Main (example usage)\n# # -------------------------\n# def main():\n#     # NOTE: update dataset_path and output_base_path to match your environment\n#     dataset_path = \"/kaggle/input/nctb-dataset/English_Final_Corpus.jsonl\"  # source format unchanged; questions are English\n#     output_base_path = \"/kaggle/working/\"\n\n#     # Use OllamaMathSolver (model reference must match a model available locally via Ollama)\n#     solver = OllamaMathSolver(model_name=\"mathstral:7b\")\n#     processor = DatasetProcessor(solver, failed_folder=os.path.join(output_base_path, \"failed_extractions\"))\n\n#     # For quick testing, process only first few problems\n#     results, out_folder = processor.process_dataset(\n#         dataset_path,\n#         output_base_path,\n#         start_idx=0,\n#         end_idx=10,\n#         two_pass=True\n#     )\n#     print(\"Done. Results saved to:\", out_folder)\n\n# if __name__ == \"__main__\":\n#     main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T02:20:14.891942Z","iopub.execute_input":"2025-09-05T02:20:14.892337Z","iopub.status.idle":"2025-09-05T02:20:14.913218Z","shell.execute_reply.started":"2025-09-05T02:20:14.892317Z","shell.execute_reply":"2025-09-05T02:20:14.912328Z"},"scrolled":true},"outputs":[],"execution_count":null}]}