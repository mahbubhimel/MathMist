{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Bangla**"
      ],
      "metadata": {
        "id": "0hETv3jSlxUS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "import re\n",
        "from datetime import datetime\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Ollama client\n",
        "try:\n",
        "    import ollama\n",
        "except Exception as e:\n",
        "    raise ImportError(\"The 'ollama' package is required. Install it and make sure the Ollama daemon is running.\") from e\n",
        "\n",
        "# -------------------------\n",
        "# Answer type normalization\n",
        "# -------------------------\n",
        "# Canonical set\n",
        "_CANONICAL_TYPES = {\"symbolic\", \"numerical\", \"proof\"}\n",
        "\n",
        "# mapping common noisy labels to canonical (English + Bengali variants)\n",
        "_ANSWER_TYPE_MAP_SIMPLE = {\n",
        "    # Proof variants (English -> Bengali)\n",
        "    \"proof\": \"proof\", \"prove\": \"proof\",\n",
        "    \"প্রমাণ\": \"proof\", \"প্রমাণ করুন\": \"proof\", \"প্রমাণ করা\": \"proof\", \"সিদ্ধ\": \"proof\", \"প্রমাণিত\": \"proof\",\n",
        "\n",
        "    # Numerical variants\n",
        "    \"numerical\": \"numerical\", \"numeric\": \"numerical\", \"number\": \"numerical\", \"calculation\": \"numerical\",\n",
        "    \"সংখ্যাগত\": \"numerical\", \"সংখ্যা\": \"numerical\", \"গণনা\": \"numerical\", \"হিসাব\": \"numerical\", \"মান\": \"numerical\", \"মানটিপান\": \"numerical\",\n",
        "\n",
        "    # Symbolic variants\n",
        "    \"symbolic\": \"symbolic\", \"symbol\": \"symbolic\", \"equation\": \"symbolic\", \"algebraic\": \"symbolic\",\n",
        "    \"চিহ্নাত্মক\": \"symbolic\", \"প্রতীকী\": \"symbolic\", \"সমীকরণ\": \"symbolic\", \"বীজগণিত\": \"symbolic\",\n",
        "}\n",
        "\n",
        "\n",
        "def normalize_answer_type(raw_label: str, question_text: str = \"\", exact_answer: str = \"\") -> str:\n",
        "    \"\"\"\n",
        "    Normalize a dataset label to one of: 'symbolic', 'numerical', 'proof'.\n",
        "    Heuristics expanded to handle Bengali (Bangla) phrases and labels (plus English).\n",
        "    \"\"\"\n",
        "    # Helper to clean label\n",
        "    def _clean_label(lbl: str) -> str:\n",
        "        if not lbl:\n",
        "            return \"\"\n",
        "        s = lbl.strip().lower()\n",
        "        # allow Bengali Unicode block and latin letters/digits\n",
        "        s = re.sub(r'[^0-9\\w\\s\\u0980-\\u09FF\\-]', ' ', s, flags=re.UNICODE)\n",
        "        s = re.sub(r'\\s+', ' ', s).strip()\n",
        "        return s\n",
        "\n",
        "    s = _clean_label(raw_label)\n",
        "\n",
        "    # direct mapping\n",
        "    if s in _ANSWER_TYPE_MAP_SIMPLE:\n",
        "        return _ANSWER_TYPE_MAP_SIMPLE[s]\n",
        "\n",
        "    # partial matches (allow English or Bengali keywords appearing)\n",
        "    for k, v in _ANSWER_TYPE_MAP_SIMPLE.items():\n",
        "        if k in s:\n",
        "            return v\n",
        "\n",
        "    # heuristics using question or exact_answer (both English & Bengali checks)\n",
        "    q = (question_text or \"\").lower()\n",
        "    a = (exact_answer or \"\").lower()\n",
        "\n",
        "    # Proof indicators (English + Bengali)\n",
        "    if re.search(r'\\b(prove|show that|prove that|proof)\\b', q) or re.search(r'\\b(প্রমাণ|সিদ্ধ|প্রমাণ করুন|প্রমাণ করা|দেখান)\\b', q, flags=re.IGNORECASE):\n",
        "        return \"proof\"\n",
        "\n",
        "    # logarithm related: English/Bengali\n",
        "    if re.search(r'\\b(log|ln|logarithm)\\b', q) or re.search(r'\\b(log|ln|লঘুগুণ|লগ|লগারিথম|লগারিথম)\\b', q) or re.search(r'\\blog\\b', a):\n",
        "        # prefer numerical if exact answer contains digits\n",
        "        if re.search(r'\\d', a):\n",
        "            return \"numerical\"\n",
        "        return \"symbolic\"\n",
        "\n",
        "    # set theory indicators: English / Bengali ('set' -> 'সেট' or 'জোট' sometimes)\n",
        "    if re.search(r'\\b(set|subset|union|intersection)\\b', q) or re.search(r'\\b(সেট|উপসেট|একীকরণ|ছেদ|ইন্টারসেকশন|ইউনিয়ন)\\b', q, flags=re.IGNORECASE):\n",
        "        return \"symbolic\"\n",
        "\n",
        "    # units (English + Bengali)\n",
        "    if re.search(r'\\bmeter\\b|\\bm\\b|\\bcm\\b|\\bkg\\b|\\bliter\\b|\\bl\\b|\\bkm\\b|\\bmile\\b', q + \" \" + a) or \\\n",
        "       re.search(r'\\bমিটার\\b|\\bমি\\b|\\bসেমি\\b|\\bকেজি\\b|\\blic\\b|\\bলিটার\\b|\\bকিমি\\b', q + \" \" + a, flags=re.IGNORECASE):\n",
        "        return \"numerical\"\n",
        "\n",
        "    # equation-solving heuristics (English + Bengali)\n",
        "    if re.search(r'\\bequation\\b|solve for|solve|= x|x\\s*=', q) or re.search(r'\\b(সমীকরণ|সমাধান|সমাধান করুন|হল|খুঁজুন)\\b', q, flags=re.IGNORECASE):\n",
        "        return \"symbolic\"\n",
        "\n",
        "    # trig / geometry indicators (English + Bengali)\n",
        "    if re.search(r'\\b(trig|sin|cos|tan|geometry|triangle|circle)\\b', q) or re.search(r'\\b(ট্রিগ|সাইন|কসাইন|ট্যান|জ্যামিতি|ত্রিভুজ|বৃত্ত|চক্র)\\b', q, flags=re.IGNORECASE):\n",
        "        if re.search(r'\\d', a):\n",
        "            return \"numerical\"\n",
        "        return \"symbolic\"\n",
        "\n",
        "    # numeric indicators (English + Bengali) -> numerical\n",
        "    if re.search(r'\\d', q) or re.search(r'find the value|compute|calculate|evaluate', q) or \\\n",
        "       re.search(r'মান বের|মানটি|মানটি বের|গণনা করুন|হিসাব করুন|পাওয়া', q, flags=re.IGNORECASE):\n",
        "        return \"numerical\"\n",
        "\n",
        "    # If exact_answer looks numeric, prefer numerical (but check for LaTeX)\n",
        "    if re.search(r'[0-9]|\\\\frac|\\\\sqrt', a):\n",
        "        if re.search(r'\\\\frac|\\\\sqrt|\\{|\\\\', a):\n",
        "            return \"symbolic\"\n",
        "        return \"numerical\"\n",
        "\n",
        "    # fallback\n",
        "    return \"symbolic\"\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# EnhancedAnswerExtractor (adapted to behave like SimplifiedAnswerExtractor)\n",
        "# and now handles Bengali markers as well\n",
        "# -------------------------\n",
        "class EnhancedAnswerExtractor:\n",
        "    \"\"\"\n",
        "    Adapter that implements the simplified extraction behavior,\n",
        "    extended to recognize Bengali (Bangla) formatting/conclusion words as well.\n",
        "    Provides:\n",
        "      - extract_final_answer(text) -> str\n",
        "      - extract_all_final_answers(generated_solution) -> list\n",
        "    and internal helpers _clean_answer and _is_valid_answer.\n",
        "    \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def _clean_answer(answer: str) -> str:\n",
        "        if not answer:\n",
        "            return \"\"\n",
        "        # Start with a trimmed answer and normalize whitespace\n",
        "        a = answer.strip()\n",
        "        # collapse whitespace\n",
        "        a = re.sub(r'\\s+', ' ', a)\n",
        "\n",
        "        # remove outer $$ if present (multiline)\n",
        "        a = re.sub(r'^\\$\\$(.*)\\$\\$$', r'\\1', a, flags=re.DOTALL)\n",
        "        # remove surrounding single $ if the whole string is wrapped\n",
        "        a = re.sub(r'^\\$(.*)\\$$', r'\\1', a, flags=re.DOTALL)\n",
        "\n",
        "        # strip standalone leading/trailing $ characters and spaces\n",
        "        a = a.strip('$ ')\n",
        "\n",
        "        # Remove common prefixes (kept after stripping $ to catch cases like \"$Final Answer: ...$\")\n",
        "        prefixes_to_remove = [\n",
        "            # English\n",
        "            r'Final Answer:\\s*', r'Answer:\\s*', r'The answer is\\s*',\n",
        "            r'Therefore,?\\s*', r'Thus,?\\s*', r'Hence,?\\s*', r'So,?\\s*', r'∴\\s*',\n",
        "\n",
        "            # Bengali\n",
        "            r'উত্তর[:\\s]*', r'ফল[:\\s]*', r'চূড়ান্ত উত্তর[:\\s]*', r'চূড়ান্ত[:\\s]*',\n",
        "            r'উত্তরটি[:]?\\s*', r'তাহলে[:\\s]*', r'অতএব[,]?\\s*', r'সুতরাং[,]?\\s*', r'তাই[,]?\\s*', r'উপসংহার[:\\s]*'\n",
        "        ]\n",
        "        for prefix in prefixes_to_remove:\n",
        "            a = re.sub(f'^{prefix}', '', a, flags=re.IGNORECASE)\n",
        "\n",
        "        # remove various boxed wrappers with optional backslashes and optional surrounding $\n",
        "        # e.g. $$\\boxed{...}$$, $\\boxed{...}$, \\boxed{...}\n",
        "        a = re.sub(r'\\$?\\s*(?:\\\\){0,3}boxed\\{([^}]*)\\}\\s*\\$?', r'\\1', a, flags=re.DOTALL | re.IGNORECASE)\n",
        "        # also ensure plain \\boxed{...} is unwrapped (redundant but safe)\n",
        "        a = re.sub(r'\\\\boxed\\{([^}]*)\\}', r'\\1', a)\n",
        "\n",
        "        # convert common LaTeX to readable forms\n",
        "        a = re.sub(r'\\\\frac\\{([^}]*)\\}\\{([^}]*)\\}', r'(\\1)/(\\2)', a)\n",
        "        a = re.sub(r'\\\\sqrt\\{([^}]*)\\}', r'√(\\1)', a)\n",
        "\n",
        "        # remove bold/italic wrappers\n",
        "        a = re.sub(r'\\*\\*([^*]+)\\*\\*', r'\\1', a)\n",
        "        a = re.sub(r'\\*([^*]+)\\*', r'\\1', a)\n",
        "\n",
        "        # collapse multiple spaces again (in case replacements introduced them)\n",
        "        a = re.sub(r'\\s+', ' ', a).strip()\n",
        "\n",
        "        # trim trailing punctuation/words\n",
        "        a = a.rstrip(' \\t\\n.,;:')\n",
        "\n",
        "        # remove trailing words like \"proved\" or \"the answer\" (English & Bengali)\n",
        "        a = re.sub(r'\\b(proved|completed|finished|the answer|প্রমাণিত|প্রমাণ|উত্তর|ফল)\\b[.\\s]*$', '', a, flags=re.IGNORECASE).strip()\n",
        "\n",
        "        return a\n",
        "\n",
        "    @staticmethod\n",
        "    def _is_valid_answer(answer: str) -> bool:\n",
        "        if not answer:\n",
        "            return False\n",
        "        # not only punctuation\n",
        "        if re.match(r'^[\\W_]+$', answer):\n",
        "            return False\n",
        "        # contains at least some alphanumeric characters (or common math symbols); include Bengali unicode range\n",
        "        if not re.search(r'[0-9A-Za-z\\u0980-\\u09FF\\\\]', answer):\n",
        "            return False\n",
        "        # length sanity\n",
        "        if len(answer) > 1000:\n",
        "            return False\n",
        "        # avoid answers that end with only concluding words (English & Bengali)\n",
        "        blacklist = [r'therefore$', r'thus$', r'hence$', r'so$', r'we get$', r'we have$', r'অতএব$', r'সুতরাং$', r'তাই$']\n",
        "        for b in blacklist:\n",
        "            if re.search(b, answer.strip(), flags=re.IGNORECASE):\n",
        "                return False\n",
        "        return True\n",
        "\n",
        "    @staticmethod\n",
        "    def extract_final_answer_simple(text: str) -> str:\n",
        "        \"\"\"\n",
        "        Primary method: Extract final answer using the last lines approach,\n",
        "        with fallback to pattern-based extraction.\n",
        "        \"\"\"\n",
        "        if not text:\n",
        "            return \"\"\n",
        "\n",
        "        # Clean the text and split into lines\n",
        "        lines = [line.strip() for line in text.strip().split('\\n') if line.strip()]\n",
        "\n",
        "        # Strategy 1: Try last two lines combined\n",
        "        if len(lines) >= 2:\n",
        "            last_two = ' '.join(lines[-2:])\n",
        "            cleaned = EnhancedAnswerExtractor._clean_answer(last_two)\n",
        "            if EnhancedAnswerExtractor._is_valid_answer(cleaned):\n",
        "                return cleaned\n",
        "\n",
        "        # Strategy 2: Try last line only\n",
        "        if lines:\n",
        "            cleaned = EnhancedAnswerExtractor._clean_answer(lines[-1])\n",
        "            if EnhancedAnswerExtractor._is_valid_answer(cleaned):\n",
        "                return cleaned\n",
        "\n",
        "        # Strategy 3: Try last 3 lines if we have them (sometimes answers span multiple lines)\n",
        "        if len(lines) >= 3:\n",
        "            last_three = ' '.join(lines[-3:])\n",
        "            cleaned = EnhancedAnswerExtractor._clean_answer(last_three)\n",
        "            if EnhancedAnswerExtractor._is_valid_answer(cleaned) and len(cleaned) < 500:\n",
        "                return cleaned\n",
        "\n",
        "        # Strategy 4: Fallback to pattern-based extraction\n",
        "        return EnhancedAnswerExtractor._extract_with_patterns(text)\n",
        "\n",
        "    @staticmethod\n",
        "    def _extract_with_patterns(text: str) -> str:\n",
        "        \"\"\"\n",
        "        Pattern-based extraction as fallback method.\n",
        "        Recognizes both English and Bengali answer/conclusion patterns.\n",
        "        \"\"\"\n",
        "        # Check for <final> tags\n",
        "        raw_matches = re.findall(r'<final>(.*?)</final>', text, re.DOTALL | re.IGNORECASE)\n",
        "        for m in raw_matches:\n",
        "            c = EnhancedAnswerExtractor._clean_answer(m)\n",
        "            if EnhancedAnswerExtractor._is_valid_answer(c):\n",
        "                return c\n",
        "\n",
        "        # Try common answer patterns (English + Bengali)\n",
        "        patterns = [\n",
        "            r'\\*\\*Final Answer:\\*\\*\\s*(.+?)(?:\\n|$)',\n",
        "            r'Final Answer:\\s*(.+?)(?:\\n|$)',\n",
        "            r'Final Answer\\s*[:\\-]\\s*(.+?)(?:\\n|$)',\n",
        "\n",
        "            # Bengali patterns\n",
        "            r'\\*\\*উত্তর:\\*\\*\\s*(.+?)(?:\\n|$)',\n",
        "            r'উত্তর[:\\s]*(.+?)(?:\\n|$)',\n",
        "            r'ফল[:\\s]*(.+?)(?:\\n|$)',\n",
        "            r'চূড়ান্ত উত্তর[:\\s]*(.+?)(?:\\n|$)',\n",
        "            r'উপসংহার[:\\s]*(.+?)(?:\\n|$)',\n",
        "\n",
        "            # English conclusion markers\n",
        "            r'Therefore[,:\\s]*(.+?)(?:\\.|$|\\n)',\n",
        "            r'Hence[,:\\s]*(.+?)(?:\\.|$|\\n)',\n",
        "            r'Thus[,:\\s]*(.+?)(?:\\.|$|\\n)',\n",
        "            r'∴\\s*(.+?)(?:\\.|$|\\n)',\n",
        "\n",
        "            # Bengali conclusion markers\n",
        "            r'অতএব[,:\\s]*(.+?)(?:\\.|$|\\n)',\n",
        "            r'সুতরাং[,:\\s]*(.+?)(?:\\.|$|\\n)',\n",
        "            r'তাই[,:\\s]*(.+?)(?:\\.|$|\\n)',\n",
        "            r'উপসংহার[,:\\s]*(.+?)(?:\\.|$|\\n)',\n",
        "\n",
        "            r'Answer[:\\s]*(.+?)(?:\\n|$)',\n",
        "            r'Result[:\\s]*(.+?)(?:\\n|$)',\n",
        "            r'Solution[:\\s]*(.+?)(?:\\n|$)',\n",
        "        ]\n",
        "\n",
        "        for pat in patterns:\n",
        "            matches = re.findall(pat, text, re.MULTILINE | re.DOTALL | re.IGNORECASE)\n",
        "            if matches:\n",
        "                answer = matches[-1].strip()\n",
        "                cleaned = EnhancedAnswerExtractor._clean_answer(answer)\n",
        "                if EnhancedAnswerExtractor._is_valid_answer(cleaned):\n",
        "                    return cleaned\n",
        "\n",
        "        # Try boxed math expressions (LaTeX boxed)\n",
        "        boxed_patterns = [\n",
        "            r'\\$\\$\\s*(?:\\\\){0,3}boxed\\{(.+?)\\}\\s*\\$\\$',\n",
        "            r'\\$\\s*(?:\\\\){0,3}boxed\\{(.+?)\\}\\s*\\$',\n",
        "            r'(?:\\\\){0,3}boxed\\{(.+?)\\}',\n",
        "        ]\n",
        "\n",
        "        for pat in boxed_patterns:\n",
        "            m = re.search(pat, text, re.DOTALL | re.IGNORECASE)\n",
        "            if m:\n",
        "                cand = EnhancedAnswerExtractor._clean_answer(m.group(1))\n",
        "                if EnhancedAnswerExtractor._is_valid_answer(cand):\n",
        "                    return cand\n",
        "\n",
        "        return \"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def extract_all_final_answers(generated_solution: str) -> list:\n",
        "        \"\"\"\n",
        "        Extract multiple final answers using simplified approach.\n",
        "        Returns a list (possibly empty) of cleaned answers found inside all <final>...</final> tags.\n",
        "        Falls back to the single simplified extraction if no tags are found.\n",
        "        \"\"\"\n",
        "        if not generated_solution:\n",
        "            return []\n",
        "\n",
        "        # Find all <final>...</final> (non-greedy)\n",
        "        raw_matches = re.findall(r'<final>(.*?)</final>', generated_solution, re.DOTALL | re.IGNORECASE)\n",
        "        cleaned = []\n",
        "        for m in raw_matches:\n",
        "            c = EnhancedAnswerExtractor._clean_answer(m)\n",
        "            if EnhancedAnswerExtractor._is_valid_answer(c):\n",
        "                cleaned.append(c)\n",
        "\n",
        "        if cleaned:\n",
        "            return cleaned\n",
        "\n",
        "        # Fallback: try to extract a single final using the simpler logic\n",
        "        simple_answer = EnhancedAnswerExtractor.extract_final_answer_simple(generated_solution)\n",
        "        if simple_answer:\n",
        "            return [simple_answer]\n",
        "\n",
        "        return []\n",
        "\n",
        "    @staticmethod\n",
        "    def extract_final_answer(generated_solution: str) -> str:\n",
        "        \"\"\"\n",
        "        Backwards-compatible extractor that delegates to the simplified extraction.\n",
        "        If multiple <final> tags exist, returns a JSON array string of cleaned answers.\n",
        "        \"\"\"\n",
        "        if not generated_solution:\n",
        "            return \"\"\n",
        "\n",
        "        # Prefer explicit <final> tags (can be multiple)\n",
        "        raw_matches = re.findall(r'<final>(.*?)</final>', generated_solution, re.DOTALL | re.IGNORECASE)\n",
        "        if raw_matches:\n",
        "            cleaned = []\n",
        "            for m in raw_matches:\n",
        "                c = EnhancedAnswerExtractor._clean_answer(m)\n",
        "                if EnhancedAnswerExtractor._is_valid_answer(c):\n",
        "                    cleaned.append(c)\n",
        "            if not cleaned:\n",
        "                # fall through to simpler single extraction\n",
        "                return EnhancedAnswerExtractor.extract_final_answer_simple(generated_solution)\n",
        "            if len(cleaned) == 1:\n",
        "                return cleaned[0]\n",
        "            try:\n",
        "                return json.dumps(cleaned, ensure_ascii=False)\n",
        "            except Exception:\n",
        "                return \" ||| \".join(cleaned)\n",
        "\n",
        "        # No explicit finals: use simplified single extraction\n",
        "        return EnhancedAnswerExtractor.extract_final_answer_simple(generated_solution)\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# Ollama-based Math Solver (ZERO-SHOT) — PROMPTS IN ENGLISH (problem is Bengali)\n",
        "# -------------------------\n",
        "class OllamaZeroShotMathSolver:\n",
        "    \"\"\"\n",
        "    Zero-shot math solver that uses the Ollama daemon via the Python client.\n",
        "    Prompts/instructions are written in English (as requested), but the solver is informed that\n",
        "    the problem text will be in BENGALI (Bangla) and is instructed to provide a concise final answer in BENGALI.\n",
        "    - Zero-shot prompt: forbids chain-of-thought and requests concise final <final> tag\n",
        "    - Single-pass only.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model_name=\"qwen3:8b\"):\n",
        "        \"\"\"\n",
        "        model_name: the Ollama model reference (e.g., \"qwen3:8b\")\n",
        "        \"\"\"\n",
        "        self.model_name = model_name\n",
        "        self.client = self._load_client()\n",
        "\n",
        "    def _load_client(self):\n",
        "        print(f\"Initializing Ollama client for model: {self.model_name}\")\n",
        "        client = ollama.Client()\n",
        "        return client\n",
        "\n",
        "    def cleanup(self):\n",
        "        if hasattr(self, 'client'):\n",
        "            del self.client\n",
        "\n",
        "    def _get_format_instructions(self, answer_type):\n",
        "        \"\"\"\n",
        "        Zero-shot formatting instructions (WRITTEN IN ENGLISH).\n",
        "        The model is explicitly informed that the problem text is in BENGALI and that the concise final\n",
        "        answer should be provided in BENGALI. Examples/formats are shown in English but demonstrate\n",
        "        that the final tag must contain the concise Bengali answer.\n",
        "        \"\"\"\n",
        "        t = (answer_type or \"symbolic\").strip().lower()\n",
        "        if t not in _CANONICAL_TYPES:\n",
        "            t = \"symbolic\"\n",
        "\n",
        "        base = (\n",
        "            \"CRITICAL FORMATTING REQUIREMENTS (ZERO-SHOT):\\n\"\n",
        "            \"- The math problem you will receive is written in BENGALI (Bangla). Provide your concise FINAL ANSWER in BENGALI.\\n\"\n",
        "            \"- DO NOT provide chain-of-thought or step-by-step internal reasoning. Do NOT reveal private chain-of-thought.\\n\"\n",
        "            \"- If a very short justification is necessary, include a single-line 'Explanation:' with at most one sentence (in Bengali).\\n\"\n",
        "            \"- Always end with a machine-readable final tag <final>...</final> containing ONLY the concise final answer in BENGALI (no extra reasoning inside the tag).\\n\"\n",
        "        )\n",
        "\n",
        "        if t == \"proof\":\n",
        "            return base + (\n",
        "                \"FOR PROOFS (zero-shot):\\n\"\n",
        "                \"- Provide a concise conclusion or a one-sentence proof sketch (in BENGALI) labeled 'উপসংহার:' or 'প্রমাণ সংক্ষেপ:' if needed. Do NOT provide a full step-by-step proof.\\n\"\n",
        "                \"Format example (English instructions):\\n\"\n",
        "                \"Final Answer (in Bengali):\\n\"\n",
        "                \"[Concise Bengali conclusion or one-sentence sketch]\\n\\n\"\n",
        "                \"<final>[Concise Bengali conclusion]</final>\\n\"\n",
        "            )\n",
        "        elif t == \"numerical\":\n",
        "            return base + (\n",
        "                \"FOR NUMERICAL RESULTS:\\n\"\n",
        "                \"- Provide the numeric result in exact form if available (fractions/radicals). Otherwise provide a decimal rounded to 4 decimal places.\\n\"\n",
        "                \"Format example (English instructions):\\n\"\n",
        "                \"Final Answer (in Bengali):\\n\"\n",
        "                \"[Numeric result]\\n\\n\"\n",
        "                \"<final>[Numeric result]</final>\\n\"\n",
        "            )\n",
        "        else:  # symbolic\n",
        "            return base + (\n",
        "                \"FOR SYMBOLIC RESULTS:\\n\"\n",
        "                \"- Provide the final symbolic expression (LaTeX allowed) in a concise form. The expression may be LaTeX but any wording should be in Bengali if used.\\n\"\n",
        "                \"Format example (English instructions):\\n\"\n",
        "                \"Final Answer (in Bengali):\\n\"\n",
        "                \"[Final symbolic expression]\\n\\n\"\n",
        "                \"<final>[LaTeX expression or concise symbolic expression — in Bengali if words are used]</final>\\n\"\n",
        "            )\n",
        "\n",
        "    def _create_prompt(self, question, answer_type=\"symbolic\"):\n",
        "        format_instructions = self._get_format_instructions(answer_type)\n",
        "\n",
        "        # The main instruction is in English (per your requirement), but it states the problem language and required answer language.\n",
        "        prompt = f\"\"\"You are an expert mathematician. The following math problem is written in BENGALI (Bangla).\n",
        "Provide a concise final answer in BENGALI. DO NOT produce chain-of-thought or step-by-step internal reasoning.\n",
        "If you include a justification, it must be one short sentence and labeled 'Explanation:' (in Bengali).\n",
        "\n",
        "MATH PROBLEM (in Bengali):\n",
        "{question}\n",
        "\n",
        "{format_instructions}\n",
        "\n",
        "Begin your concise answer (in Bengali) now:\n",
        "\"\"\"\n",
        "        return prompt\n",
        "\n",
        "    def _generate_once(self, prompt_text: str, enable_thinking: bool = False) -> str:\n",
        "        \"\"\"\n",
        "        Call ollama.Client.chat WITHOUT temperature/max_tokens.\n",
        "        Handles several possible response shapes.\n",
        "        \"\"\"\n",
        "        messages = [{\"role\": \"user\", \"content\": prompt_text}]\n",
        "\n",
        "        # Call Ollama client.chat without temperature/max_tokens\n",
        "        try:\n",
        "            resp = self.client.chat(model=self.model_name, messages=messages, think=enable_thinking)\n",
        "        except TypeError:\n",
        "            # Some client versions have different signatures\n",
        "            try:\n",
        "                resp = self.client.chat(self.model_name, messages=messages, think=enable_thinking)\n",
        "            except Exception:\n",
        "                resp = self.client.chat(self.model_name, messages)\n",
        "\n",
        "        # Normalize response into a string\n",
        "        full_output = \"\"\n",
        "        if isinstance(resp, dict):\n",
        "            if 'message' in resp and isinstance(resp['message'], dict) and 'content' in resp['message']:\n",
        "                full_output = resp['message']['content']\n",
        "            elif 'choices' in resp and isinstance(resp['choices'], (list, tuple)) and resp['choices']:\n",
        "                choice = resp['choices'][0]\n",
        "                if isinstance(choice, dict) and 'message' in choice and isinstance(choice['message'], dict):\n",
        "                    full_output = choice['message'].get('content', '')\n",
        "                else:\n",
        "                    full_output = str(choice)\n",
        "            else:\n",
        "                full_output = str(resp)\n",
        "        else:\n",
        "            # resp might be an object with .message.content\n",
        "            try:\n",
        "                full_output = resp.message.content\n",
        "            except Exception:\n",
        "                full_output = str(resp)\n",
        "\n",
        "        if isinstance(full_output, bytes):\n",
        "            full_output = full_output.decode('utf-8', errors='ignore')\n",
        "        return (full_output or \"\").strip()\n",
        "\n",
        "    def solve_problem(self, question, answer_type=\"symbolic\"):\n",
        "        \"\"\"\n",
        "        Zero-shot single-pass solve via Ollama.\n",
        "        \"\"\"\n",
        "        prompt = self._create_prompt(question, answer_type)\n",
        "        full_output = self._generate_once(prompt, enable_thinking=False)\n",
        "\n",
        "        # No thinking parsing for zero-shot mode\n",
        "        thinking_content = \"\"\n",
        "        generated_answer = full_output\n",
        "        final_tag_output = \"\"  # no second pass\n",
        "\n",
        "        extracted_final_answer = EnhancedAnswerExtractor.extract_final_answer(generated_answer)\n",
        "\n",
        "        return {\n",
        "            \"thinking_content\": thinking_content,\n",
        "            \"generated_answer\": generated_answer,\n",
        "            \"final_tag_output\": final_tag_output,\n",
        "            \"extracted_final_answer\": extracted_final_answer\n",
        "        }\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# Dataset Processor\n",
        "# -------------------------\n",
        "class DatasetProcessor:\n",
        "    def __init__(self, solver: OllamaZeroShotMathSolver, failed_folder=None):\n",
        "        self.solver = solver\n",
        "        self.extractor = EnhancedAnswerExtractor()\n",
        "        self.failed_folder = failed_folder or \"failed_extractions\"\n",
        "        os.makedirs(self.failed_folder, exist_ok=True)\n",
        "\n",
        "    def process_dataset(self, dataset_path, output_base_path, start_idx=0, end_idx=None,\n",
        "                        folder_name=None, create_timestamped_folder=True):\n",
        "        dataset = self._load_dataset(dataset_path)\n",
        "        if end_idx is None:\n",
        "            end_idx = len(dataset)\n",
        "\n",
        "        output_folder = self._create_output_folder(output_base_path, folder_name, start_idx, end_idx, create_timestamped_folder)\n",
        "        results = []\n",
        "\n",
        "        print(f\"Processing problems {start_idx} to {end_idx-1} ({end_idx-start_idx} total)\")\n",
        "        print(f\"Output will be saved in: {output_folder}\")\n",
        "\n",
        "        for idx in tqdm(range(start_idx, min(end_idx, len(dataset)))):\n",
        "            problem = dataset[idx]\n",
        "            try:\n",
        "                result_entry = self._process_single_problem(idx, problem)\n",
        "                results.append(result_entry)\n",
        "                self._print_progress(idx, result_entry)\n",
        "                if (idx - start_idx + 1) % 10 == 0:\n",
        "                    self._save_intermediate_results(results, output_folder, idx - start_idx + 1)\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing problem {idx+1}: {str(e)}\")\n",
        "                error_entry = self._create_error_entry(idx, problem, str(e))\n",
        "                results.append(error_entry)\n",
        "\n",
        "        final_output_path = self._save_final_results(results, output_folder, start_idx, end_idx)\n",
        "        self._create_summary_file(results, output_folder, dataset_path, start_idx, end_idx)\n",
        "        return results, output_folder\n",
        "\n",
        "    def _create_output_folder(self, base_path, folder_name, start_idx, end_idx, add_timestamp):\n",
        "        if folder_name is None:\n",
        "            folder_name = f\"results_{start_idx}_to_{end_idx-1}\"\n",
        "        if add_timestamp:\n",
        "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "            folder_name = f\"{folder_name}_{timestamp}\"\n",
        "        output_folder = os.path.join(base_path, folder_name)\n",
        "        os.makedirs(output_folder, exist_ok=True)\n",
        "        return output_folder\n",
        "\n",
        "    def _load_dataset(self, dataset_path):\n",
        "        dataset = []\n",
        "        with open(dataset_path, 'r', encoding='utf-8') as f:\n",
        "            for line in f:\n",
        "                if line.strip():\n",
        "                    dataset.append(json.loads(line))\n",
        "        return dataset\n",
        "\n",
        "    def _process_single_problem(self, idx, problem):\n",
        "        language = problem.get(\"Language\", \"\")\n",
        "        chapter_num = problem.get(\"Chapter Number\", \"\")\n",
        "        example_num = problem.get(\"Example Number\", \"\")\n",
        "        question = problem.get(\"Question\", \"\")\n",
        "        exact_answer = problem.get(\"Exact Answer\", \"\")\n",
        "        raw_answer_type = problem.get(\"Answer Type\", \"\") or \"\"\n",
        "\n",
        "        # Normalize/infer canonical answer type: 'symbolic', 'numerical', 'proof'\n",
        "        canonical_type = normalize_answer_type(raw_answer_type, question_text=question, exact_answer=exact_answer)\n",
        "\n",
        "        # If exact_answer strongly indicates numeric, prefer numerical\n",
        "        if exact_answer and re.search(r'\\d', str(exact_answer)):\n",
        "            # if exact contains LaTeX expressions like \\frac or \\sqrt, keep symbolic\n",
        "            if re.search(r'\\\\frac|\\\\sqrt|\\\\boxed', str(exact_answer)):\n",
        "                pass\n",
        "            else:\n",
        "                canonical_type = \"numerical\"\n",
        "\n",
        "        print(f\"\\nProcessing Problem {idx+1}: Chapter {chapter_num}, Example {example_num}\")\n",
        "        print(f\"Raw Answer Type: '{raw_answer_type}'  --> canonical: '{canonical_type}'\")\n",
        "\n",
        "        # Generate solution (use canonical_type) -- zero-shot, single pass\n",
        "        solution_result = self.solver.solve_problem(question, answer_type=canonical_type)\n",
        "        generated_answer = solution_result.get('generated_answer', '')\n",
        "        thinking_content = solution_result.get('thinking_content', '')  # will be empty\n",
        "        final_tag_output = solution_result.get('final_tag_output', '')\n",
        "\n",
        "        # --- NEW extraction logic: keep both forms (single string & list) ---\n",
        "        # Try to get all <final> answers first (preferred)\n",
        "        all_finals = EnhancedAnswerExtractor.extract_all_final_answers(generated_answer)\n",
        "        extracted_final_answer = \"\"\n",
        "        extracted_final_answers = []\n",
        "\n",
        "        # If none found in generated_answer, try final_tag_output (unused here)\n",
        "        if not all_finals and final_tag_output:\n",
        "            all_finals = EnhancedAnswerExtractor.extract_all_final_answers(final_tag_output)\n",
        "\n",
        "        # If still none, fall back to single-answer extractor\n",
        "        if not all_finals:\n",
        "            single = EnhancedAnswerExtractor.extract_final_answer(generated_answer)\n",
        "            if single:\n",
        "                extracted_final_answer = single\n",
        "                extracted_final_answers = [single]\n",
        "            else:\n",
        "                # try whole combined text (thinking + generated + final_tag)\n",
        "                combined = \"\\n\".join([thinking_content or \"\", generated_answer or \"\", final_tag_output or \"\"])\n",
        "                single = EnhancedAnswerExtractor.extract_final_answer(combined)\n",
        "                if single:\n",
        "                    extracted_final_answer = single\n",
        "                    extracted_final_answers = [single]\n",
        "                else:\n",
        "                    extracted_final_answer = \"\"\n",
        "                    extracted_final_answers = []\n",
        "        else:\n",
        "            # we have one or more finals\n",
        "            extracted_final_answers = all_finals\n",
        "            if len(all_finals) == 1:\n",
        "                extracted_final_answer = all_finals[0]\n",
        "            else:\n",
        "                # store a machine-readable concatenation: JSON array string\n",
        "                try:\n",
        "                    extracted_final_answer = json.dumps(all_finals, ensure_ascii=False)\n",
        "                except Exception:\n",
        "                    extracted_final_answer = \" ||| \".join(all_finals)\n",
        "\n",
        "        # If still empty, save a failed extraction example for inspection\n",
        "        if not extracted_final_answer:\n",
        "            fname = f\"failed_{idx}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
        "            fpath = os.path.join(self.failed_folder, fname)\n",
        "            with open(fpath, 'w', encoding='utf-8') as f:\n",
        "                json.dump({\n",
        "                    \"index\": idx,\n",
        "                    \"question\": question,\n",
        "                    \"generated_answer\": generated_answer,\n",
        "                    \"thinking_content\": thinking_content,\n",
        "                    \"final_tag_output\": final_tag_output,\n",
        "                    \"exact_answer\": exact_answer,\n",
        "                    \"canonical_type\": canonical_type,\n",
        "                    \"extracted_final_answer\": extracted_final_answer,\n",
        "                    \"extracted_final_answers\": extracted_final_answers\n",
        "                }, f, ensure_ascii=False, indent=2)\n",
        "            print(f\"Saved failed extraction example to {fpath}\")\n",
        "\n",
        "        result_entry = {\n",
        "            \"problem_index\": idx,\n",
        "            \"language\": language,\n",
        "            \"chapter_number\": chapter_num,\n",
        "            \"example_number\": example_num,\n",
        "            \"question\": question,\n",
        "            \"generated_answer\": generated_answer,\n",
        "            \"thinking_content\": thinking_content,\n",
        "            \"final_tag_output\": final_tag_output,\n",
        "            \"extracted_final_answer\": extracted_final_answer,       # string (or JSON array string)\n",
        "            \"extracted_final_answers\": extracted_final_answers,     # list (empty / single / many)\n",
        "            \"exact_answer\": exact_answer,\n",
        "            \"raw_answer_type\": raw_answer_type,\n",
        "            \"canonical_answer_type\": canonical_type,\n",
        "            \"evaluation_method\": problem.get(\"Evaluation Method\", \"\")\n",
        "        }\n",
        "        return result_entry\n",
        "\n",
        "    def _create_error_entry(self, idx, problem, error_msg):\n",
        "        return {\n",
        "            \"problem_index\": idx,\n",
        "            \"language\": problem.get(\"Language\", \"\"),\n",
        "            \"chapter_number\": problem.get(\"Chapter Number\", \"\"),\n",
        "            \"example_number\": problem.get(\"Example Number\", \"\"),\n",
        "            \"question\": problem.get(\"Question\", \"\"),\n",
        "            \"generated_answer\": f\"ERROR: {error_msg}\",\n",
        "            \"thinking_content\": \"\",\n",
        "            \"final_tag_output\": \"\",\n",
        "            \"extracted_final_answer\": \"\",\n",
        "            \"extracted_final_answers\": [],\n",
        "            \"exact_answer\": problem.get(\"Exact Answer\", \"\"),\n",
        "            \"raw_answer_type\": problem.get(\"Answer Type\", \"\"),\n",
        "            \"canonical_answer_type\": \"\",\n",
        "            \"evaluation_method\": problem.get(\"Evaluation Method\", \"\")\n",
        "        }\n",
        "\n",
        "    def _print_progress(self, idx, result_entry):\n",
        "        print(f\"Generated answer length: {len(result_entry['generated_answer']) if result_entry['generated_answer'] else 0}\")\n",
        "        print(f\"Extracted final answer: '{result_entry['extracted_final_answer']}'\")\n",
        "        print(f\"Extracted final answers (list): {result_entry.get('extracted_final_answers', [])}\")\n",
        "        print(f\"Expected answer: '{result_entry['exact_answer']}'\")\n",
        "\n",
        "    def _save_intermediate_results(self, results, output_folder, count):\n",
        "        temp_filename = f'intermediate_results_{count}.json'\n",
        "        temp_output_path = os.path.join(output_folder, temp_filename)\n",
        "        with open(temp_output_path, 'w', encoding='utf-8') as f:\n",
        "            json.dump(results, f, ensure_ascii=False, indent=2)\n",
        "        print(f\"Saved intermediate results to {temp_output_path}\")\n",
        "\n",
        "    def _save_final_results(self, results, output_folder, start_idx, end_idx):\n",
        "        final_filename = f'final_results_{start_idx}_to_{end_idx-1}.json'\n",
        "        final_output_path = os.path.join(output_folder, final_filename)\n",
        "        with open(final_output_path, 'w', encoding='utf-8') as f:\n",
        "            json.dump(results, f, ensure_ascii=False, indent=2)\n",
        "        print(f\"\\nProcessing complete. Results saved to {final_output_path}\")\n",
        "        print(f\"Total problems processed: {len(results)}\")\n",
        "        return final_output_path\n",
        "\n",
        "    def _create_summary_file(self, results, output_folder, dataset_path, start_idx, end_idx):\n",
        "        successful_extractions = len([r for r in results if r.get('extracted_final_answer', '').strip()])\n",
        "        summary_data = {\n",
        "            \"processing_info\": {\n",
        "                \"dataset_path\": dataset_path,\n",
        "                \"start_index\": start_idx,\n",
        "                \"end_index\": end_idx - 1,\n",
        "                \"total_processed\": len(results),\n",
        "                \"processing_timestamp\": datetime.now().isoformat(),\n",
        "                \"output_folder\": output_folder\n",
        "            },\n",
        "            \"statistics\": {\n",
        "                \"successful_problems\": len([r for r in results if not r['generated_answer'].startswith('ERROR:')]),\n",
        "                \"failed_problems\": len([r for r in results if r['generated_answer'].startswith('ERROR:')]),\n",
        "                \"successful_extractions\": successful_extractions,\n",
        "                \"extraction_success_rate\": f\"{(successful_extractions/len(results)*100):.1f}%\" if results else \"0%\",\n",
        "                \"average_answer_length\": sum(len(r['generated_answer']) for r in results) / len(results) if results else 0,\n",
        "                \"chapters_processed\": list(set(r['chapter_number'] for r in results if r['chapter_number'])),\n",
        "                \"raw_answer_types\": list(set(r['raw_answer_type'] for r in results if r.get('raw_answer_type'))),\n",
        "                \"canonical_answer_types\": list(set(r['canonical_answer_type'] for r in results if r.get('canonical_answer_type')))\n",
        "            }\n",
        "        }\n",
        "        summary_path = os.path.join(output_folder, 'processing_summary.json')\n",
        "        with open(summary_path, 'w', encoding='utf-8') as f:\n",
        "            json.dump(summary_data, f, ensure_ascii=False, indent=2)\n",
        "        print(f\"Processing summary saved to {summary_path}\")\n",
        "        print(f\"Answer extraction success rate: {summary_data['statistics']['extraction_success_rate']}\")\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# Main (example usage)\n",
        "# -------------------------\n",
        "def main():\n",
        "    # NOTE: update dataset_path and output_base_path to match your environment.\n",
        "    # Ensure your dataset's \"Question\" fields are in Bengali (Bangla).\n",
        "    dataset_path = \"/kaggle/input/nctb-dataset/Bengali_Final_Corpus.jsonl\"\n",
        "    output_base_path = \"/kaggle/working/\"\n",
        "\n",
        "    # Use the Ollama zero-shot solver (ensure the specified model is available in Ollama)\n",
        "    solver = OllamaZeroShotMathSolver(model_name=\"qwen3:8b\")\n",
        "    processor = DatasetProcessor(solver, failed_folder=os.path.join(output_base_path, \"failed_extractions\"))\n",
        "\n",
        "    # For quick testing, process only first few problems\n",
        "    results, out_folder = processor.process_dataset(\n",
        "        dataset_path,\n",
        "        output_base_path,\n",
        "        start_idx=0,\n",
        "        end_idx=100  # smaller quick test\n",
        "    )\n",
        "    print(\"Done. Results saved to:\", out_folder)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "V6imjWEylwFf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **English**"
      ],
      "metadata": {
        "id": "0D1GFxCPhF5U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "import re\n",
        "from datetime import datetime\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Ollama client\n",
        "try:\n",
        "    import ollama\n",
        "except Exception as e:\n",
        "    raise ImportError(\"The 'ollama' package is required. Install it and make sure the Ollama daemon is running.\") from e\n",
        "\n",
        "# -------------------------\n",
        "# Answer type normalization\n",
        "# -------------------------\n",
        "# Canonical set\n",
        "_CANONICAL_TYPES = {\"symbolic\", \"numerical\", \"proof\"}\n",
        "\n",
        "# mapping common noisy labels to canonical\n",
        "_ANSWER_TYPE_MAP_SIMPLE = {\n",
        "    # Proof variants\n",
        "    \"proof\": \"proof\", \"prove\": \"proof\",\n",
        "    # Numerical variants\n",
        "    \"numerical\": \"numerical\", \"numeric\": \"numerical\", \"number\": \"numerical\", \"calculation\": \"numerical\",\n",
        "    # Symbolic variants\n",
        "    \"symbolic\": \"symbolic\", \"symbol\": \"symbolic\", \"equation\": \"symbolic\", \"algebraic\": \"symbolic\",\n",
        "}\n",
        "\n",
        "\n",
        "def normalize_answer_type(raw_label: str, question_text: str = \"\", exact_answer: str = \"\") -> str:\n",
        "    \"\"\"\n",
        "    Normalize a dataset label to one of: 'symbolic', 'numerical', 'proof'.\n",
        "    Heuristics:\n",
        "      - Direct mapping from known strings (English)\n",
        "      - If dataset field missing or noisy, infer from question or exact_answer\n",
        "      - Final fallback: 'symbolic'\n",
        "    \"\"\"\n",
        "    # Helper to clean label\n",
        "    def _clean_label(lbl: str) -> str:\n",
        "        if not lbl:\n",
        "            return \"\"\n",
        "        s = lbl.strip().lower()\n",
        "        s = re.sub(r'[^0-9a-z\\s]', ' ', s)\n",
        "        s = re.sub(r'\\s+', ' ', s).strip()\n",
        "        return s\n",
        "\n",
        "    s = _clean_label(raw_label)\n",
        "\n",
        "    # direct mapping\n",
        "    if s in _ANSWER_TYPE_MAP_SIMPLE:\n",
        "        return _ANSWER_TYPE_MAP_SIMPLE[s]\n",
        "\n",
        "    # partial matches\n",
        "    for k, v in _ANSWER_TYPE_MAP_SIMPLE.items():\n",
        "        if k in s:\n",
        "            return v\n",
        "\n",
        "    # heuristics using question or exact_answer\n",
        "    q = (question_text or \"\").lower()\n",
        "    a = (exact_answer or \"\").lower()\n",
        "\n",
        "    if re.search(r'prove|show that|prove that', q) or 'proof' in s:\n",
        "        return \"proof\"\n",
        "\n",
        "    if re.search(r'\\b(log|ln|logarithm)\\b', q) or re.search(r'\\blog\\b', a):\n",
        "        # default to symbolic but prefer numerical if exact answer contains digits\n",
        "        if re.search(r'\\d', a):\n",
        "            return \"numerical\"\n",
        "        return \"symbolic\"\n",
        "\n",
        "    if re.search(r'set|subset|\\bunion\\b|\\bintersection\\b', q):\n",
        "        return \"symbolic\"\n",
        "\n",
        "    if re.search(r'meter|m\\b|cm|kg|liter|l\\b|unit|units|km|mile', q + \" \" + a):\n",
        "        return \"numerical\"\n",
        "\n",
        "    # equation-solving heuristics\n",
        "    if re.search(r'equation|solve for|solve|= x|x\\s*=', q) or re.search(r'= x|= \\d', a):\n",
        "        return \"symbolic\"\n",
        "\n",
        "    if re.search(r'trig|sin|cos|tan|geometry|triangle|circle', q):\n",
        "        if re.search(r'\\d', a):\n",
        "            return \"numerical\"\n",
        "        return \"symbolic\"\n",
        "\n",
        "    # numeric indicators -> numerical\n",
        "    if re.search(r'\\d', q) or re.search(r'find the value|compute|calculate|evaluate', q):\n",
        "        return \"numerical\"\n",
        "\n",
        "    # If exact_answer looks numeric, prefer numerical\n",
        "    if re.search(r'[0-9]|\\\\frac|\\\\sqrt', a):\n",
        "        if re.search(r'\\\\frac|\\\\sqrt|\\{|\\\\', a):\n",
        "            return \"symbolic\"\n",
        "        return \"numerical\"\n",
        "\n",
        "    # fallback\n",
        "    return \"symbolic\"\n",
        "\n",
        "# -------------------------\n",
        "# EnhancedAnswerExtractor (adapted to behave like SimplifiedAnswerExtractor)\n",
        "# -------------------------\n",
        "class EnhancedAnswerExtractor:\n",
        "    \"\"\"\n",
        "    Adapter that implements the simplified extraction behavior (ported from SimplifiedAnswerExtractor).\n",
        "    Provides:\n",
        "      - extract_final_answer(text) -> str\n",
        "      - extract_all_final_answers(generated_solution) -> list\n",
        "    and internal helpers _clean_answer and _is_valid_answer.\n",
        "    \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def _clean_answer(answer: str) -> str:\n",
        "        if not answer:\n",
        "            return \"\"\n",
        "        # Start with a trimmed answer and normalize whitespace\n",
        "        a = answer.strip()\n",
        "        # collapse whitespace\n",
        "        a = re.sub(r'\\s+', ' ', a)\n",
        "\n",
        "        # remove outer $$ if present (multiline)\n",
        "        a = re.sub(r'^\\$\\$(.*)\\$\\$$', r'\\1', a, flags=re.DOTALL)\n",
        "        # remove surrounding single $ if the whole string is wrapped\n",
        "        a = re.sub(r'^\\$(.*)\\$$', r'\\1', a, flags=re.DOTALL)\n",
        "\n",
        "        # strip standalone leading/trailing $ characters and spaces\n",
        "        a = a.strip('$ ')\n",
        "\n",
        "        # Remove common prefixes (kept after stripping $ to catch cases like \"$Final Answer: ...$\")\n",
        "        prefixes_to_remove = [\n",
        "            r'Final Answer:\\s*',\n",
        "            r'Answer:\\s*',\n",
        "            r'The answer is\\s*',\n",
        "            r'Therefore,?\\s*',\n",
        "            r'Thus,?\\s*',\n",
        "            r'Hence,?\\s*',\n",
        "            r'So,?\\s*',\n",
        "            r'∴\\s*',\n",
        "        ]\n",
        "        for prefix in prefixes_to_remove:\n",
        "            a = re.sub(f'^{prefix}', '', a, flags=re.IGNORECASE)\n",
        "\n",
        "        # remove various boxed wrappers with optional backslashes and optional surrounding $\n",
        "        # e.g. $$\\boxed{...}$$, $\\boxed{...}$, \\boxed{...}\n",
        "        a = re.sub(r'\\$?\\s*(?:\\\\){0,3}boxed\\{([^}]*)\\}\\s*\\$?', r'\\1', a, flags=re.DOTALL | re.IGNORECASE)\n",
        "        # also ensure plain \\boxed{...} is unwrapped (redundant but safe)\n",
        "        a = re.sub(r'\\\\boxed\\{([^}]*)\\}', r'\\1', a)\n",
        "\n",
        "        # convert common LaTeX to readable forms\n",
        "        a = re.sub(r'\\\\frac\\{([^}]*)\\}\\{([^}]*)\\}', r'(\\1)/(\\2)', a)\n",
        "        a = re.sub(r'\\\\sqrt\\{([^}]*)\\}', r'√(\\1)', a)\n",
        "\n",
        "        # remove bold/italic wrappers\n",
        "        a = re.sub(r'\\*\\*([^*]+)\\*\\*', r'\\1', a)\n",
        "        a = re.sub(r'\\*([^*]+)\\*', r'\\1', a)\n",
        "\n",
        "        # collapse multiple spaces again (in case replacements introduced them)\n",
        "        a = re.sub(r'\\s+', ' ', a).strip()\n",
        "\n",
        "        # trim trailing punctuation/words\n",
        "        a = a.rstrip(' \\t\\n.,;:')\n",
        "\n",
        "        # remove trailing words like \"proved\" or \"the answer\"\n",
        "        a = re.sub(r'\\b(proved|completed|finished|the answer)\\b[.\\s]*$', '', a, flags=re.IGNORECASE).strip()\n",
        "\n",
        "        return a\n",
        "\n",
        "    @staticmethod\n",
        "    def _is_valid_answer(answer: str) -> bool:\n",
        "        if not answer:\n",
        "            return False\n",
        "        if re.match(r'^[\\W_]+$', answer):\n",
        "            return False\n",
        "        if not re.search(r'[0-9A-Za-z\\\\]', answer):\n",
        "            return False\n",
        "        if len(answer) > 1000:\n",
        "            return False\n",
        "        blacklist = [r'therefore$', r'thus$', r'hence$', r'so$', r'we get$', r'we have$']\n",
        "        for b in blacklist:\n",
        "            if re.search(b, answer.strip(), flags=re.IGNORECASE):\n",
        "                return False\n",
        "        return True\n",
        "\n",
        "    @staticmethod\n",
        "    def extract_final_answer_simple(text: str) -> str:\n",
        "        \"\"\"\n",
        "        Primary method: Extract final answer using the last lines approach,\n",
        "        with fallback to pattern-based extraction.\n",
        "        \"\"\"\n",
        "        if not text:\n",
        "            return \"\"\n",
        "\n",
        "        # Clean the text and split into lines\n",
        "        lines = [line.strip() for line in text.strip().split('\\n') if line.strip()]\n",
        "\n",
        "        # Strategy 1: Try last two lines combined\n",
        "        if len(lines) >= 2:\n",
        "            last_two = ' '.join(lines[-2:])\n",
        "            cleaned = EnhancedAnswerExtractor._clean_answer(last_two)\n",
        "            if EnhancedAnswerExtractor._is_valid_answer(cleaned):\n",
        "                return cleaned\n",
        "\n",
        "        # Strategy 2: Try last line only\n",
        "        if lines:\n",
        "            cleaned = EnhancedAnswerExtractor._clean_answer(lines[-1])\n",
        "            if EnhancedAnswerExtractor._is_valid_answer(cleaned):\n",
        "                return cleaned\n",
        "\n",
        "        # Strategy 3: Try last 3 lines if we have them (sometimes answers span multiple lines)\n",
        "        if len(lines) >= 3:\n",
        "            last_three = ' '.join(lines[-3:])\n",
        "            cleaned = EnhancedAnswerExtractor._clean_answer(last_three)\n",
        "            if EnhancedAnswerExtractor._is_valid_answer(cleaned) and len(cleaned) < 500:\n",
        "                return cleaned\n",
        "\n",
        "        # Strategy 4: Fallback to pattern-based extraction\n",
        "        return EnhancedAnswerExtractor._extract_with_patterns(text)\n",
        "\n",
        "    @staticmethod\n",
        "    def _extract_with_patterns(text: str) -> str:\n",
        "        \"\"\"\n",
        "        Pattern-based extraction as fallback method.\n",
        "        \"\"\"\n",
        "        # Check for <final> tags\n",
        "        raw_matches = re.findall(r'<final>(.*?)</final>', text, re.DOTALL | re.IGNORECASE)\n",
        "        for m in raw_matches:\n",
        "            c = EnhancedAnswerExtractor._clean_answer(m)\n",
        "            if EnhancedAnswerExtractor._is_valid_answer(c):\n",
        "                return c\n",
        "\n",
        "        # Try common answer patterns\n",
        "        patterns = [\n",
        "            r'\\*\\*Final Answer:\\*\\*\\s*(.+?)(?:\\n|$)',\n",
        "            r'Final Answer:\\s*(.+?)(?:\\n|$)',\n",
        "            r'Therefore[,:\\s]*(.+?)(?:\\.|$|\\n)',\n",
        "            r'Hence[,:\\s]*(.+?)(?:\\.|$|\\n)',\n",
        "            r'Thus[,:\\s]*(.+?)(?:\\.|$|\\n)',\n",
        "            r'Answer[:\\s]*(.+?)(?:\\n|$)',\n",
        "            r'∴\\s*(.+?)(?:\\.|$|\\n)',\n",
        "        ]\n",
        "\n",
        "        for pat in patterns:\n",
        "            matches = re.findall(pat, text, re.MULTILINE | re.DOTALL | re.IGNORECASE)\n",
        "            if matches:\n",
        "                answer = matches[-1].strip()\n",
        "                cleaned = EnhancedAnswerExtractor._clean_answer(answer)\n",
        "                if EnhancedAnswerExtractor._is_valid_answer(cleaned):\n",
        "                    return cleaned\n",
        "\n",
        "        # Try boxed math expressions\n",
        "        boxed_patterns = [\n",
        "            r'\\$\\$\\s*(?:\\\\){0,3}boxed\\{(.+?)\\}\\s*\\$\\$',\n",
        "            r'\\$\\s*(?:\\\\){0,3}boxed\\{(.+?)\\}\\s*\\$',\n",
        "            r'(?:\\\\){0,3}boxed\\{(.+?)\\}',\n",
        "        ]\n",
        "\n",
        "        for pat in boxed_patterns:\n",
        "            m = re.search(pat, text, re.DOTALL | re.IGNORECASE)\n",
        "            if m:\n",
        "                cand = EnhancedAnswerExtractor._clean_answer(m.group(1))\n",
        "                if EnhancedAnswerExtractor._is_valid_answer(cand):\n",
        "                    return cand\n",
        "\n",
        "        return \"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def extract_all_final_answers(generated_solution: str) -> list:\n",
        "        \"\"\"\n",
        "        Extract multiple final answers using simplified approach.\n",
        "        Returns a list (possibly empty) of cleaned answers found inside all <final>...</final> tags.\n",
        "        Falls back to the single simplified extraction if no tags are found.\n",
        "        \"\"\"\n",
        "        if not generated_solution:\n",
        "            return []\n",
        "\n",
        "        # Find all <final>...</final> (non-greedy)\n",
        "        raw_matches = re.findall(r'<final>(.*?)</final>', generated_solution, re.DOTALL | re.IGNORECASE)\n",
        "        cleaned = []\n",
        "        for m in raw_matches:\n",
        "            c = EnhancedAnswerExtractor._clean_answer(m)\n",
        "            if EnhancedAnswerExtractor._is_valid_answer(c):\n",
        "                cleaned.append(c)\n",
        "\n",
        "        if cleaned:\n",
        "            return cleaned\n",
        "\n",
        "        # Fallback: try to extract a single final using the simpler logic\n",
        "        simple_answer = EnhancedAnswerExtractor.extract_final_answer_simple(generated_solution)\n",
        "        if simple_answer:\n",
        "            return [simple_answer]\n",
        "\n",
        "        return []\n",
        "\n",
        "    @staticmethod\n",
        "    def extract_final_answer(generated_solution: str) -> str:\n",
        "        \"\"\"\n",
        "        Backwards-compatible extractor that delegates to the simplified extraction.\n",
        "        If multiple <final> tags exist, returns a JSON array string of cleaned answers.\n",
        "        \"\"\"\n",
        "        if not generated_solution:\n",
        "            return \"\"\n",
        "\n",
        "        # Prefer explicit <final> tags (can be multiple)\n",
        "        raw_matches = re.findall(r'<final>(.*?)</final>', generated_solution, re.DOTALL | re.IGNORECASE)\n",
        "        if raw_matches:\n",
        "            cleaned = []\n",
        "            for m in raw_matches:\n",
        "                c = EnhancedAnswerExtractor._clean_answer(m)\n",
        "                if EnhancedAnswerExtractor._is_valid_answer(c):\n",
        "                    cleaned.append(c)\n",
        "            if not cleaned:\n",
        "                # fall through to simpler single extraction\n",
        "                return EnhancedAnswerExtractor.extract_final_answer_simple(generated_solution)\n",
        "            if len(cleaned) == 1:\n",
        "                return cleaned[0]\n",
        "            try:\n",
        "                return json.dumps(cleaned, ensure_ascii=False)\n",
        "            except Exception:\n",
        "                return \" ||| \".join(cleaned)\n",
        "\n",
        "        # No explicit finals: use simplified single extraction\n",
        "        return EnhancedAnswerExtractor.extract_final_answer_simple(generated_solution)\n",
        "\n",
        "# -------------------------\n",
        "# Ollama-based English Math Solver (ZERO-SHOT)\n",
        "# -------------------------\n",
        "class OllamaZeroShotMathSolver:\n",
        "    \"\"\"\n",
        "    Zero-shot math solver that uses the Ollama daemon via the Python client.\n",
        "    - Zero-shot prompt: forbids chain-of-thought and requests concise final <final> tag\n",
        "    - Single-pass only.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model_name=\"qwen3:8b\"):\n",
        "        \"\"\"\n",
        "        model_name: the Ollama model reference (e.g., \"qwen3:8b\")\n",
        "        \"\"\"\n",
        "        self.model_name = model_name\n",
        "        self.client = self._load_client()\n",
        "\n",
        "    def _load_client(self):\n",
        "        print(f\"Initializing Ollama client for model: {self.model_name}\")\n",
        "        client = ollama.Client()\n",
        "        return client\n",
        "\n",
        "    def cleanup(self):\n",
        "        if hasattr(self, 'client'):\n",
        "            del self.client\n",
        "\n",
        "    def _get_format_instructions(self, answer_type):\n",
        "        \"\"\"\n",
        "        Zero-shot formatting instructions (same logic as your zero-shot HF version).\n",
        "        \"\"\"\n",
        "        t = (answer_type or \"symbolic\").strip().lower()\n",
        "        if t not in _CANONICAL_TYPES:\n",
        "            t = \"symbolic\"\n",
        "\n",
        "        base = (\n",
        "            \"CRITICAL ANSWER FORMATTING REQUIREMENTS (ZERO-SHOT):\\n\"\n",
        "            \"You MUST NOT provide chain-of-thought or step-by-step internal reasoning. \"\n",
        "            \"Do NOT reveal private chain-of-thought. Provide a concise answer only. \"\n",
        "            \"If a very short justification is necessary, include a single-line 'Explanation:' \"\n",
        "            \"with at most one sentence. Always end with a machine-readable final tag <final>...</final> \"\n",
        "            \"containing only the concise final answer (no extra reasoning inside the tag).\\n\"\n",
        "        )\n",
        "\n",
        "        if t == \"proof\":\n",
        "            return base + (\n",
        "                \"FOR PROOFS (zero-shot):\\n\"\n",
        "                \"- Provide a concise conclusion or a one-sentence proof sketch labeled 'Conclusion:' or 'Proof sketch:' \"\n",
        "                \"if needed (one sentence only). Do NOT provide a full step-by-step proof or chain-of-thought.\\n\"\n",
        "                \"Format:\\n\"\n",
        "                \"Final Answer:\\n\"\n",
        "                \"[Concise English conclusion or one-sentence sketch]\\n\\n\"\n",
        "                \"<final>[Concise English conclusion]</final>\\n\"\n",
        "            )\n",
        "        elif t == \"numerical\":\n",
        "            return base + (\n",
        "                \"FOR NUMERICAL RESULTS:\\n\"\n",
        "                \"- Provide the numeric result in exact form if available (fractions/radicals). Otherwise provide a decimal rounded to 4 decimal places.\\n\"\n",
        "                \"Format:\\n\"\n",
        "                \"Final Answer:\\n\"\n",
        "                \"[Numeric result]\\n\\n\"\n",
        "                \"<final>[Numeric result]</final>\\n\"\n",
        "            )\n",
        "        else:  # symbolic\n",
        "            return base + (\n",
        "                \"FOR SYMBOLIC RESULTS:\\n\"\n",
        "                \"- Provide the final symbolic expression (LaTeX is allowed) in a concise form.\\n\"\n",
        "                \"Format:\\n\"\n",
        "                \"Final Answer:\\n\"\n",
        "                \"[Final symbolic expression]\\n\\n\"\n",
        "                \"<final>[LaTeX expression or concise symbolic expression]</final>\\n\"\n",
        "            )\n",
        "\n",
        "    def _create_prompt(self, question, answer_type=\"General\"):\n",
        "        format_instructions = self._get_format_instructions(answer_type)\n",
        "\n",
        "        prompt = f\"\"\"You are an expert mathematician. Provide a concise answer to the problem below.\n",
        "DO NOT provide chain-of-thought, step-by-step reasoning, or internal deliberation. If you include any justification, it must be a single short sentence preceded by 'Explanation:'.\n",
        "\n",
        "MATHEMATICAL PROBLEM:\n",
        "{question}\n",
        "\n",
        "{format_instructions}\n",
        "\n",
        "Begin your concise answer now:\n",
        "\"\"\"\n",
        "        return prompt\n",
        "\n",
        "    def _generate_once(self, prompt_text: str, enable_thinking: bool = False) -> str:\n",
        "        \"\"\"\n",
        "        Call ollama.Client.chat WITHOUT temperature/max_tokens.\n",
        "        Handles several possible response shapes.\n",
        "        \"\"\"\n",
        "        messages = [{\"role\": \"user\", \"content\": prompt_text}]\n",
        "\n",
        "        # Call Ollama client.chat without temperature/max_tokens\n",
        "        try:\n",
        "            resp = self.client.chat(model=self.model_name, messages=messages, think=enable_thinking)\n",
        "        except TypeError:\n",
        "            # Some client versions have different signatures\n",
        "            try:\n",
        "                resp = self.client.chat(self.model_name, messages=messages, think=enable_thinking)\n",
        "            except Exception:\n",
        "                resp = self.client.chat(self.model_name, messages)\n",
        "\n",
        "        # Normalize response into a string\n",
        "        full_output = \"\"\n",
        "        if isinstance(resp, dict):\n",
        "            if 'message' in resp and isinstance(resp['message'], dict) and 'content' in resp['message']:\n",
        "                full_output = resp['message']['content']\n",
        "            elif 'choices' in resp and isinstance(resp['choices'], (list, tuple)) and resp['choices']:\n",
        "                choice = resp['choices'][0]\n",
        "                if isinstance(choice, dict) and 'message' in choice and isinstance(choice['message'], dict):\n",
        "                    full_output = choice['message'].get('content', '')\n",
        "                else:\n",
        "                    full_output = str(choice)\n",
        "            else:\n",
        "                full_output = str(resp)\n",
        "        else:\n",
        "            # resp might be an object with .message.content\n",
        "            try:\n",
        "                full_output = resp.message.content\n",
        "            except Exception:\n",
        "                full_output = str(resp)\n",
        "\n",
        "        if isinstance(full_output, bytes):\n",
        "            full_output = full_output.decode('utf-8', errors='ignore')\n",
        "        return (full_output or \"\").strip()\n",
        "\n",
        "    def solve_problem(self, question, answer_type=\"symbolic\"):\n",
        "        \"\"\"\n",
        "        Zero-shot single-pass solve via Ollama.\n",
        "        \"\"\"\n",
        "        prompt = self._create_prompt(question, answer_type)\n",
        "        full_output = self._generate_once(prompt, enable_thinking=False)\n",
        "\n",
        "        # No thinking parsing for zero-shot mode\n",
        "        thinking_content = \"\"\n",
        "        generated_answer = full_output\n",
        "        final_tag_output = \"\"  # no second pass\n",
        "\n",
        "        extracted_final_answer = EnhancedAnswerExtractor.extract_final_answer(generated_answer)\n",
        "\n",
        "        return {\n",
        "            \"thinking_content\": thinking_content,\n",
        "            \"generated_answer\": generated_answer,\n",
        "            \"final_tag_output\": final_tag_output,\n",
        "            \"extracted_final_answer\": extracted_final_answer\n",
        "        }\n",
        "\n",
        "# -------------------------\n",
        "# Dataset Processor\n",
        "# -------------------------\n",
        "class DatasetProcessor:\n",
        "    def __init__(self, solver: OllamaZeroShotMathSolver, failed_folder=None):\n",
        "        self.solver = solver\n",
        "        self.extractor = EnhancedAnswerExtractor()\n",
        "        self.failed_folder = failed_folder or \"failed_extractions\"\n",
        "        os.makedirs(self.failed_folder, exist_ok=True)\n",
        "\n",
        "    def process_dataset(self, dataset_path, output_base_path, start_idx=0, end_idx=None,\n",
        "                        folder_name=None, create_timestamped_folder=True):\n",
        "        dataset = self._load_dataset(dataset_path)\n",
        "        if end_idx is None:\n",
        "            end_idx = len(dataset)\n",
        "\n",
        "        output_folder = self._create_output_folder(output_base_path, folder_name, start_idx, end_idx, create_timestamped_folder)\n",
        "        results = []\n",
        "\n",
        "        print(f\"Processing problems {start_idx} to {end_idx-1} ({end_idx-start_idx} total)\")\n",
        "        print(f\"Output will be saved in: {output_folder}\")\n",
        "\n",
        "        for idx in tqdm(range(start_idx, min(end_idx, len(dataset)))):\n",
        "            problem = dataset[idx]\n",
        "            try:\n",
        "                result_entry = self._process_single_problem(idx, problem)\n",
        "                results.append(result_entry)\n",
        "                self._print_progress(idx, result_entry)\n",
        "                if (idx - start_idx + 1) % 10 == 0:\n",
        "                    self._save_intermediate_results(results, output_folder, idx - start_idx + 1)\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing problem {idx+1}: {str(e)}\")\n",
        "                error_entry = self._create_error_entry(idx, problem, str(e))\n",
        "                results.append(error_entry)\n",
        "\n",
        "        final_output_path = self._save_final_results(results, output_folder, start_idx, end_idx)\n",
        "        self._create_summary_file(results, output_folder, dataset_path, start_idx, end_idx)\n",
        "        return results, output_folder\n",
        "\n",
        "    def _create_output_folder(self, base_path, folder_name, start_idx, end_idx, add_timestamp):\n",
        "        if folder_name is None:\n",
        "            folder_name = f\"results_{start_idx}_to_{end_idx-1}\"\n",
        "        if add_timestamp:\n",
        "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "            folder_name = f\"{folder_name}_{timestamp}\"\n",
        "        output_folder = os.path.join(base_path, folder_name)\n",
        "        os.makedirs(output_folder, exist_ok=True)\n",
        "        return output_folder\n",
        "\n",
        "    def _load_dataset(self, dataset_path):\n",
        "        dataset = []\n",
        "        with open(dataset_path, 'r', encoding='utf-8') as f:\n",
        "            for line in f:\n",
        "                if line.strip():\n",
        "                    dataset.append(json.loads(line))\n",
        "        return dataset\n",
        "\n",
        "    def _process_single_problem(self, idx, problem):\n",
        "        language = problem.get(\"Language\", \"\")\n",
        "        chapter_num = problem.get(\"Chapter Number\", \"\")\n",
        "        example_num = problem.get(\"Example Number\", \"\")\n",
        "        question = problem.get(\"Question\", \"\")\n",
        "        exact_answer = problem.get(\"Exact Answer\", \"\")\n",
        "        raw_answer_type = problem.get(\"Answer Type\", \"\") or \"\"\n",
        "\n",
        "        # Normalize/infer canonical answer type: 'symbolic', 'numerical', 'proof'\n",
        "        canonical_type = normalize_answer_type(raw_answer_type, question_text=question, exact_answer=exact_answer)\n",
        "\n",
        "        # If exact_answer strongly indicates numeric, prefer numerical\n",
        "        if exact_answer and re.search(r'\\d', str(exact_answer)):\n",
        "            # if exact contains LaTeX expressions like \\frac or \\sqrt, keep symbolic\n",
        "            if re.search(r'\\\\frac|\\\\sqrt|\\\\boxed', str(exact_answer)):\n",
        "                pass\n",
        "            else:\n",
        "                canonical_type = \"numerical\"\n",
        "\n",
        "        print(f\"\\nProcessing Problem {idx+1}: Chapter {chapter_num}, Example {example_num}\")\n",
        "        print(f\"Raw Answer Type: '{raw_answer_type}'  --> canonical: '{canonical_type}'\")\n",
        "\n",
        "        # Generate solution (use canonical_type) -- zero-shot, single pass\n",
        "        solution_result = self.solver.solve_problem(question, answer_type=canonical_type)\n",
        "        generated_answer = solution_result.get('generated_answer', '')\n",
        "        thinking_content = solution_result.get('thinking_content', '')  # will be empty\n",
        "        final_tag_output = solution_result.get('final_tag_output', '')\n",
        "\n",
        "        # --- NEW extraction logic: keep both forms (single string & list) ---\n",
        "        # Try to get all <final> answers first (preferred)\n",
        "        all_finals = EnhancedAnswerExtractor.extract_all_final_answers(generated_answer)\n",
        "        extracted_final_answer = \"\"\n",
        "        extracted_final_answers = []\n",
        "\n",
        "        # If none found in generated_answer, try final_tag_output (unused here)\n",
        "        if not all_finals and final_tag_output:\n",
        "            all_finals = EnhancedAnswerExtractor.extract_all_final_answers(final_tag_output)\n",
        "\n",
        "        # If still none, fall back to single-answer extractor\n",
        "        if not all_finals:\n",
        "            single = EnhancedAnswerExtractor.extract_final_answer(generated_answer)\n",
        "            if single:\n",
        "                extracted_final_answer = single\n",
        "                extracted_final_answers = [single]\n",
        "            else:\n",
        "                # try whole combined text (thinking + generated + final_tag)\n",
        "                combined = \"\\n\".join([thinking_content or \"\", generated_answer or \"\", final_tag_output or \"\"])\n",
        "                single = EnhancedAnswerExtractor.extract_final_answer(combined)\n",
        "                if single:\n",
        "                    extracted_final_answer = single\n",
        "                    extracted_final_answers = [single]\n",
        "                else:\n",
        "                    extracted_final_answer = \"\"\n",
        "                    extracted_final_answers = []\n",
        "        else:\n",
        "            # we have one or more finals\n",
        "            extracted_final_answers = all_finals\n",
        "            if len(all_finals) == 1:\n",
        "                extracted_final_answer = all_finals[0]\n",
        "            else:\n",
        "                # store a machine-readable concatenation: JSON array string\n",
        "                try:\n",
        "                    extracted_final_answer = json.dumps(all_finals, ensure_ascii=False)\n",
        "                except Exception:\n",
        "                    extracted_final_answer = \" ||| \".join(all_finals)\n",
        "\n",
        "        # If still empty, save a failed extraction example for inspection\n",
        "        if not extracted_final_answer:\n",
        "            fname = f\"failed_{idx}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
        "            fpath = os.path.join(self.failed_folder, fname)\n",
        "            with open(fpath, 'w', encoding='utf-8') as f:\n",
        "                json.dump({\n",
        "                    \"index\": idx,\n",
        "                    \"question\": question,\n",
        "                    \"generated_answer\": generated_answer,\n",
        "                    \"thinking_content\": thinking_content,\n",
        "                    \"final_tag_output\": final_tag_output,\n",
        "                    \"exact_answer\": exact_answer,\n",
        "                    \"canonical_type\": canonical_type,\n",
        "                    \"extracted_final_answer\": extracted_final_answer,\n",
        "                    \"extracted_final_answers\": extracted_final_answers\n",
        "                }, f, ensure_ascii=False, indent=2)\n",
        "            print(f\"Saved failed extraction example to {fpath}\")\n",
        "\n",
        "        result_entry = {\n",
        "            \"problem_index\": idx,\n",
        "            \"language\": language,\n",
        "            \"chapter_number\": chapter_num,\n",
        "            \"example_number\": example_num,\n",
        "            \"question\": question,\n",
        "            \"generated_answer\": generated_answer,\n",
        "            \"thinking_content\": thinking_content,\n",
        "            \"final_tag_output\": final_tag_output,\n",
        "            \"extracted_final_answer\": extracted_final_answer,       # string (or JSON array string)\n",
        "            \"extracted_final_answers\": extracted_final_answers,     # list (empty / single / many)\n",
        "            \"exact_answer\": exact_answer,\n",
        "            \"raw_answer_type\": raw_answer_type,\n",
        "            \"canonical_answer_type\": canonical_type,\n",
        "            \"evaluation_method\": problem.get(\"Evaluation Method\", \"\")\n",
        "        }\n",
        "        return result_entry\n",
        "\n",
        "    def _create_error_entry(self, idx, problem, error_msg):\n",
        "        return {\n",
        "            \"problem_index\": idx,\n",
        "            \"language\": problem.get(\"Language\", \"\"),\n",
        "            \"chapter_number\": problem.get(\"Chapter Number\", \"\"),\n",
        "            \"example_number\": problem.get(\"Example Number\", \"\"),\n",
        "            \"question\": problem.get(\"Question\", \"\"),\n",
        "            \"generated_answer\": f\"ERROR: {error_msg}\",\n",
        "            \"thinking_content\": \"\",\n",
        "            \"final_tag_output\": \"\",\n",
        "            \"extracted_final_answer\": \"\",\n",
        "            \"extracted_final_answers\": [],\n",
        "            \"exact_answer\": problem.get(\"Exact Answer\", \"\"),\n",
        "            \"raw_answer_type\": problem.get(\"Answer Type\", \"\"),\n",
        "            \"canonical_answer_type\": \"\",\n",
        "            \"evaluation_method\": problem.get(\"Evaluation Method\", \"\")\n",
        "        }\n",
        "\n",
        "    def _print_progress(self, idx, result_entry):\n",
        "        print(f\"Generated answer length: {len(result_entry['generated_answer']) if result_entry['generated_answer'] else 0}\")\n",
        "        print(f\"Extracted final answer: '{result_entry['extracted_final_answer']}'\")\n",
        "        print(f\"Extracted final answers (list): {result_entry.get('extracted_final_answers', [])}\")\n",
        "        print(f\"Expected answer: '{result_entry['exact_answer']}'\")\n",
        "\n",
        "    def _save_intermediate_results(self, results, output_folder, count):\n",
        "        temp_filename = f'intermediate_results_{count}.json'\n",
        "        temp_output_path = os.path.join(output_folder, temp_filename)\n",
        "        with open(temp_output_path, 'w', encoding='utf-8') as f:\n",
        "            json.dump(results, f, ensure_ascii=False, indent=2)\n",
        "        print(f\"Saved intermediate results to {temp_output_path}\")\n",
        "\n",
        "    def _save_final_results(self, results, output_folder, start_idx, end_idx):\n",
        "        final_filename = f'final_results_{start_idx}_to_{end_idx-1}.json'\n",
        "        final_output_path = os.path.join(output_folder, final_filename)\n",
        "        with open(final_output_path, 'w', encoding='utf-8') as f:\n",
        "            json.dump(results, f, ensure_ascii=False, indent=2)\n",
        "        print(f\"\\nProcessing complete. Results saved to {final_output_path}\")\n",
        "        print(f\"Total problems processed: {len(results)}\")\n",
        "        return final_output_path\n",
        "\n",
        "    def _create_summary_file(self, results, output_folder, dataset_path, start_idx, end_idx):\n",
        "        successful_extractions = len([r for r in results if r.get('extracted_final_answer', '').strip()])\n",
        "        summary_data = {\n",
        "            \"processing_info\": {\n",
        "                \"dataset_path\": dataset_path,\n",
        "                \"start_index\": start_idx,\n",
        "                \"end_index\": end_idx - 1,\n",
        "                \"total_processed\": len(results),\n",
        "                \"processing_timestamp\": datetime.now().isoformat(),\n",
        "                \"output_folder\": output_folder\n",
        "            },\n",
        "            \"statistics\": {\n",
        "                \"successful_problems\": len([r for r in results if not r['generated_answer'].startswith('ERROR:')]),\n",
        "                \"failed_problems\": len([r for r in results if r['generated_answer'].startswith('ERROR:')]),\n",
        "                \"successful_extractions\": successful_extractions,\n",
        "                \"extraction_success_rate\": f\"{(successful_extractions/len(results)*100):.1f}%\" if results else \"0%\",\n",
        "                \"average_answer_length\": sum(len(r['generated_answer']) for r in results) / len(results) if results else 0,\n",
        "                \"chapters_processed\": list(set(r['chapter_number'] for r in results if r['chapter_number'])),\n",
        "                \"raw_answer_types\": list(set(r['raw_answer_type'] for r in results if r.get('raw_answer_type'))),\n",
        "                \"canonical_answer_types\": list(set(r['canonical_answer_type'] for r in results if r.get('canonical_answer_type')))\n",
        "            }\n",
        "        }\n",
        "        summary_path = os.path.join(output_folder, 'processing_summary.json')\n",
        "        with open(summary_path, 'w', encoding='utf-8') as f:\n",
        "            json.dump(summary_data, f, ensure_ascii=False, indent=2)\n",
        "        print(f\"Processing summary saved to {summary_path}\")\n",
        "        print(f\"Answer extraction success rate: {summary_data['statistics']['extraction_success_rate']}\")\n",
        "\n",
        "# -------------------------\n",
        "# Main (example usage)\n",
        "# -------------------------\n",
        "def main():\n",
        "    # NOTE: update dataset_path and output_base_path to match your environment\n",
        "    dataset_path = \"/kaggle/input/nctb-dataset/English_Final_Corpus.jsonl\"  # source format unchanged; questions are English\n",
        "    output_base_path = \"/kaggle/working/\"\n",
        "\n",
        "    # Use the Ollama zero-shot solver (ensure the specified model is available in Ollama)\n",
        "    solver = OllamaZeroShotMathSolver(model_name=\"qwen3:8b\")\n",
        "    processor = DatasetProcessor(solver, failed_folder=os.path.join(output_base_path, \"failed_extractions\"))\n",
        "\n",
        "    # For quick testing, process only first few problems\n",
        "    results, out_folder = processor.process_dataset(\n",
        "        dataset_path,\n",
        "        output_base_path,\n",
        "        start_idx=0,\n",
        "        end_idx=1445\n",
        "    )\n",
        "    print(\"Done. Results saved to:\", out_folder)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "jz6sgPmxg61U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **French**"
      ],
      "metadata": {
        "id": "_jy0dpidg31O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "import re\n",
        "from datetime import datetime\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Ollama client\n",
        "try:\n",
        "    import ollama\n",
        "except Exception as e:\n",
        "    raise ImportError(\"The 'ollama' package is required. Install it and make sure the Ollama daemon is running.\") from e\n",
        "\n",
        "# -------------------------\n",
        "# Answer type normalization\n",
        "# -------------------------\n",
        "# Canonical set\n",
        "_CANONICAL_TYPES = {\"symbolic\", \"numerical\", \"proof\"}\n",
        "\n",
        "# mapping common noisy labels to canonical (English + French variants)\n",
        "_ANSWER_TYPE_MAP_SIMPLE = {\n",
        "    # Proof variants (English -> French)\n",
        "    \"proof\": \"proof\", \"prove\": \"proof\", \"proove\": \"proof\",\n",
        "    \"preuve\": \"proof\", \"prouver\": \"proof\", \"démontrer\": \"proof\", \"demonstration\": \"proof\",\n",
        "\n",
        "    # Numerical variants\n",
        "    \"numerical\": \"numerical\", \"numeric\": \"numerical\", \"number\": \"numerical\", \"calculation\": \"numerical\",\n",
        "    \"numérique\": \"numerical\", \"numerique\": \"numerical\", \"nombre\": \"numerical\", \"calcul\": \"numerical\",\n",
        "\n",
        "    # Symbolic variants\n",
        "    \"symbolic\": \"symbolic\", \"symbol\": \"symbolic\", \"equation\": \"symbolic\", \"algebraic\": \"symbolic\",\n",
        "    \"symbolique\": \"symbolic\", \"algébrique\": \"symbolic\", \"algebrique\": \"symbolic\", \"équation\": \"symbolic\",\n",
        "    \"equations\": \"symbolic\",\n",
        "}\n",
        "\n",
        "\n",
        "def normalize_answer_type(raw_label: str, question_text: str = \"\", exact_answer: str = \"\") -> str:\n",
        "    \"\"\"\n",
        "    Normalize a dataset label to one of: 'symbolic', 'numerical', 'proof'.\n",
        "    Heuristics expanded to handle French phrases and labels.\n",
        "    \"\"\"\n",
        "    # Helper to clean label\n",
        "    def _clean_label(lbl: str) -> str:\n",
        "        if not lbl:\n",
        "            return \"\"\n",
        "        s = lbl.strip().lower()\n",
        "        # keep unicode letters (accents) and digits and spaces\n",
        "        s = re.sub(r'[^0-9\\w\\sàâäéèêëïîôöùûüçœÀÂÄÉÈÊËÏÎÔÖÙÛÜÇŒ-]', ' ', s, flags=re.UNICODE)\n",
        "        s = re.sub(r'\\s+', ' ', s).strip()\n",
        "        return s\n",
        "\n",
        "    s = _clean_label(raw_label)\n",
        "\n",
        "    # direct mapping\n",
        "    if s in _ANSWER_TYPE_MAP_SIMPLE:\n",
        "        return _ANSWER_TYPE_MAP_SIMPLE[s]\n",
        "\n",
        "    # partial matches (allow English or French keywords appearing)\n",
        "    for k, v in _ANSWER_TYPE_MAP_SIMPLE.items():\n",
        "        if k in s:\n",
        "            return v\n",
        "\n",
        "    # heuristics using question or exact_answer (both English & French checks)\n",
        "    q = (question_text or \"\").lower()\n",
        "    a = (exact_answer or \"\").lower()\n",
        "\n",
        "    # Proof indicators (English + French)\n",
        "    if re.search(r'\\b(prove|show that|prove that|proof)\\b', q) or re.search(r'\\b(prouver|démontrer|demontrer|preuve|montrer que)\\b', q):\n",
        "        return \"proof\"\n",
        "\n",
        "    # logarithm related: English/French\n",
        "    if re.search(r'\\b(log|ln|logarithm)\\b', q) or re.search(r'\\b(log|ln|logarithme)\\b', q) or re.search(r'\\blog\\b', a):\n",
        "        # prefer numerical if exact answer contains digits\n",
        "        if re.search(r'\\d', a):\n",
        "            return \"numerical\"\n",
        "        return \"symbolic\"\n",
        "\n",
        "    # set theory indicators: English / French\n",
        "    if re.search(r'\\b(set|subset|union|intersection)\\b', q) or re.search(r'\\b(ensemble|sous-ensemble|union|intersection)\\b', q):\n",
        "        return \"symbolic\"\n",
        "\n",
        "    # units (English + French)\n",
        "    if re.search(r'\\bmeter\\b|\\bm\\b|\\bcm\\b|\\bkg\\b|\\bliter\\b|\\bl\\b|\\bkm\\b|\\bmile\\b', q + \" \" + a) or \\\n",
        "       re.search(r'\\bmètre\\b|\\bmetre\\b|\\bcm\\b|\\bkg\\b|\\blitre\\b|\\bl\\b|\\bkm\\b', q + \" \" + a):\n",
        "        return \"numerical\"\n",
        "\n",
        "    # equation-solving heuristics (English + French)\n",
        "    if re.search(r'\\bequation\\b|solve for|solve|= x|x\\s*=', q) or re.search(r'\\beq(uation)?\\b|résoudre|resoudre|résoudre pour|= x|x\\s*=', q, flags=re.IGNORECASE):\n",
        "        return \"symbolic\"\n",
        "\n",
        "    # trig / geometry indicators (English + French)\n",
        "    if re.search(r'\\b(trig|sin|cos|tan|geometry|triangle|circle)\\b', q) or re.search(r'\\b(trigonométr|sin|cos|tan|géométrie|triangle|cercle)\\b', q):\n",
        "        if re.search(r'\\d', a):\n",
        "            return \"numerical\"\n",
        "        return \"symbolic\"\n",
        "\n",
        "    # numeric indicators (English + French) -> numerical\n",
        "    if re.search(r'\\d', q) or re.search(r'find the value|compute|calculate|evaluate', q) or \\\n",
        "       re.search(r'trouver la valeur|calculer|évaluer|evaluer', q):\n",
        "        return \"numerical\"\n",
        "\n",
        "    # If exact_answer looks numeric, prefer numerical (but check for LaTeX)\n",
        "    if re.search(r'[0-9]|\\\\frac|\\\\sqrt', a):\n",
        "        if re.search(r'\\\\frac|\\\\sqrt|\\{|\\\\', a):\n",
        "            return \"symbolic\"\n",
        "        return \"numerical\"\n",
        "\n",
        "    # fallback\n",
        "    return \"symbolic\"\n",
        "\n",
        "# -------------------------\n",
        "# EnhancedAnswerExtractor (adapted to behave like SimplifiedAnswerExtractor)\n",
        "# and now handles French markers as well\n",
        "# -------------------------\n",
        "class EnhancedAnswerExtractor:\n",
        "    \"\"\"\n",
        "    Adapter that implements the simplified extraction behavior (ported from SimplifiedAnswerExtractor),\n",
        "    extended to recognize French formatting/conclusion words as well.\n",
        "    Provides:\n",
        "      - extract_final_answer(text) -> str\n",
        "      - extract_all_final_answers(generated_solution) -> list\n",
        "    and internal helpers _clean_answer and _is_valid_answer.\n",
        "    \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def _clean_answer(answer: str) -> str:\n",
        "        if not answer:\n",
        "            return \"\"\n",
        "        # Start with a trimmed answer and normalize whitespace\n",
        "        a = answer.strip()\n",
        "        # collapse whitespace\n",
        "        a = re.sub(r'\\s+', ' ', a)\n",
        "\n",
        "        # remove outer $$ if present (multiline)\n",
        "        a = re.sub(r'^\\$\\$(.*)\\$\\$$', r'\\1', a, flags=re.DOTALL)\n",
        "        # remove surrounding single $ if the whole string is wrapped\n",
        "        a = re.sub(r'^\\$(.*)\\$$', r'\\1', a, flags=re.DOTALL)\n",
        "\n",
        "        # strip standalone leading/trailing $ characters and spaces\n",
        "        a = a.strip('$ ')\n",
        "\n",
        "        # Remove common prefixes (kept after stripping $ to catch cases like \"$Final Answer: ...$\")\n",
        "        prefixes_to_remove = [\n",
        "            # English\n",
        "            r'Final Answer:\\s*', r'Answer:\\s*', r'The answer is\\s*',\n",
        "            r'Therefore,?\\s*', r'Thus,?\\s*', r'Hence,?\\s*', r'So,?\\s*', r'∴\\s*',\n",
        "\n",
        "            # French\n",
        "            r'Réponse finale[:\\s]*', r'Reponse finale[:\\s]*',\n",
        "            r'Réponse[:\\s]*', r'Reponse[:\\s]*',\n",
        "            r'La réponse est\\s*', r'La reponse est\\s*',\n",
        "            r'Par conséquent,?\\s*', r'Par consequent,?\\s*',\n",
        "            r'Donc,?\\s*', r'Ainsi,?\\s*', r'Doù\\s*', r'Dou\\s*',\n",
        "        ]\n",
        "        for prefix in prefixes_to_remove:\n",
        "            a = re.sub(f'^{prefix}', '', a, flags=re.IGNORECASE)\n",
        "\n",
        "        # remove various boxed wrappers with optional backslashes and optional surrounding $\n",
        "        # e.g. $$\\boxed{...}$$, $\\boxed{...}$, \\boxed{...}\n",
        "        a = re.sub(r'\\$?\\s*(?:\\\\){0,3}boxed\\{([^}]*)\\}\\s*\\$?', r'\\1', a, flags=re.DOTALL | re.IGNORECASE)\n",
        "        # also ensure plain \\boxed{...} is unwrapped (redundant but safe)\n",
        "        a = re.sub(r'\\\\boxed\\{([^}]*)\\}', r'\\1', a)\n",
        "\n",
        "        # convert common LaTeX to readable forms\n",
        "        a = re.sub(r'\\\\frac\\{([^}]*)\\}\\{([^}]*)\\}', r'(\\1)/(\\2)', a)\n",
        "        a = re.sub(r'\\\\sqrt\\{([^}]*)\\}', r'√(\\1)', a)\n",
        "\n",
        "        # remove bold/italic wrappers\n",
        "        a = re.sub(r'\\*\\*([^*]+)\\*\\*', r'\\1', a)\n",
        "        a = re.sub(r'\\*([^*]+)\\*', r'\\1', a)\n",
        "\n",
        "        # collapse multiple spaces again (in case replacements introduced them)\n",
        "        a = re.sub(r'\\s+', ' ', a).strip()\n",
        "\n",
        "        # trim trailing punctuation/words\n",
        "        a = a.rstrip(' \\t\\n.,;:')\n",
        "\n",
        "        # remove trailing words like \"proved\" or \"the answer\" (English & French)\n",
        "        a = re.sub(r'\\b(proved|completed|finished|the answer|prouvé|prouve|la réponse)\\b[.\\s]*$', '', a, flags=re.IGNORECASE).strip()\n",
        "\n",
        "        return a\n",
        "\n",
        "    @staticmethod\n",
        "    def _is_valid_answer(answer: str) -> bool:\n",
        "        if not answer:\n",
        "            return False\n",
        "        # not only punctuation\n",
        "        if re.match(r'^[\\W_]+$', answer):\n",
        "            return False\n",
        "        # contains at least some alphanumeric characters (or common math symbols)\n",
        "        if not re.search(r'[0-9A-Za-zÀ-ÖØ-öø-ÿ\\\\]', answer):\n",
        "            return False\n",
        "        # length sanity\n",
        "        if len(answer) > 1000:\n",
        "            return False\n",
        "        # avoid answers that end with only concluding words (English & French)\n",
        "        blacklist = [r'therefore$', r'thus$', r'hence$', r'so$', r'we get$', r'we have$', r'donc$', r'ainsi$', r'par conséquent$']\n",
        "        for b in blacklist:\n",
        "            if re.search(b, answer.strip(), flags=re.IGNORECASE):\n",
        "                return False\n",
        "        return True\n",
        "\n",
        "    @staticmethod\n",
        "    def extract_final_answer_simple(text: str) -> str:\n",
        "        \"\"\"\n",
        "        Primary method: Extract final answer using the last lines approach,\n",
        "        with fallback to pattern-based extraction.\n",
        "        \"\"\"\n",
        "        if not text:\n",
        "            return \"\"\n",
        "\n",
        "        # Clean the text and split into lines\n",
        "        lines = [line.strip() for line in text.strip().split('\\n') if line.strip()]\n",
        "\n",
        "        # Strategy 1: Try last two lines combined\n",
        "        if len(lines) >= 2:\n",
        "            last_two = ' '.join(lines[-2:])\n",
        "            cleaned = EnhancedAnswerExtractor._clean_answer(last_two)\n",
        "            if EnhancedAnswerExtractor._is_valid_answer(cleaned):\n",
        "                return cleaned\n",
        "\n",
        "        # Strategy 2: Try last line only\n",
        "        if lines:\n",
        "            cleaned = EnhancedAnswerExtractor._clean_answer(lines[-1])\n",
        "            if EnhancedAnswerExtractor._is_valid_answer(cleaned):\n",
        "                return cleaned\n",
        "\n",
        "        # Strategy 3: Try last 3 lines if we have them (sometimes answers span multiple lines)\n",
        "        if len(lines) >= 3:\n",
        "            last_three = ' '.join(lines[-3:])\n",
        "            cleaned = EnhancedAnswerExtractor._clean_answer(last_three)\n",
        "            if EnhancedAnswerExtractor._is_valid_answer(cleaned) and len(cleaned) < 500:\n",
        "                return cleaned\n",
        "\n",
        "        # Strategy 4: Fallback to pattern-based extraction\n",
        "        return EnhancedAnswerExtractor._extract_with_patterns(text)\n",
        "\n",
        "    @staticmethod\n",
        "    def _extract_with_patterns(text: str) -> str:\n",
        "        \"\"\"\n",
        "        Pattern-based extraction as fallback method.\n",
        "        Recognizes both English and French answer/conclusion patterns.\n",
        "        \"\"\"\n",
        "        # Check for <final> tags\n",
        "        raw_matches = re.findall(r'<final>(.*?)</final>', text, re.DOTALL | re.IGNORECASE)\n",
        "        for m in raw_matches:\n",
        "            c = EnhancedAnswerExtractor._clean_answer(m)\n",
        "            if EnhancedAnswerExtractor._is_valid_answer(c):\n",
        "                return c\n",
        "\n",
        "        # Try common answer patterns (English + French)\n",
        "        patterns = [\n",
        "            r'\\*\\*Final Answer:\\*\\*\\s*(.+?)(?:\\n|$)',\n",
        "            r'Final Answer:\\s*(.+?)(?:\\n|$)',\n",
        "            r'Final Answer\\s*[:\\-]\\s*(.+?)(?:\\n|$)',\n",
        "            r'\\*\\*Réponse finale:\\*\\*\\s*(.+?)(?:\\n|$)',\n",
        "            r'Réponse finale[:\\s]*(.+?)(?:\\n|$)',\n",
        "            r'Reponse finale[:\\s]*(.+?)(?:\\n|$)',\n",
        "            r'Reponse[:\\s]*(.+?)(?:\\n|$)',\n",
        "            r'Réponse[:\\s]*(.+?)(?:\\n|$)',\n",
        "            r'Therefore[,:\\s]*(.+?)(?:\\.|$|\\n)',\n",
        "            r'Hence[,:\\s]*(.+?)(?:\\.|$|\\n)',\n",
        "            r'Thus[,:\\s]*(.+?)(?:\\.|$|\\n)',\n",
        "            r'∴\\s*(.+?)(?:\\.|$|\\n)',\n",
        "            r'Par conséquent[,:\\s]*(.+?)(?:\\.|$|\\n)',\n",
        "            r'Par consequent[,:\\s]*(.+?)(?:\\.|$|\\n)',\n",
        "            r'Donc[,:\\s]*(.+?)(?:\\.|$|\\n)',\n",
        "            r'Ainsi[,:\\s]*(.+?)(?:\\.|$|\\n)',\n",
        "            r'Doù[,:\\s]*(.+?)(?:\\.|$|\\n)',\n",
        "            r'Answer[:\\s]*(.+?)(?:\\n|$)',\n",
        "            r'Result[:\\s]*(.+?)(?:\\n|$)',\n",
        "            r'Solution[:\\s]*(.+?)(?:\\n|$)',\n",
        "        ]\n",
        "\n",
        "        for pat in patterns:\n",
        "            matches = re.findall(pat, text, re.MULTILINE | re.DOTALL | re.IGNORECASE)\n",
        "            if matches:\n",
        "                answer = matches[-1].strip()\n",
        "                cleaned = EnhancedAnswerExtractor._clean_answer(answer)\n",
        "                if EnhancedAnswerExtractor._is_valid_answer(cleaned):\n",
        "                    return cleaned\n",
        "\n",
        "        # Try boxed math expressions\n",
        "        boxed_patterns = [\n",
        "            r'\\$\\$\\s*(?:\\\\){0,3}boxed\\{(.+?)\\}\\s*\\$\\$',\n",
        "            r'\\$\\s*(?:\\\\){0,3}boxed\\{(.+?)\\}\\s*\\$',\n",
        "            r'(?:\\\\){0,3}boxed\\{(.+?)\\}',\n",
        "        ]\n",
        "\n",
        "        for pat in boxed_patterns:\n",
        "            m = re.search(pat, text, re.DOTALL | re.IGNORECASE)\n",
        "            if m:\n",
        "                cand = EnhancedAnswerExtractor._clean_answer(m.group(1))\n",
        "                if EnhancedAnswerExtractor._is_valid_answer(cand):\n",
        "                    return cand\n",
        "\n",
        "        return \"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def extract_all_final_answers(generated_solution: str) -> list:\n",
        "        \"\"\"\n",
        "        Extract multiple final answers using simplified approach.\n",
        "        Returns a list (possibly empty) of cleaned answers found inside all <final>...</final> tags.\n",
        "        Falls back to the single simplified extraction if no tags are found.\n",
        "        \"\"\"\n",
        "        if not generated_solution:\n",
        "            return []\n",
        "\n",
        "        # Find all <final>...</final> (non-greedy)\n",
        "        raw_matches = re.findall(r'<final>(.*?)</final>', generated_solution, re.DOTALL | re.IGNORECASE)\n",
        "        cleaned = []\n",
        "        for m in raw_matches:\n",
        "            c = EnhancedAnswerExtractor._clean_answer(m)\n",
        "            if EnhancedAnswerExtractor._is_valid_answer(c):\n",
        "                cleaned.append(c)\n",
        "\n",
        "        if cleaned:\n",
        "            return cleaned\n",
        "\n",
        "        # Fallback: try to extract a single final using the simpler logic\n",
        "        simple_answer = EnhancedAnswerExtractor.extract_final_answer_simple(generated_solution)\n",
        "        if simple_answer:\n",
        "            return [simple_answer]\n",
        "\n",
        "        return []\n",
        "\n",
        "    @staticmethod\n",
        "    def extract_final_answer(generated_solution: str) -> str:\n",
        "        \"\"\"\n",
        "        Backwards-compatible extractor that delegates to the simplified extraction.\n",
        "        If multiple <final> tags exist, returns a JSON array string of cleaned answers.\n",
        "        \"\"\"\n",
        "        if not generated_solution:\n",
        "            return \"\"\n",
        "\n",
        "        # Prefer explicit <final> tags (can be multiple)\n",
        "        raw_matches = re.findall(r'<final>(.*?)</final>', generated_solution, re.DOTALL | re.IGNORECASE)\n",
        "        if raw_matches:\n",
        "            cleaned = []\n",
        "            for m in raw_matches:\n",
        "                c = EnhancedAnswerExtractor._clean_answer(m)\n",
        "                if EnhancedAnswerExtractor._is_valid_answer(c):\n",
        "                    cleaned.append(c)\n",
        "            if not cleaned:\n",
        "                # fall through to simpler single extraction\n",
        "                return EnhancedAnswerExtractor.extract_final_answer_simple(generated_solution)\n",
        "            if len(cleaned) == 1:\n",
        "                return cleaned[0]\n",
        "            try:\n",
        "                return json.dumps(cleaned, ensure_ascii=False)\n",
        "            except Exception:\n",
        "                return \" ||| \".join(cleaned)\n",
        "\n",
        "        # No explicit finals: use simplified single extraction\n",
        "        return EnhancedAnswerExtractor.extract_final_answer_simple(generated_solution)\n",
        "\n",
        "# -------------------------\n",
        "# Ollama-based Math Solver (ZERO-SHOT) — PROMPTS IN ENGLISH (but problem is French)\n",
        "# -------------------------\n",
        "class OllamaZeroShotMathSolver:\n",
        "    \"\"\"\n",
        "    Zero-shot math solver that uses the Ollama daemon via the Python client.\n",
        "    Prompts/instructions are written in English (as requested), but the solver is informed that\n",
        "    the problem text will be in French and is instructed to provide a concise final answer in French.\n",
        "    - Zero-shot prompt: forbids chain-of-thought and requests concise final <final> tag\n",
        "    - Single-pass only.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model_name=\"gpt-oss:20b\"):\n",
        "        \"\"\"\n",
        "        model_name: the Ollama model reference (e.g., \"gpt-oss:20b\")\n",
        "        \"\"\"\n",
        "        self.model_name = model_name\n",
        "        self.client = self._load_client()\n",
        "\n",
        "    def _load_client(self):\n",
        "        print(f\"Initializing Ollama client for model: {self.model_name}\")\n",
        "        client = ollama.Client()\n",
        "        return client\n",
        "\n",
        "    def cleanup(self):\n",
        "        if hasattr(self, 'client'):\n",
        "            del self.client\n",
        "\n",
        "    def _get_format_instructions(self, answer_type):\n",
        "        \"\"\"\n",
        "        Zero-shot formatting instructions (WRITTEN IN ENGLISH).\n",
        "        The model is explicitly informed that the problem text is in French and that the concise final\n",
        "        answer should be provided in FRENCH. Examples/formats are shown in English but demonstrate\n",
        "        that the final tag must contain the concise French answer.\n",
        "        \"\"\"\n",
        "        t = (answer_type or \"symbolic\").strip().lower()\n",
        "        if t not in _CANONICAL_TYPES:\n",
        "            t = \"symbolic\"\n",
        "\n",
        "        base = (\n",
        "            \"CRITICAL FORMATTING REQUIREMENTS (ZERO-SHOT):\\n\"\n",
        "            \"- The math problem you will receive is written in FRENCH. Provide your concise FINAL ANSWER in FRENCH.\\n\"\n",
        "            \"- DO NOT provide chain-of-thought or step-by-step internal reasoning. Do NOT reveal private chain-of-thought.\\n\"\n",
        "            \"- If a very short justification is necessary, include a single-line 'Explanation:' with at most one sentence (in French).\\n\"\n",
        "            \"- Always end with a machine-readable final tag <final>...</final> containing ONLY the concise final answer in FRENCH (no extra reasoning inside the tag).\\n\"\n",
        "        )\n",
        "\n",
        "        if t == \"proof\":\n",
        "            return base + (\n",
        "                \"FOR PROOFS (zero-shot):\\n\"\n",
        "                \"- Provide a concise conclusion or a one-sentence proof sketch (in FRENCH) labeled 'Conclusion:' or 'Esquisse de preuve:' if needed. Do NOT provide a full step-by-step proof.\\n\"\n",
        "                \"Format example (English instructions):\\n\"\n",
        "                \"Final Answer (in French):\\n\"\n",
        "                \"[Concise French conclusion or one-sentence sketch]\\n\\n\"\n",
        "                \"<final>[Concise French conclusion]</final>\\n\"\n",
        "            )\n",
        "        elif t == \"numerical\":\n",
        "            return base + (\n",
        "                \"FOR NUMERICAL RESULTS:\\n\"\n",
        "                \"- Provide the numeric result in exact form if available (fractions/radicals). Otherwise provide a decimal rounded to 4 decimal places.\\n\"\n",
        "                \"Format example (English instructions):\\n\"\n",
        "                \"Final Answer (in French):\\n\"\n",
        "                \"[Numeric result in French notation if needed]\\n\\n\"\n",
        "                \"<final>[Numeric result]</final>\\n\"\n",
        "            )\n",
        "        else:  # symbolic\n",
        "            return base + (\n",
        "                \"FOR SYMBOLIC RESULTS:\\n\"\n",
        "                \"- Provide the final symbolic expression (LaTeX allowed) in a concise form. The expression may be LaTeX but the surrounding explanation should be in French if any.\\n\"\n",
        "                \"Format example (English instructions):\\n\"\n",
        "                \"Final Answer (in French):\\n\"\n",
        "                \"[Final symbolic expression]\\n\\n\"\n",
        "                \"<final>[LaTeX expression or concise symbolic expression — in French if words are used]</final>\\n\"\n",
        "            )\n",
        "\n",
        "    def _create_prompt(self, question, answer_type=\"symbolic\"):\n",
        "        format_instructions = self._get_format_instructions(answer_type)\n",
        "\n",
        "        # The main instruction is still in English (per your requirement), but it states the problem language and the required answer language.\n",
        "        prompt = f\"\"\"You are an expert mathematician. The following math problem is written in FRENCH.\n",
        "Provide a concise final answer in FRENCH. DO NOT produce chain-of-thought or step-by-step internal reasoning.\n",
        "If you include a justification, it must be one short sentence and labeled 'Explication:' (in French).\n",
        "\n",
        "MATH PROBLEM (in French):\n",
        "{question}\n",
        "\n",
        "{format_instructions}\n",
        "\n",
        "Begin your concise answer (in French) now:\n",
        "\"\"\"\n",
        "        return prompt\n",
        "\n",
        "    def _generate_once(self, prompt_text: str, enable_thinking: bool = False) -> str:\n",
        "        \"\"\"\n",
        "        Call ollama.Client.chat WITHOUT temperature/max_tokens.\n",
        "        Handles several possible response shapes.\n",
        "        \"\"\"\n",
        "        messages = [{\"role\": \"user\", \"content\": prompt_text}]\n",
        "\n",
        "        # Call Ollama client.chat without temperature/max_tokens\n",
        "        try:\n",
        "            resp = self.client.chat(model=self.model_name, messages=messages, think=enable_thinking)\n",
        "        except TypeError:\n",
        "            # Some client versions have different signatures\n",
        "            try:\n",
        "                resp = self.client.chat(self.model_name, messages=messages, think=enable_thinking)\n",
        "            except Exception:\n",
        "                resp = self.client.chat(self.model_name, messages)\n",
        "\n",
        "        # Normalize response into a string\n",
        "        full_output = \"\"\n",
        "        if isinstance(resp, dict):\n",
        "            if 'message' in resp and isinstance(resp['message'], dict) and 'content' in resp['message']:\n",
        "                full_output = resp['message']['content']\n",
        "            elif 'choices' in resp and isinstance(resp['choices'], (list, tuple)) and resp['choices']:\n",
        "                choice = resp['choices'][0]\n",
        "                if isinstance(choice, dict) and 'message' in choice and isinstance(choice['message'], dict):\n",
        "                    full_output = choice['message'].get('content', '')\n",
        "                else:\n",
        "                    full_output = str(choice)\n",
        "            else:\n",
        "                full_output = str(resp)\n",
        "        else:\n",
        "            # resp might be an object with .message.content\n",
        "            try:\n",
        "                full_output = resp.message.content\n",
        "            except Exception:\n",
        "                full_output = str(resp)\n",
        "\n",
        "        if isinstance(full_output, bytes):\n",
        "            full_output = full_output.decode('utf-8', errors='ignore')\n",
        "        return (full_output or \"\").strip()\n",
        "\n",
        "    def solve_problem(self, question, answer_type=\"symbolic\"):\n",
        "        \"\"\"\n",
        "        Zero-shot single-pass solve via Ollama.\n",
        "        \"\"\"\n",
        "        prompt = self._create_prompt(question, answer_type)\n",
        "        full_output = self._generate_once(prompt, enable_thinking=False)\n",
        "\n",
        "        # No thinking parsing for zero-shot mode\n",
        "        thinking_content = \"\"\n",
        "        generated_answer = full_output\n",
        "        final_tag_output = \"\"  # no second pass\n",
        "\n",
        "        extracted_final_answer = EnhancedAnswerExtractor.extract_final_answer(generated_answer)\n",
        "\n",
        "        return {\n",
        "            \"thinking_content\": thinking_content,\n",
        "            \"generated_answer\": generated_answer,\n",
        "            \"final_tag_output\": final_tag_output,\n",
        "            \"extracted_final_answer\": extracted_final_answer\n",
        "        }\n",
        "\n",
        "# -------------------------\n",
        "# Dataset Processor\n",
        "# -------------------------\n",
        "class DatasetProcessor:\n",
        "    def __init__(self, solver: OllamaZeroShotMathSolver, failed_folder=None):\n",
        "        self.solver = solver\n",
        "        self.extractor = EnhancedAnswerExtractor()\n",
        "        self.failed_folder = failed_folder or \"failed_extractions\"\n",
        "        os.makedirs(self.failed_folder, exist_ok=True)\n",
        "\n",
        "    def process_dataset(self, dataset_path, output_base_path, start_idx=0, end_idx=None,\n",
        "                        folder_name=None, create_timestamped_folder=True):\n",
        "        dataset = self._load_dataset(dataset_path)\n",
        "        if end_idx is None:\n",
        "            end_idx = len(dataset)\n",
        "\n",
        "        output_folder = self._create_output_folder(output_base_path, folder_name, start_idx, end_idx, create_timestamped_folder)\n",
        "        results = []\n",
        "\n",
        "        print(f\"Processing problems {start_idx} to {end_idx-1} ({end_idx-start_idx} total)\")\n",
        "        print(f\"Output will be saved in: {output_folder}\")\n",
        "\n",
        "        for idx in tqdm(range(start_idx, min(end_idx, len(dataset)))):\n",
        "            problem = dataset[idx]\n",
        "            try:\n",
        "                result_entry = self._process_single_problem(idx, problem)\n",
        "                results.append(result_entry)\n",
        "                self._print_progress(idx, result_entry)\n",
        "                if (idx - start_idx + 1) % 10 == 0:\n",
        "                    self._save_intermediate_results(results, output_folder, idx - start_idx + 1)\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing problem {idx+1}: {str(e)}\")\n",
        "                error_entry = self._create_error_entry(idx, problem, str(e))\n",
        "                results.append(error_entry)\n",
        "\n",
        "        final_output_path = self._save_final_results(results, output_folder, start_idx, end_idx)\n",
        "        self._create_summary_file(results, output_folder, dataset_path, start_idx, end_idx)\n",
        "        return results, output_folder\n",
        "\n",
        "    def _create_output_folder(self, base_path, folder_name, start_idx, end_idx, add_timestamp):\n",
        "        if folder_name is None:\n",
        "            folder_name = f\"results_{start_idx}_to_{end_idx-1}\"\n",
        "        if add_timestamp:\n",
        "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "            folder_name = f\"{folder_name}_{timestamp}\"\n",
        "        output_folder = os.path.join(base_path, folder_name)\n",
        "        os.makedirs(output_folder, exist_ok=True)\n",
        "        return output_folder\n",
        "\n",
        "    def _load_dataset(self, dataset_path):\n",
        "        dataset = []\n",
        "        with open(dataset_path, 'r', encoding='utf-8') as f:\n",
        "            for line in f:\n",
        "                if line.strip():\n",
        "                    dataset.append(json.loads(line))\n",
        "        return dataset\n",
        "\n",
        "    def _process_single_problem(self, idx, problem):\n",
        "        language = problem.get(\"Language\", \"\")\n",
        "        chapter_num = problem.get(\"Chapter Number\", \"\")\n",
        "        example_num = problem.get(\"Example Number\", \"\")\n",
        "        question = problem.get(\"Question\", \"\")\n",
        "        exact_answer = problem.get(\"Exact Answer\", \"\")\n",
        "        raw_answer_type = problem.get(\"Answer Type\", \"\") or \"\"\n",
        "\n",
        "        # Normalize/infer canonical answer type: 'symbolic', 'numerical', 'proof'\n",
        "        canonical_type = normalize_answer_type(raw_answer_type, question_text=question, exact_answer=exact_answer)\n",
        "\n",
        "        # If exact_answer strongly indicates numeric, prefer numerical\n",
        "        if exact_answer and re.search(r'\\d', str(exact_answer)):\n",
        "            # if exact contains LaTeX expressions like \\frac or \\sqrt, keep symbolic\n",
        "            if re.search(r'\\\\frac|\\\\sqrt|\\\\boxed', str(exact_answer)):\n",
        "                pass\n",
        "            else:\n",
        "                canonical_type = \"numerical\"\n",
        "\n",
        "        print(f\"\\nProcessing Problem {idx+1}: Chapter {chapter_num}, Example {example_num}\")\n",
        "        print(f\"Raw Answer Type: '{raw_answer_type}'  --> canonical: '{canonical_type}'\")\n",
        "\n",
        "        # Generate solution (use canonical_type) -- zero-shot, single pass\n",
        "        solution_result = self.solver.solve_problem(question, answer_type=canonical_type)\n",
        "        generated_answer = solution_result.get('generated_answer', '')\n",
        "        thinking_content = solution_result.get('thinking_content', '')  # will be empty\n",
        "        final_tag_output = solution_result.get('final_tag_output', '')\n",
        "\n",
        "        # --- NEW extraction logic: keep both forms (single string & list) ---\n",
        "        # Try to get all <final> answers first (preferred)\n",
        "        all_finals = EnhancedAnswerExtractor.extract_all_final_answers(generated_answer)\n",
        "        extracted_final_answer = \"\"\n",
        "        extracted_final_answers = []\n",
        "\n",
        "        # If none found in generated_answer, try final_tag_output (unused here)\n",
        "        if not all_finals and final_tag_output:\n",
        "            all_finals = EnhancedAnswerExtractor.extract_all_final_answers(final_tag_output)\n",
        "\n",
        "        # If still none, fall back to single-answer extractor\n",
        "        if not all_finals:\n",
        "            single = EnhancedAnswerExtractor.extract_final_answer(generated_answer)\n",
        "            if single:\n",
        "                extracted_final_answer = single\n",
        "                extracted_final_answers = [single]\n",
        "            else:\n",
        "                # try whole combined text (thinking + generated + final_tag)\n",
        "                combined = \"\\n\".join([thinking_content or \"\", generated_answer or \"\", final_tag_output or \"\"])\n",
        "                single = EnhancedAnswerExtractor.extract_final_answer(combined)\n",
        "                if single:\n",
        "                    extracted_final_answer = single\n",
        "                    extracted_final_answers = [single]\n",
        "                else:\n",
        "                    extracted_final_answer = \"\"\n",
        "                    extracted_final_answers = []\n",
        "        else:\n",
        "            # we have one or more finals\n",
        "            extracted_final_answers = all_finals\n",
        "            if len(all_finals) == 1:\n",
        "                extracted_final_answer = all_finals[0]\n",
        "            else:\n",
        "                # store a machine-readable concatenation: JSON array string\n",
        "                try:\n",
        "                    extracted_final_answer = json.dumps(all_finals, ensure_ascii=False)\n",
        "                except Exception:\n",
        "                    extracted_final_answer = \" ||| \".join(all_finals)\n",
        "\n",
        "        # If still empty, save a failed extraction example for inspection\n",
        "        if not extracted_final_answer:\n",
        "            fname = f\"failed_{idx}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
        "            fpath = os.path.join(self.failed_folder, fname)\n",
        "            with open(fpath, 'w', encoding='utf-8') as f:\n",
        "                json.dump({\n",
        "                    \"index\": idx,\n",
        "                    \"question\": question,\n",
        "                    \"generated_answer\": generated_answer,\n",
        "                    \"thinking_content\": thinking_content,\n",
        "                    \"final_tag_output\": final_tag_output,\n",
        "                    \"exact_answer\": exact_answer,\n",
        "                    \"canonical_type\": canonical_type,\n",
        "                    \"extracted_final_answer\": extracted_final_answer,\n",
        "                    \"extracted_final_answers\": extracted_final_answers\n",
        "                }, f, ensure_ascii=False, indent=2)\n",
        "            print(f\"Saved failed extraction example to {fpath}\")\n",
        "\n",
        "        result_entry = {\n",
        "            \"problem_index\": idx,\n",
        "            \"language\": language,\n",
        "            \"chapter_number\": chapter_num,\n",
        "            \"example_number\": example_num,\n",
        "            \"question\": question,\n",
        "            \"generated_answer\": generated_answer,\n",
        "            \"thinking_content\": thinking_content,\n",
        "            \"final_tag_output\": final_tag_output,\n",
        "            \"extracted_final_answer\": extracted_final_answer,       # string (or JSON array string)\n",
        "            \"extracted_final_answers\": extracted_final_answers,     # list (empty / single / many)\n",
        "            \"exact_answer\": exact_answer,\n",
        "            \"raw_answer_type\": raw_answer_type,\n",
        "            \"canonical_answer_type\": canonical_type,\n",
        "            \"evaluation_method\": problem.get(\"Evaluation Method\", \"\")\n",
        "        }\n",
        "        return result_entry\n",
        "\n",
        "    def _create_error_entry(self, idx, problem, error_msg):\n",
        "        return {\n",
        "            \"problem_index\": idx,\n",
        "            \"language\": problem.get(\"Language\", \"\"),\n",
        "            \"chapter_number\": problem.get(\"Chapter Number\", \"\"),\n",
        "            \"example_number\": problem.get(\"Example Number\", \"\"),\n",
        "            \"question\": problem.get(\"Question\", \"\"),\n",
        "            \"generated_answer\": f\"ERROR: {error_msg}\",\n",
        "            \"thinking_content\": \"\",\n",
        "            \"final_tag_output\": \"\",\n",
        "            \"extracted_final_answer\": \"\",\n",
        "            \"extracted_final_answers\": [],\n",
        "            \"exact_answer\": problem.get(\"Exact Answer\", \"\"),\n",
        "            \"raw_answer_type\": problem.get(\"Answer Type\", \"\"),\n",
        "            \"canonical_answer_type\": \"\",\n",
        "            \"evaluation_method\": problem.get(\"Evaluation Method\", \"\")\n",
        "        }\n",
        "\n",
        "    def _print_progress(self, idx, result_entry):\n",
        "        print(f\"Generated answer length: {len(result_entry['generated_answer']) if result_entry['generated_answer'] else 0}\")\n",
        "        print(f\"Extracted final answer: '{result_entry['extracted_final_answer']}'\")\n",
        "        print(f\"Extracted final answers (list): {result_entry.get('extracted_final_answers', [])}\")\n",
        "        print(f\"Expected answer: '{result_entry['exact_answer']}'\")\n",
        "\n",
        "    def _save_intermediate_results(self, results, output_folder, count):\n",
        "        temp_filename = f'intermediate_results_{count}.json'\n",
        "        temp_output_path = os.path.join(output_folder, temp_filename)\n",
        "        with open(temp_output_path, 'w', encoding='utf-8') as f:\n",
        "            json.dump(results, f, ensure_ascii=False, indent=2)\n",
        "        print(f\"Saved intermediate results to {temp_output_path}\")\n",
        "\n",
        "    def _save_final_results(self, results, output_folder, start_idx, end_idx):\n",
        "        final_filename = f'final_results_{start_idx}_to_{end_idx-1}.json'\n",
        "        final_output_path = os.path.join(output_folder, final_filename)\n",
        "        with open(final_output_path, 'w', encoding='utf-8') as f:\n",
        "            json.dump(results, f, ensure_ascii=False, indent=2)\n",
        "        print(f\"\\nProcessing complete. Results saved to {final_output_path}\")\n",
        "        print(f\"Total problems processed: {len(results)}\")\n",
        "        return final_output_path\n",
        "\n",
        "    def _create_summary_file(self, results, output_folder, dataset_path, start_idx, end_idx):\n",
        "        successful_extractions = len([r for r in results if r.get('extracted_final_answer', '').strip()])\n",
        "        summary_data = {\n",
        "            \"processing_info\": {\n",
        "                \"dataset_path\": dataset_path,\n",
        "                \"start_index\": start_idx,\n",
        "                \"end_index\": end_idx - 1,\n",
        "                \"total_processed\": len(results),\n",
        "                \"processing_timestamp\": datetime.now().isoformat(),\n",
        "                \"output_folder\": output_folder\n",
        "            },\n",
        "            \"statistics\": {\n",
        "                \"successful_problems\": len([r for r in results if not r['generated_answer'].startswith('ERROR:')]),\n",
        "                \"failed_problems\": len([r for r in results if r['generated_answer'].startswith('ERROR:')]),\n",
        "                \"successful_extractions\": successful_extractions,\n",
        "                \"extraction_success_rate\": f\"{(successful_extractions/len(results)*100):.1f}%\" if results else \"0%\",\n",
        "                \"average_answer_length\": sum(len(r['generated_answer']) for r in results) / len(results) if results else 0,\n",
        "                \"chapters_processed\": list(set(r['chapter_number'] for r in results if r['chapter_number'])),\n",
        "                \"raw_answer_types\": list(set(r['raw_answer_type'] for r in results if r.get('raw_answer_type'))),\n",
        "                \"canonical_answer_types\": list(set(r['canonical_answer_type'] for r in results if r.get('canonical_answer_type')))\n",
        "            }\n",
        "        }\n",
        "        summary_path = os.path.join(output_folder, 'processing_summary.json')\n",
        "        with open(summary_path, 'w', encoding='utf-8') as f:\n",
        "            json.dump(summary_data, f, ensure_ascii=False, indent=2)\n",
        "        print(f\"Processing summary saved to {summary_path}\")\n",
        "        print(f\"Answer extraction success rate: {summary_data['statistics']['extraction_success_rate']}\")\n",
        "\n",
        "# -------------------------\n",
        "# Main (example usage)\n",
        "# -------------------------\n",
        "def main():\n",
        "    # NOTE: update dataset_path and output_base_path to match your environment.\n",
        "    # Ensure your dataset's \"Question\" fields are in French.\n",
        "    dataset_path = \"/content/French_150_Corpus.jsonl\"\n",
        "    output_base_path = \"/content/\"\n",
        "\n",
        "    # Use the Ollama zero-shot solver (ensure the specified model is available in Ollama)\n",
        "    solver = OllamaZeroShotMathSolver(model_name=\"gpt-oss:20b\")\n",
        "    processor = DatasetProcessor(solver, failed_folder=os.path.join(output_base_path, \"failed_extractions\"))\n",
        "\n",
        "    # For quick testing, process only first few problems\n",
        "    results, out_folder = processor.process_dataset(\n",
        "        dataset_path,\n",
        "        output_base_path,\n",
        "        start_idx=0,\n",
        "        end_idx=150  # smaller quick test\n",
        "    )\n",
        "    print(\"Done. Results saved to:\", out_folder)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "TBJ-WYJUgxAW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Kazakh**"
      ],
      "metadata": {
        "id": "fvJqRgldgpiV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6eW3OlIKbNdf"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "import re\n",
        "from datetime import datetime\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Ollama client\n",
        "try:\n",
        "    import ollama\n",
        "except Exception as e:\n",
        "    raise ImportError(\"The 'ollama' package is required. Install it and make sure the Ollama daemon is running.\") from e\n",
        "\n",
        "# -------------------------\n",
        "# Answer type normalization\n",
        "# -------------------------\n",
        "# Canonical set\n",
        "_CANONICAL_TYPES = {\"symbolic\", \"numerical\", \"proof\"}\n",
        "\n",
        "# mapping common noisy labels to canonical (English + Kazakh variants)\n",
        "_ANSWER_TYPE_MAP_SIMPLE = {\n",
        "    # Proof variants (English -> Kazakh)\n",
        "    \"proof\": \"proof\", \"prove\": \"proof\", \"proove\": \"proof\",\n",
        "    \"дәлел\": \"proof\", \"дәлелдеу\": \"proof\", \"дәлелдену\": \"proof\", \"көрсету\": \"proof\",\n",
        "\n",
        "    # Numerical variants\n",
        "    \"numerical\": \"numerical\", \"numeric\": \"numerical\", \"number\": \"numerical\", \"calculation\": \"numerical\",\n",
        "    \"сандық\": \"numerical\", \"сан\": \"numerical\", \"есептеу\": \"numerical\", \"мәнін\": \"numerical\", \"таб\": \"numerical\",\n",
        "\n",
        "    # Symbolic variants\n",
        "    \"symbolic\": \"symbolic\", \"symbol\": \"symbolic\", \"equation\": \"symbolic\", \"algebraic\": \"symbolic\",\n",
        "    \"теңдеу\": \"symbolic\", \"символдық\": \"symbolic\", \"алгебралық\": \"symbolic\", \"теңдеулер\": \"symbolic\",\n",
        "}\n",
        "\n",
        "\n",
        "def normalize_answer_type(raw_label: str, question_text: str = \"\", exact_answer: str = \"\") -> str:\n",
        "    \"\"\"\n",
        "    Normalize a dataset label to one of: 'symbolic', 'numerical', 'proof'.\n",
        "    Heuristics expanded to handle Kazakh phrases and labels (plus English).\n",
        "    \"\"\"\n",
        "    # Helper to clean label\n",
        "    def _clean_label(lbl: str) -> str:\n",
        "        if not lbl:\n",
        "            return \"\"\n",
        "        s = lbl.strip().lower()\n",
        "        # keep unicode letters (Cyrillic, Latin accents) and digits and spaces\n",
        "        s = re.sub(r'[^0-9\\w\\s\\u0400-\\u04FF\\u0500-\\u052F-]', ' ', s, flags=re.UNICODE)\n",
        "        s = re.sub(r'\\s+', ' ', s).strip()\n",
        "        return s\n",
        "\n",
        "    s = _clean_label(raw_label)\n",
        "\n",
        "    # direct mapping\n",
        "    if s in _ANSWER_TYPE_MAP_SIMPLE:\n",
        "        return _ANSWER_TYPE_MAP_SIMPLE[s]\n",
        "\n",
        "    # partial matches (allow English or Kazakh keywords appearing)\n",
        "    for k, v in _ANSWER_TYPE_MAP_SIMPLE.items():\n",
        "        if k in s:\n",
        "            return v\n",
        "\n",
        "    # heuristics using question or exact_answer (both English & Kazakh checks)\n",
        "    q = (question_text or \"\").lower()\n",
        "    a = (exact_answer or \"\").lower()\n",
        "\n",
        "    # Proof indicators (English + Kazakh)\n",
        "    if re.search(r'\\b(prove|show that|prove that|proof)\\b', q) or re.search(r'\\b(дәлелдеу|дәлел|көрсету|көрсетіңіз|дәлелдеңіз)\\b', q, flags=re.IGNORECASE):\n",
        "        return \"proof\"\n",
        "\n",
        "    # logarithm related: English/Kazakh\n",
        "    if re.search(r'\\b(log|ln|logarithm)\\b', q) or re.search(r'\\b(log|ln|логарифм)\\b', q) or re.search(r'\\blog\\b', a):\n",
        "        # prefer numerical if exact answer contains digits\n",
        "        if re.search(r'\\d', a):\n",
        "            return \"numerical\"\n",
        "        return \"symbolic\"\n",
        "\n",
        "    # set theory indicators: English / Kazakh (use 'жиын' = set)\n",
        "    if re.search(r'\\b(set|subset|union|intersection)\\b', q) or re.search(r'\\b(жиын|асты жиын|қосынды|қиылысу|қисық)\\b', q, flags=re.IGNORECASE):\n",
        "        return \"symbolic\"\n",
        "\n",
        "    # units (English + Kazakh)\n",
        "    if re.search(r'\\bmeter\\b|\\bm\\b|\\bcm\\b|\\bkg\\b|\\bliter\\b|\\bl\\b|\\bkm\\b|\\bmile\\b', q + \" \" + a) or \\\n",
        "       re.search(r'\\bметр\\b|\\bсм\\b|\\bкм\\b|\\bкг\\b|\\bлитр\\b', q + \" \" + a, flags=re.IGNORECASE):\n",
        "        return \"numerical\"\n",
        "\n",
        "    # equation-solving heuristics (English + Kazakh)\n",
        "    if re.search(r'\\bequation\\b|solve for|solve|= x|x\\s*=', q) or re.search(r'\\bтеңдеу\\b|шешу|шешіңдер|шешіңіз|шешу\\b', q, flags=re.IGNORECASE):\n",
        "        return \"symbolic\"\n",
        "\n",
        "    # trig / geometry indicators (English + Kazakh)\n",
        "    if re.search(r'\\b(trig|sin|cos|tan|geometry|triangle|circle)\\b', q) or re.search(r'\\b(триг|sin|cos|tan|геометрия|треугольник|шеңбер|үшбұрыш)\\b', q, flags=re.IGNORECASE):\n",
        "        if re.search(r'\\d', a):\n",
        "            return \"numerical\"\n",
        "        return \"symbolic\"\n",
        "\n",
        "    # numeric indicators (English + Kazakh) -> numerical\n",
        "    if re.search(r'\\d', q) or re.search(r'find the value|compute|calculate|evaluate', q) or \\\n",
        "       re.search(r'мәнін таб|таб(ыңыз|ыңызшы)|есептеу|шығар', q, flags=re.IGNORECASE):\n",
        "        return \"numerical\"\n",
        "\n",
        "    # If exact_answer looks numeric, prefer numerical (but check for LaTeX)\n",
        "    if re.search(r'[0-9]|\\\\frac|\\\\sqrt', a):\n",
        "        if re.search(r'\\\\frac|\\\\sqrt|\\{|\\\\', a):\n",
        "            return \"symbolic\"\n",
        "        return \"numerical\"\n",
        "\n",
        "    # fallback\n",
        "    return \"symbolic\"\n",
        "\n",
        "# -------------------------\n",
        "# EnhancedAnswerExtractor (adapted to behave like SimplifiedAnswerExtractor)\n",
        "# and now handles Kazakh markers as well\n",
        "# -------------------------\n",
        "class EnhancedAnswerExtractor:\n",
        "    \"\"\"\n",
        "    Adapter that implements a simplified extraction behavior (from SimplifiedAnswerExtractor),\n",
        "    extended to recognize Kazakh formatting/conclusion words as well as English.\n",
        "    Provides:\n",
        "      - extract_final_answer(text) -> str\n",
        "      - extract_all_final_answers(generated_solution) -> list\n",
        "    and internal helpers _clean_answer and _is_valid_answer.\n",
        "    \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def _clean_answer(answer: str) -> str:\n",
        "        if not answer:\n",
        "            return \"\"\n",
        "        # Start with a trimmed answer and normalize whitespace\n",
        "        a = answer.strip()\n",
        "        # collapse whitespace\n",
        "        a = re.sub(r'\\s+', ' ', a)\n",
        "\n",
        "        # remove outer $$ if present (multiline)\n",
        "        a = re.sub(r'^\\$\\$(.*)\\$\\$$', r'\\1', a, flags=re.DOTALL)\n",
        "        # remove surrounding single $ if the whole string is wrapped\n",
        "        a = re.sub(r'^\\$(.*)\\$$', r'\\1', a, flags=re.DOTALL)\n",
        "\n",
        "        # strip standalone leading/trailing $ characters and spaces\n",
        "        a = a.strip('$ ')\n",
        "\n",
        "        # Remove common prefixes (kept after stripping $ to catch cases like \"$Final Answer: ...$\")\n",
        "        prefixes_to_remove = [\n",
        "            # English\n",
        "            r'Final Answer:\\s*', r'Answer:\\s*', r'The answer is\\s*',\n",
        "            r'Therefore,?\\s*', r'Thus,?\\s*', r'Hence,?\\s*', r'So,?\\s*', r'∴\\s*',\n",
        "\n",
        "            # Kazakh (Cyrillic common markers)\n",
        "            r'Жауап[:\\s]*', r'Соңғы жауап[:\\s]*', r'Қорытынды[:\\s]*', r'Шешімі[:\\s]*',\n",
        "            r'Нәтиже[:\\s]*', r'Сондықтан,?\\s*', r'Демек,?\\s*', r'Осындайша,?\\s*', r'Осыдан,?\\s*',\n",
        "        ]\n",
        "        for prefix in prefixes_to_remove:\n",
        "            a = re.sub(f'^{prefix}', '', a, flags=re.IGNORECASE)\n",
        "\n",
        "        # remove various boxed wrappers with optional backslashes and optional surrounding $\n",
        "        # e.g. $$\\boxed{...}$$, $\\boxed{...}$, \\boxed{...}\n",
        "        a = re.sub(r'\\$?\\s*(?:\\\\){0,3}boxed\\{([^}]*)\\}\\s*\\$?', r'\\1', a, flags=re.DOTALL | re.IGNORECASE)\n",
        "        # also ensure plain \\boxed{...} is unwrapped (redundant but safe)\n",
        "        a = re.sub(r'\\\\boxed\\{([^}]*)\\}', r'\\1', a)\n",
        "\n",
        "        # convert common LaTeX to readable forms\n",
        "        a = re.sub(r'\\\\frac\\{([^}]*)\\}\\{([^}]*)\\}', r'(\\1)/(\\2)', a)\n",
        "        a = re.sub(r'\\\\sqrt\\{([^}]*)\\}', r'√(\\1)', a)\n",
        "\n",
        "        # remove bold/italic wrappers\n",
        "        a = re.sub(r'\\*\\*([^*]+)\\*\\*', r'\\1', a)\n",
        "        a = re.sub(r'\\*([^*]+)\\*', r'\\1', a)\n",
        "\n",
        "        # collapse multiple spaces again (in case replacements introduced them)\n",
        "        a = re.sub(r'\\s+', ' ', a).strip()\n",
        "\n",
        "        # trim trailing punctuation/words\n",
        "        a = a.rstrip(' \\t\\n.,;:')\n",
        "\n",
        "        # remove trailing words like \"proved\" or \"the answer\" (English & Kazakh)\n",
        "        a = re.sub(r'\\b(proved|completed|finished|the answer|prouvé|prouve|la réponse|дәлелденді|дәлел|жауап)\\b[.\\s]*$', '', a, flags=re.IGNORECASE).strip()\n",
        "\n",
        "        return a\n",
        "\n",
        "    @staticmethod\n",
        "    def _is_valid_answer(answer: str) -> bool:\n",
        "        if not answer:\n",
        "            return False\n",
        "        # not only punctuation\n",
        "        if re.match(r'^[\\W_]+$', answer):\n",
        "            return False\n",
        "        # contains at least some alphanumeric characters (or common math symbols)\n",
        "        if not re.search(r'[0-9A-Za-z\\u0400-\\u04FF\\\\]', answer):\n",
        "            return False\n",
        "        # length sanity\n",
        "        if len(answer) > 1000:\n",
        "            return False\n",
        "        # avoid answers that end with only concluding words (English & Kazakh)\n",
        "        blacklist = [r'therefore$', r'thus$', r'hence$', r'so$', r'we get$', r'we have$', r'сондықтан$', r'демек$', r'осылайша$']\n",
        "        for b in blacklist:\n",
        "            if re.search(b, answer.strip(), flags=re.IGNORECASE):\n",
        "                return False\n",
        "        return True\n",
        "\n",
        "    @staticmethod\n",
        "    def extract_final_answer_simple(text: str) -> str:\n",
        "        \"\"\"\n",
        "        Primary method: Extract final answer using the last lines approach,\n",
        "        with fallback to pattern-based extraction.\n",
        "        \"\"\"\n",
        "        if not text:\n",
        "            return \"\"\n",
        "\n",
        "        # Clean the text and split into lines\n",
        "        lines = [line.strip() for line in text.strip().split('\\n') if line.strip()]\n",
        "\n",
        "        # Strategy 1: Try last two lines combined\n",
        "        if len(lines) >= 2:\n",
        "            last_two = ' '.join(lines[-2:])\n",
        "            cleaned = EnhancedAnswerExtractor._clean_answer(last_two)\n",
        "            if EnhancedAnswerExtractor._is_valid_answer(cleaned):\n",
        "                return cleaned\n",
        "\n",
        "        # Strategy 2: Try last line only\n",
        "        if lines:\n",
        "            cleaned = EnhancedAnswerExtractor._clean_answer(lines[-1])\n",
        "            if EnhancedAnswerExtractor._is_valid_answer(cleaned):\n",
        "                return cleaned\n",
        "\n",
        "        # Strategy 3: Try last 3 lines if we have them (sometimes answers span multiple lines)\n",
        "        if len(lines) >= 3:\n",
        "            last_three = ' '.join(lines[-3:])\n",
        "            cleaned = EnhancedAnswerExtractor._clean_answer(last_three)\n",
        "            if EnhancedAnswerExtractor._is_valid_answer(cleaned) and len(cleaned) < 500:\n",
        "                return cleaned\n",
        "\n",
        "        # Strategy 4: Fallback to pattern-based extraction\n",
        "        return EnhancedAnswerExtractor._extract_with_patterns(text)\n",
        "\n",
        "    @staticmethod\n",
        "    def _extract_with_patterns(text: str) -> str:\n",
        "        \"\"\"\n",
        "        Pattern-based extraction as fallback method.\n",
        "        Recognizes English and Kazakh answer/conclusion patterns.\n",
        "        \"\"\"\n",
        "        # Check for <final> tags\n",
        "        raw_matches = re.findall(r'<final>(.*?)</final>', text, re.DOTALL | re.IGNORECASE)\n",
        "        for m in raw_matches:\n",
        "            c = EnhancedAnswerExtractor._clean_answer(m)\n",
        "            if EnhancedAnswerExtractor._is_valid_answer(c):\n",
        "                return c\n",
        "\n",
        "        # Try common answer patterns (English + Kazakh)\n",
        "        patterns = [\n",
        "            r'\\*\\*Final Answer:\\*\\*\\s*(.+?)(?:\\n|$)',\n",
        "            r'Final Answer:\\s*(.+?)(?:\\n|$)',\n",
        "            r'Final Answer\\s*[:\\-]\\s*(.+?)(?:\\n|$)',\n",
        "\n",
        "            # Kazakh patterns\n",
        "            r'\\*\\*Соңғы жауап:\\*\\*\\s*(.+?)(?:\\n|$)',\n",
        "            r'Соңғы жауап[:\\s]*(.+?)(?:\\n|$)',\n",
        "            r'Жауап[:\\s]*(.+?)(?:\\n|$)',\n",
        "            r'Қорытынды[:\\s]*(.+?)(?:\\n|$)',\n",
        "            r'Нәтиже[:\\s]*(.+?)(?:\\n|$)',\n",
        "\n",
        "            # English conclusion markers\n",
        "            r'Therefore[,:\\s]*(.+?)(?:\\.|$|\\n)',\n",
        "            r'Hence[,:\\s]*(.+?)(?:\\.|$|\\n)',\n",
        "            r'Thus[,:\\s]*(.+?)(?:\\.|$|\\n)',\n",
        "            r'∴\\s*(.+?)(?:\\.|$|\\n)',\n",
        "\n",
        "            # Kazakh conclusion markers\n",
        "            r'Сондықтан[,:\\s]*(.+?)(?:\\.|$|\\n)',\n",
        "            r'Демек[,:\\s]*(.+?)(?:\\.|$|\\n)',\n",
        "            r'Осыдан[,:\\s]*(.+?)(?:\\.|$|\\n)',\n",
        "            r'Осындайша[,:\\s]*(.+?)(?:\\.|$|\\n)',\n",
        "\n",
        "            r'Answer[:\\s]*(.+?)(?:\\n|$)',\n",
        "            r'Result[:\\s]*(.+?)(?:\\n|$)',\n",
        "            r'Solution[:\\s]*(.+?)(?:\\n|$)',\n",
        "        ]\n",
        "\n",
        "        for pat in patterns:\n",
        "            matches = re.findall(pat, text, re.MULTILINE | re.DOTALL | re.IGNORECASE)\n",
        "            if matches:\n",
        "                answer = matches[-1].strip()\n",
        "                cleaned = EnhancedAnswerExtractor._clean_answer(answer)\n",
        "                if EnhancedAnswerExtractor._is_valid_answer(cleaned):\n",
        "                    return cleaned\n",
        "\n",
        "        # Try boxed math expressions (LaTeX boxed)\n",
        "        boxed_patterns = [\n",
        "            r'\\$\\$\\s*(?:\\\\){0,3}boxed\\{(.+?)\\}\\s*\\$\\$',\n",
        "            r'\\$\\s*(?:\\\\){0,3}boxed\\{(.+?)\\}\\s*\\$',\n",
        "            r'(?:\\\\){0,3}boxed\\{(.+?)\\}',\n",
        "        ]\n",
        "\n",
        "        for pat in boxed_patterns:\n",
        "            m = re.search(pat, text, re.DOTALL | re.IGNORECASE)\n",
        "            if m:\n",
        "                cand = EnhancedAnswerExtractor._clean_answer(m.group(1))\n",
        "                if EnhancedAnswerExtractor._is_valid_answer(cand):\n",
        "                    return cand\n",
        "\n",
        "        return \"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def extract_all_final_answers(generated_solution: str) -> list:\n",
        "        \"\"\"\n",
        "        Extract multiple final answers using simplified approach.\n",
        "        Returns a list (possibly empty) of cleaned answers found inside all <final>...</final> tags.\n",
        "        Falls back to the single simplified extraction if no tags are found.\n",
        "        \"\"\"\n",
        "        if not generated_solution:\n",
        "            return []\n",
        "\n",
        "        # Find all <final>...</final> (non-greedy)\n",
        "        raw_matches = re.findall(r'<final>(.*?)</final>', generated_solution, re.DOTALL | re.IGNORECASE)\n",
        "        cleaned = []\n",
        "        for m in raw_matches:\n",
        "            c = EnhancedAnswerExtractor._clean_answer(m)\n",
        "            if EnhancedAnswerExtractor._is_valid_answer(c):\n",
        "                cleaned.append(c)\n",
        "\n",
        "        if cleaned:\n",
        "            return cleaned\n",
        "\n",
        "        # Fallback: try to extract a single final using the simpler logic\n",
        "        simple_answer = EnhancedAnswerExtractor.extract_final_answer_simple(generated_solution)\n",
        "        if simple_answer:\n",
        "            return [simple_answer]\n",
        "\n",
        "        return []\n",
        "\n",
        "    @staticmethod\n",
        "    def extract_final_answer(generated_solution: str) -> str:\n",
        "        \"\"\"\n",
        "        Backwards-compatible extractor that delegates to the simplified extraction.\n",
        "        If multiple <final> tags exist, returns a JSON array string of cleaned answers.\n",
        "        \"\"\"\n",
        "        if not generated_solution:\n",
        "            return \"\"\n",
        "\n",
        "        # Prefer explicit <final> tags (can be multiple)\n",
        "        raw_matches = re.findall(r'<final>(.*?)</final>', generated_solution, re.DOTALL | re.IGNORECASE)\n",
        "        if raw_matches:\n",
        "            cleaned = []\n",
        "            for m in raw_matches:\n",
        "                c = EnhancedAnswerExtractor._clean_answer(m)\n",
        "                if EnhancedAnswerExtractor._is_valid_answer(c):\n",
        "                    cleaned.append(c)\n",
        "            if not cleaned:\n",
        "                # fall through to simpler single extraction\n",
        "                return EnhancedAnswerExtractor.extract_final_answer_simple(generated_solution)\n",
        "            if len(cleaned) == 1:\n",
        "                return cleaned[0]\n",
        "            try:\n",
        "                return json.dumps(cleaned, ensure_ascii=False)\n",
        "            except Exception:\n",
        "                return \" ||| \".join(cleaned)\n",
        "\n",
        "        # No explicit finals: use simplified single extraction\n",
        "        return EnhancedAnswerExtractor.extract_final_answer_simple(generated_solution)\n",
        "\n",
        "# -------------------------\n",
        "# Ollama-based Math Solver (ZERO-SHOT) — PROMPTS IN ENGLISH (problem is Kazakh)\n",
        "# -------------------------\n",
        "class OllamaZeroShotMathSolver:\n",
        "    \"\"\"\n",
        "    Zero-shot math solver that uses the Ollama daemon via the Python client.\n",
        "    Prompts/instructions are written in English (as requested), but the solver is informed that\n",
        "    the problem text will be in KAZAKH and is instructed to provide a concise final answer in KAZAKH.\n",
        "    - Zero-shot prompt: forbids chain-of-thought and requests concise final <final> tag\n",
        "    - Single-pass only.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model_name=\"qwen3:8b\"):\n",
        "        \"\"\"\n",
        "        model_name: the Ollama model reference (e.g., \"qwen3:8b\")\n",
        "        \"\"\"\n",
        "        self.model_name = model_name\n",
        "        self.client = self._load_client()\n",
        "\n",
        "    def _load_client(self):\n",
        "        print(f\"Initializing Ollama client for model: {self.model_name}\")\n",
        "        client = ollama.Client()\n",
        "        return client\n",
        "\n",
        "    def cleanup(self):\n",
        "        if hasattr(self, 'client'):\n",
        "            del self.client\n",
        "\n",
        "    def _get_format_instructions(self, answer_type):\n",
        "        \"\"\"\n",
        "        Zero-shot formatting instructions (WRITTEN IN ENGLISH).\n",
        "        The model is explicitly informed that the problem text is in KAZAKH and that the concise final\n",
        "        answer should be provided in KAZAKH. Examples/formats are shown in English but demonstrate\n",
        "        that the final tag must contain the concise Kazakh answer.\n",
        "        \"\"\"\n",
        "        t = (answer_type or \"symbolic\").strip().lower()\n",
        "        if t not in _CANONICAL_TYPES:\n",
        "            t = \"symbolic\"\n",
        "\n",
        "        base = (\n",
        "            \"CRITICAL FORMATTING REQUIREMENTS (ZERO-SHOT):\\n\"\n",
        "            \"- The math problem you will receive is written in KAZAKH. Provide your concise FINAL ANSWER in KAZAKH.\\n\"\n",
        "            \"- DO NOT provide chain-of-thought or step-by-step internal reasoning. Do NOT reveal private chain-of-thought.\\n\"\n",
        "            \"- If a very short justification is necessary, include a single-line 'Explanation:' with at most one sentence (in Kazakh).\\n\"\n",
        "            \"- Always end with a machine-readable final tag <final>...</final> containing ONLY the concise final answer in KAZAKH (no extra reasoning inside the tag).\\n\"\n",
        "        )\n",
        "\n",
        "        if t == \"proof\":\n",
        "            return base + (\n",
        "                \"FOR PROOFS (zero-shot):\\n\"\n",
        "                \"- Provide a concise conclusion or a one-sentence proof sketch (in KAZAKH) labeled 'Қорытынды:' or 'Esquisse de preuve:' if needed. Do NOT provide a full step-by-step proof.\\n\"\n",
        "                \"Format example (English instructions):\\n\"\n",
        "                \"Final Answer (in Kazakh):\\n\"\n",
        "                \"[Concise Kazakh conclusion or one-sentence sketch]\\n\\n\"\n",
        "                \"<final>[Concise Kazakh conclusion]</final>\\n\"\n",
        "            )\n",
        "        elif t == \"numerical\":\n",
        "            return base + (\n",
        "                \"FOR NUMERICAL RESULTS:\\n\"\n",
        "                \"- Provide the numeric result in exact form if available (fractions/radicals). Otherwise provide a decimal rounded to 4 decimal places.\\n\"\n",
        "                \"Format example (English instructions):\\n\"\n",
        "                \"Final Answer (in Kazakh):\\n\"\n",
        "                \"[Numeric result]\\n\\n\"\n",
        "                \"<final>[Numeric result]</final>\\n\"\n",
        "            )\n",
        "        else:  # symbolic\n",
        "            return base + (\n",
        "                \"FOR SYMBOLIC RESULTS:\\n\"\n",
        "                \"- Provide the final symbolic expression (LaTeX allowed) in a concise form. The expression may be LaTeX but any wording should be in Kazakh if used.\\n\"\n",
        "                \"Format example (English instructions):\\n\"\n",
        "                \"Final Answer (in Kazakh):\\n\"\n",
        "                \"[Final symbolic expression]\\n\\n\"\n",
        "                \"<final>[LaTeX expression or concise symbolic expression — in Kazakh if words are used]</final>\\n\"\n",
        "            )\n",
        "\n",
        "    def _create_prompt(self, question, answer_type=\"symbolic\"):\n",
        "        format_instructions = self._get_format_instructions(answer_type)\n",
        "\n",
        "        # The main instruction is in English (per your requirement), but it states the problem language and required answer language.\n",
        "        prompt = f\"\"\"You are an expert mathematician. The following math problem is written in KAZAKH.\n",
        "Provide a concise final answer in KAZAKH. DO NOT produce chain-of-thought or step-by-step internal reasoning.\n",
        "If you include a justification, it must be one short sentence and labeled 'Explanation:' (in Kazakh).\n",
        "\n",
        "MATH PROBLEM (in Kazakh):\n",
        "{question}\n",
        "\n",
        "{format_instructions}\n",
        "\n",
        "Begin your concise answer (in Kazakh) now:\n",
        "\"\"\"\n",
        "        return prompt\n",
        "\n",
        "    def _generate_once(self, prompt_text: str, enable_thinking: bool = False) -> str:\n",
        "        \"\"\"\n",
        "        Call ollama.Client.chat WITHOUT temperature/max_tokens.\n",
        "        Handles several possible response shapes.\n",
        "        \"\"\"\n",
        "        messages = [{\"role\": \"user\", \"content\": prompt_text}]\n",
        "\n",
        "        # Call Ollama client.chat without temperature/max_tokens\n",
        "        try:\n",
        "            resp = self.client.chat(model=self.model_name, messages=messages, think=enable_thinking)\n",
        "        except TypeError:\n",
        "            # Some client versions have different signatures\n",
        "            try:\n",
        "                resp = self.client.chat(self.model_name, messages=messages, think=enable_thinking)\n",
        "            except Exception:\n",
        "                resp = self.client.chat(self.model_name, messages)\n",
        "\n",
        "        # Normalize response into a string\n",
        "        full_output = \"\"\n",
        "        if isinstance(resp, dict):\n",
        "            if 'message' in resp and isinstance(resp['message'], dict) and 'content' in resp['message']:\n",
        "                full_output = resp['message']['content']\n",
        "            elif 'choices' in resp and isinstance(resp['choices'], (list, tuple)) and resp['choices']:\n",
        "                choice = resp['choices'][0]\n",
        "                if isinstance(choice, dict) and 'message' in choice and isinstance(choice['message'], dict):\n",
        "                    full_output = choice['message'].get('content', '')\n",
        "                else:\n",
        "                    full_output = str(choice)\n",
        "            else:\n",
        "                full_output = str(resp)\n",
        "        else:\n",
        "            # resp might be an object with .message.content\n",
        "            try:\n",
        "                full_output = resp.message.content\n",
        "            except Exception:\n",
        "                full_output = str(resp)\n",
        "\n",
        "        if isinstance(full_output, bytes):\n",
        "            full_output = full_output.decode('utf-8', errors='ignore')\n",
        "        return (full_output or \"\").strip()\n",
        "\n",
        "    def solve_problem(self, question, answer_type=\"symbolic\"):\n",
        "        \"\"\"\n",
        "        Zero-shot single-pass solve via Ollama.\n",
        "        \"\"\"\n",
        "        prompt = self._create_prompt(question, answer_type)\n",
        "        full_output = self._generate_once(prompt, enable_thinking=False)\n",
        "\n",
        "        # No thinking parsing for zero-shot mode\n",
        "        thinking_content = \"\"\n",
        "        generated_answer = full_output\n",
        "        final_tag_output = \"\"  # no second pass\n",
        "\n",
        "        extracted_final_answer = EnhancedAnswerExtractor.extract_final_answer(generated_answer)\n",
        "\n",
        "        return {\n",
        "            \"thinking_content\": thinking_content,\n",
        "            \"generated_answer\": generated_answer,\n",
        "            \"final_tag_output\": final_tag_output,\n",
        "            \"extracted_final_answer\": extracted_final_answer\n",
        "        }\n",
        "\n",
        "# -------------------------\n",
        "# Dataset Processor\n",
        "# -------------------------\n",
        "class DatasetProcessor:\n",
        "    def __init__(self, solver: OllamaZeroShotMathSolver, failed_folder=None):\n",
        "        self.solver = solver\n",
        "        self.extractor = EnhancedAnswerExtractor()\n",
        "        self.failed_folder = failed_folder or \"failed_extractions\"\n",
        "        os.makedirs(self.failed_folder, exist_ok=True)\n",
        "\n",
        "    def process_dataset(self, dataset_path, output_base_path, start_idx=0, end_idx=None,\n",
        "                        folder_name=None, create_timestamped_folder=True):\n",
        "        dataset = self._load_dataset(dataset_path)\n",
        "        if end_idx is None:\n",
        "            end_idx = len(dataset)\n",
        "\n",
        "        output_folder = self._create_output_folder(output_base_path, folder_name, start_idx, end_idx, create_timestamped_folder)\n",
        "        results = []\n",
        "\n",
        "        print(f\"Processing problems {start_idx} to {end_idx-1} ({end_idx-start_idx} total)\")\n",
        "        print(f\"Output will be saved in: {output_folder}\")\n",
        "\n",
        "        for idx in tqdm(range(start_idx, min(end_idx, len(dataset)))):\n",
        "            problem = dataset[idx]\n",
        "            try:\n",
        "                result_entry = self._process_single_problem(idx, problem)\n",
        "                results.append(result_entry)\n",
        "                self._print_progress(idx, result_entry)\n",
        "                if (idx - start_idx + 1) % 10 == 0:\n",
        "                    self._save_intermediate_results(results, output_folder, idx - start_idx + 1)\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing problem {idx+1}: {str(e)}\")\n",
        "                error_entry = self._create_error_entry(idx, problem, str(e))\n",
        "                results.append(error_entry)\n",
        "\n",
        "        final_output_path = self._save_final_results(results, output_folder, start_idx, end_idx)\n",
        "        self._create_summary_file(results, output_folder, dataset_path, start_idx, end_idx)\n",
        "        return results, output_folder\n",
        "\n",
        "    def _create_output_folder(self, base_path, folder_name, start_idx, end_idx, add_timestamp):\n",
        "        if folder_name is None:\n",
        "            folder_name = f\"results_{start_idx}_to_{end_idx-1}\"\n",
        "        if add_timestamp:\n",
        "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "            folder_name = f\"{folder_name}_{timestamp}\"\n",
        "        output_folder = os.path.join(base_path, folder_name)\n",
        "        os.makedirs(output_folder, exist_ok=True)\n",
        "        return output_folder\n",
        "\n",
        "    def _load_dataset(self, dataset_path):\n",
        "        dataset = []\n",
        "        with open(dataset_path, 'r', encoding='utf-8') as f:\n",
        "            for line in f:\n",
        "                if line.strip():\n",
        "                    dataset.append(json.loads(line))\n",
        "        return dataset\n",
        "\n",
        "    def _process_single_problem(self, idx, problem):\n",
        "        language = problem.get(\"Language\", \"\")\n",
        "        chapter_num = problem.get(\"Chapter Number\", \"\")\n",
        "        example_num = problem.get(\"Example Number\", \"\")\n",
        "        question = problem.get(\"Question\", \"\")\n",
        "        exact_answer = problem.get(\"Exact Answer\", \"\")\n",
        "        raw_answer_type = problem.get(\"Answer Type\", \"\") or \"\"\n",
        "\n",
        "        # Normalize/infer canonical answer type: 'symbolic', 'numerical', 'proof'\n",
        "        canonical_type = normalize_answer_type(raw_answer_type, question_text=question, exact_answer=exact_answer)\n",
        "\n",
        "        # If exact_answer strongly indicates numeric, prefer numerical\n",
        "        if exact_answer and re.search(r'\\d', str(exact_answer)):\n",
        "            # if exact contains LaTeX expressions like \\frac or \\sqrt, keep symbolic\n",
        "            if re.search(r'\\\\frac|\\\\sqrt|\\\\boxed', str(exact_answer)):\n",
        "                pass\n",
        "            else:\n",
        "                canonical_type = \"numerical\"\n",
        "\n",
        "        print(f\"\\nProcessing Problem {idx+1}: Chapter {chapter_num}, Example {example_num}\")\n",
        "        print(f\"Raw Answer Type: '{raw_answer_type}'  --> canonical: '{canonical_type}'\")\n",
        "\n",
        "        # Generate solution (use canonical_type) -- zero-shot, single pass\n",
        "        solution_result = self.solver.solve_problem(question, answer_type=canonical_type)\n",
        "        generated_answer = solution_result.get('generated_answer', '')\n",
        "        thinking_content = solution_result.get('thinking_content', '')  # will be empty\n",
        "        final_tag_output = solution_result.get('final_tag_output', '')\n",
        "\n",
        "        # --- NEW extraction logic: keep both forms (single string & list) ---\n",
        "        # Try to get all <final> answers first (preferred)\n",
        "        all_finals = EnhancedAnswerExtractor.extract_all_final_answers(generated_answer)\n",
        "        extracted_final_answer = \"\"\n",
        "        extracted_final_answers = []\n",
        "\n",
        "        # If none found in generated_answer, try final_tag_output (unused here)\n",
        "        if not all_finals and final_tag_output:\n",
        "            all_finals = EnhancedAnswerExtractor.extract_all_final_answers(final_tag_output)\n",
        "\n",
        "        # If still none, fall back to single-answer extractor\n",
        "        if not all_finals:\n",
        "            single = EnhancedAnswerExtractor.extract_final_answer(generated_answer)\n",
        "            if single:\n",
        "                extracted_final_answer = single\n",
        "                extracted_final_answers = [single]\n",
        "            else:\n",
        "                # try whole combined text (thinking + generated + final_tag)\n",
        "                combined = \"\\n\".join([thinking_content or \"\", generated_answer or \"\", final_tag_output or \"\"])\n",
        "                single = EnhancedAnswerExtractor.extract_final_answer(combined)\n",
        "                if single:\n",
        "                    extracted_final_answer = single\n",
        "                    extracted_final_answers = [single]\n",
        "                else:\n",
        "                    extracted_final_answer = \"\"\n",
        "                    extracted_final_answers = []\n",
        "        else:\n",
        "            # we have one or more finals\n",
        "            extracted_final_answers = all_finals\n",
        "            if len(all_finals) == 1:\n",
        "                extracted_final_answer = all_finals[0]\n",
        "            else:\n",
        "                # store a machine-readable concatenation: JSON array string\n",
        "                try:\n",
        "                    extracted_final_answer = json.dumps(all_finals, ensure_ascii=False)\n",
        "                except Exception:\n",
        "                    extracted_final_answer = \" ||| \".join(all_finals)\n",
        "\n",
        "        # If still empty, save a failed extraction example for inspection\n",
        "        if not extracted_final_answer:\n",
        "            fname = f\"failed_{idx}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
        "            fpath = os.path.join(self.failed_folder, fname)\n",
        "            with open(fpath, 'w', encoding='utf-8') as f:\n",
        "                json.dump({\n",
        "                    \"index\": idx,\n",
        "                    \"question\": question,\n",
        "                    \"generated_answer\": generated_answer,\n",
        "                    \"thinking_content\": thinking_content,\n",
        "                    \"final_tag_output\": final_tag_output,\n",
        "                    \"exact_answer\": exact_answer,\n",
        "                    \"canonical_type\": canonical_type,\n",
        "                    \"extracted_final_answer\": extracted_final_answer,\n",
        "                    \"extracted_final_answers\": extracted_final_answers\n",
        "                }, f, ensure_ascii=False, indent=2)\n",
        "            print(f\"Saved failed extraction example to {fpath}\")\n",
        "\n",
        "        result_entry = {\n",
        "            \"problem_index\": idx,\n",
        "            \"language\": language,\n",
        "            \"chapter_number\": chapter_num,\n",
        "            \"example_number\": example_num,\n",
        "            \"question\": question,\n",
        "            \"generated_answer\": generated_answer,\n",
        "            \"thinking_content\": thinking_content,\n",
        "            \"final_tag_output\": final_tag_output,\n",
        "            \"extracted_final_answer\": extracted_final_answer,       # string (or JSON array string)\n",
        "            \"extracted_final_answers\": extracted_final_answers,     # list (empty / single / many)\n",
        "            \"exact_answer\": exact_answer,\n",
        "            \"raw_answer_type\": raw_answer_type,\n",
        "            \"canonical_answer_type\": canonical_type,\n",
        "            \"evaluation_method\": problem.get(\"Evaluation Method\", \"\")\n",
        "        }\n",
        "        return result_entry\n",
        "\n",
        "    def _create_error_entry(self, idx, problem, error_msg):\n",
        "        return {\n",
        "            \"problem_index\": idx,\n",
        "            \"language\": problem.get(\"Language\", \"\"),\n",
        "            \"chapter_number\": problem.get(\"Chapter Number\", \"\"),\n",
        "            \"example_number\": problem.get(\"Example Number\", \"\"),\n",
        "            \"question\": problem.get(\"Question\", \"\"),\n",
        "            \"generated_answer\": f\"ERROR: {error_msg}\",\n",
        "            \"thinking_content\": \"\",\n",
        "            \"final_tag_output\": \"\",\n",
        "            \"extracted_final_answer\": \"\",\n",
        "            \"extracted_final_answers\": [],\n",
        "            \"exact_answer\": problem.get(\"Exact Answer\", \"\"),\n",
        "            \"raw_answer_type\": problem.get(\"Answer Type\", \"\"),\n",
        "            \"canonical_answer_type\": \"\",\n",
        "            \"evaluation_method\": problem.get(\"Evaluation Method\", \"\")\n",
        "        }\n",
        "\n",
        "    def _print_progress(self, idx, result_entry):\n",
        "        print(f\"Generated answer length: {len(result_entry['generated_answer']) if result_entry['generated_answer'] else 0}\")\n",
        "        print(f\"Extracted final answer: '{result_entry['extracted_final_answer']}'\")\n",
        "        print(f\"Extracted final answers (list): {result_entry.get('extracted_final_answers', [])}\")\n",
        "        print(f\"Expected answer: '{result_entry['exact_answer']}'\")\n",
        "\n",
        "    def _save_intermediate_results(self, results, output_folder, count):\n",
        "        temp_filename = f'intermediate_results_{count}.json'\n",
        "        temp_output_path = os.path.join(output_folder, temp_filename)\n",
        "        with open(temp_output_path, 'w', encoding='utf-8') as f:\n",
        "            json.dump(results, f, ensure_ascii=False, indent=2)\n",
        "        print(f\"Saved intermediate results to {temp_output_path}\")\n",
        "\n",
        "    def _save_final_results(self, results, output_folder, start_idx, end_idx):\n",
        "        final_filename = f'final_results_{start_idx}_to_{end_idx-1}.json'\n",
        "        final_output_path = os.path.join(output_folder, final_filename)\n",
        "        with open(final_output_path, 'w', encoding='utf-8') as f:\n",
        "            json.dump(results, f, ensure_ascii=False, indent=2)\n",
        "        print(f\"\\nProcessing complete. Results saved to {final_output_path}\")\n",
        "        print(f\"Total problems processed: {len(results)}\")\n",
        "        return final_output_path\n",
        "\n",
        "    def _create_summary_file(self, results, output_folder, dataset_path, start_idx, end_idx):\n",
        "        successful_extractions = len([r for r in results if r.get('extracted_final_answer', '').strip()])\n",
        "        summary_data = {\n",
        "            \"processing_info\": {\n",
        "                \"dataset_path\": dataset_path,\n",
        "                \"start_index\": start_idx,\n",
        "                \"end_index\": end_idx - 1,\n",
        "                \"total_processed\": len(results),\n",
        "                \"processing_timestamp\": datetime.now().isoformat(),\n",
        "                \"output_folder\": output_folder\n",
        "            },\n",
        "            \"statistics\": {\n",
        "                \"successful_problems\": len([r for r in results if not r['generated_answer'].startswith('ERROR:')]),\n",
        "                \"failed_problems\": len([r for r in results if r['generated_answer'].startswith('ERROR:')]),\n",
        "                \"successful_extractions\": successful_extractions,\n",
        "                \"extraction_success_rate\": f\"{(successful_extractions/len(results)*100):.1f}%\" if results else \"0%\",\n",
        "                \"average_answer_length\": sum(len(r['generated_answer']) for r in results) / len(results) if results else 0,\n",
        "                \"chapters_processed\": list(set(r['chapter_number'] for r in results if r['chapter_number'])),\n",
        "                \"raw_answer_types\": list(set(r['raw_answer_type'] for r in results if r.get('raw_answer_type'))),\n",
        "                \"canonical_answer_types\": list(set(r['canonical_answer_type'] for r in results if r.get('canonical_answer_type')))\n",
        "            }\n",
        "        }\n",
        "        summary_path = os.path.join(output_folder, 'processing_summary.json')\n",
        "        with open(summary_path, 'w', encoding='utf-8') as f:\n",
        "            json.dump(summary_data, f, ensure_ascii=False, indent=2)\n",
        "        print(f\"Processing summary saved to {summary_path}\")\n",
        "        print(f\"Answer extraction success rate: {summary_data['statistics']['extraction_success_rate']}\")\n",
        "\n",
        "# -------------------------\n",
        "# Main (example usage)\n",
        "# -------------------------\n",
        "def main():\n",
        "    # NOTE: update dataset_path and output_base_path to match your environment.\n",
        "    # Ensure your dataset's \"Question\" fields are in Kazakh.\n",
        "    dataset_path = \"/kaggle/input/nctb-dataset/Kazakh_Final_Corpus.jsonl\"\n",
        "    output_base_path = \"/kaggle/working/\"\n",
        "\n",
        "    # Use the Ollama zero-shot solver (ensure the specified model is available in Ollama)\n",
        "    solver = OllamaZeroShotMathSolver(model_name=\"qwen3:8b\")\n",
        "    processor = DatasetProcessor(solver, failed_folder=os.path.join(output_base_path, \"failed_extractions\"))\n",
        "\n",
        "    # For quick testing, process only first few problems\n",
        "    results, out_folder = processor.process_dataset(\n",
        "        dataset_path,\n",
        "        output_base_path,\n",
        "        start_idx=0,\n",
        "        end_idx=100  # smaller quick test\n",
        "    )\n",
        "    print(\"Done. Results saved to:\", out_folder)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Finnish**"
      ],
      "metadata": {
        "id": "l-XZx4KmcHO6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "import re\n",
        "from datetime import datetime\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Ollama client\n",
        "try:\n",
        "    import ollama\n",
        "except Exception as e:\n",
        "    raise ImportError(\"The 'ollama' package is required. Install it and make sure the Ollama daemon is running.\") from e\n",
        "\n",
        "# -------------------------\n",
        "# Answer type normalization\n",
        "# -------------------------\n",
        "# Canonical set\n",
        "_CANONICAL_TYPES = {\"symbolic\", \"numerical\", \"proof\"}\n",
        "\n",
        "# mapping common noisy labels to canonical (English + Finnish variants)\n",
        "_ANSWER_TYPE_MAP_SIMPLE = {\n",
        "    # Proof variants (English -> Finnish)\n",
        "    \"proof\": \"proof\", \"prove\": \"proof\",\n",
        "    \"todistus\": \"proof\", \"todista\": \"proof\", \"todistaa\": \"proof\", \"näytä\": \"proof\", \"näytä että\": \"proof\",\n",
        "\n",
        "    # Numerical variants\n",
        "    \"numerical\": \"numerical\", \"numeric\": \"numerical\", \"number\": \"numerical\", \"calculation\": \"numerical\",\n",
        "    \"numeerinen\": \"numerical\", \"numero\": \"numerical\", \"arvo\": \"numerical\", \"laskea\": \"numerical\", \"laske\": \"numerical\",\n",
        "\n",
        "    # Symbolic variants\n",
        "    \"symbolic\": \"symbolic\", \"symbol\": \"symbolic\", \"equation\": \"symbolic\", \"algebraic\": \"symbolic\",\n",
        "    \"symbolinen\": \"symbolic\", \"yhtälö\": \"symbolic\", \"yhtalo\": \"symbolic\", \"yhtälöt\": \"symbolic\",\n",
        "}\n",
        "\n",
        "\n",
        "def normalize_answer_type(raw_label: str, question_text: str = \"\", exact_answer: str = \"\") -> str:\n",
        "    \"\"\"\n",
        "    Normalize a dataset label to one of: 'symbolic', 'numerical', 'proof'.\n",
        "    Heuristics expanded to handle Finnish phrases and labels (plus English).\n",
        "    \"\"\"\n",
        "    # Helper to clean label\n",
        "    def _clean_label(lbl: str) -> str:\n",
        "        if not lbl:\n",
        "            return \"\"\n",
        "        s = lbl.strip().lower()\n",
        "        # keep unicode letters and digits and spaces\n",
        "        s = re.sub(r'[^0-9\\w\\säöåÄÖÅ-]', ' ', s, flags=re.UNICODE)\n",
        "        s = re.sub(r'\\s+', ' ', s).strip()\n",
        "        return s\n",
        "\n",
        "    s = _clean_label(raw_label)\n",
        "\n",
        "    # direct mapping\n",
        "    if s in _ANSWER_TYPE_MAP_SIMPLE:\n",
        "        return _ANSWER_TYPE_MAP_SIMPLE[s]\n",
        "\n",
        "    # partial matches (allow English or Finnish keywords appearing)\n",
        "    for k, v in _ANSWER_TYPE_MAP_SIMPLE.items():\n",
        "        if k in s:\n",
        "            return v\n",
        "\n",
        "    # heuristics using question or exact_answer (English & Finnish checks)\n",
        "    q = (question_text or \"\").lower()\n",
        "    a = (exact_answer or \"\").lower()\n",
        "\n",
        "    # Proof indicators (English + Finnish)\n",
        "    if re.search(r'\\b(prove|show that|prove that|proof)\\b', q) or re.search(r'\\b(todista|todistus|näytä|näytä että|todistaa)\\b', q):\n",
        "        return \"proof\"\n",
        "\n",
        "    # logarithm related: English/Finnish\n",
        "    if re.search(r'\\b(log|ln|logarithm)\\b', q) or re.search(r'\\b(log|ln|logaritmi)\\b', q) or re.search(r'\\blog\\b', a):\n",
        "        # prefer numerical if exact answer contains digits\n",
        "        if re.search(r'\\d', a):\n",
        "            return \"numerical\"\n",
        "        return \"symbolic\"\n",
        "\n",
        "    # set theory indicators: English / Finnish\n",
        "    if re.search(r'\\b(set|subset|union|intersection)\\b', q) or re.search(r'\\b(joukko|osajoukko|yhdiste|leikkaus)\\b', q):\n",
        "        return \"symbolic\"\n",
        "\n",
        "    # units (English + Finnish)\n",
        "    if re.search(r'\\bmeter\\b|\\bm\\b|\\bcm\\b|\\bkg\\b|\\bliter\\b|\\bl\\b|\\bkm\\b|\\bmile\\b', q + \" \" + a) or \\\n",
        "       re.search(r'\\bmetri\\b|\\bcm\\b|\\bkg\\b|\\blitra\\b|\\bl\\b|\\bkm\\b', q + \" \" + a):\n",
        "        return \"numerical\"\n",
        "\n",
        "    # equation-solving heuristics (English + Finnish)\n",
        "    if re.search(r'\\bequation\\b|solve for|solve|= x|x\\s*=', q) or re.search(r'\\byhtälö\\b|ratkaise|ratkaista|ratkaise for|= x|x\\s*=', q):\n",
        "        return \"symbolic\"\n",
        "\n",
        "    # trig / geometry indicators (English + Finnish)\n",
        "    if re.search(r'\\b(trig|sin|cos|tan|geometry|triangle|circle)\\b', q) or re.search(r'\\b(trigonometr|sin|cos|tan|geometria|kolmio|ympyrä|ympyra)\\b', q):\n",
        "        if re.search(r'\\d', a):\n",
        "            return \"numerical\"\n",
        "        return \"symbolic\"\n",
        "\n",
        "    # numeric indicators (English + Finnish) -> numerical\n",
        "    if re.search(r'\\d', q) or re.search(r'find the value|compute|calculate|evaluate', q) or \\\n",
        "       re.search(r'arvon|laske|laske arvo|laske\\W|laske\\W|laske:', q):\n",
        "        return \"numerical\"\n",
        "\n",
        "    # If exact_answer looks numeric, prefer numerical (but check for LaTeX)\n",
        "    if re.search(r'[0-9]|\\\\frac|\\\\sqrt', a):\n",
        "        if re.search(r'\\\\frac|\\\\sqrt|\\{|\\\\', a):\n",
        "            return \"symbolic\"\n",
        "        return \"numerical\"\n",
        "\n",
        "    # fallback\n",
        "    return \"symbolic\"\n",
        "\n",
        "# -------------------------\n",
        "# EnhancedAnswerExtractor (adapted to behave like SimplifiedAnswerExtractor)\n",
        "# and now handles Finnish markers as well\n",
        "# -------------------------\n",
        "class EnhancedAnswerExtractor:\n",
        "    \"\"\"\n",
        "    Adapter that implements the simplified extraction behavior,\n",
        "    extended to recognize Finnish formatting/conclusion words as well.\n",
        "    Provides:\n",
        "      - extract_final_answer(text) -> str\n",
        "      - extract_all_final_answers(generated_solution) -> list\n",
        "    and internal helpers _clean_answer and _is_valid_answer.\n",
        "    \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def _clean_answer(answer: str) -> str:\n",
        "        if not answer:\n",
        "            return \"\"\n",
        "        # Start with a trimmed answer and normalize whitespace\n",
        "        a = answer.strip()\n",
        "        # collapse whitespace\n",
        "        a = re.sub(r'\\s+', ' ', a)\n",
        "\n",
        "        # remove outer $$ if present (multiline)\n",
        "        a = re.sub(r'^\\$\\$(.*)\\$\\$$', r'\\1', a, flags=re.DOTALL)\n",
        "        # remove surrounding single $ if the whole string is wrapped\n",
        "        a = re.sub(r'^\\$(.*)\\$$', r'\\1', a, flags=re.DOTALL)\n",
        "\n",
        "        # strip standalone leading/trailing $ characters and spaces\n",
        "        a = a.strip('$ ')\n",
        "\n",
        "        # Remove common prefixes (kept after stripping $ to catch cases like \"$Final Answer: ...$\")\n",
        "        prefixes_to_remove = [\n",
        "            # English\n",
        "            r'Final Answer:\\s*', r'Answer:\\s*', r'The answer is\\s*',\n",
        "            r'Therefore,?\\s*', r'Thus,?\\s*', r'Hence,?\\s*', r'So,?\\s*', r'∴\\s*',\n",
        "\n",
        "            # Finnish\n",
        "            r'Lopullinen vastaus[:\\s]*', r'Lopullinen[:\\s]*',\n",
        "            r'Vastaus[:\\s]*', r'Lopullinen vastaus[:\\s]*', r'Vastaus on\\s*',\n",
        "            r'Siksi,?\\s*', r'Joten,?\\s*', r'Näin ollen,?\\s*', r'Johtopäätös[:\\s]*'\n",
        "        ]\n",
        "        for prefix in prefixes_to_remove:\n",
        "            a = re.sub(f'^{prefix}', '', a, flags=re.IGNORECASE)\n",
        "\n",
        "        # remove various boxed wrappers with optional backslashes and optional surrounding $\n",
        "        # e.g. $$\\boxed{...}$$, $\\boxed{...}$, \\boxed{...}\n",
        "        a = re.sub(r'\\$?\\s*(?:\\\\){0,3}boxed\\{([^}]*)\\}\\s*\\$?', r'\\1', a, flags=re.DOTALL | re.IGNORECASE)\n",
        "        # also ensure plain \\boxed{...} is unwrapped (redundant but safe)\n",
        "        a = re.sub(r'\\\\boxed\\{([^}]*)\\}', r'\\1', a)\n",
        "\n",
        "        # convert common LaTeX to readable forms\n",
        "        a = re.sub(r'\\\\frac\\{([^}]*)\\}\\{([^}]*)\\}', r'(\\1)/(\\2)', a)\n",
        "        a = re.sub(r'\\\\sqrt\\{([^}]*)\\}', r'√(\\1)', a)\n",
        "\n",
        "        # remove bold/italic wrappers\n",
        "        a = re.sub(r'\\*\\*([^*]+)\\*\\*', r'\\1', a)\n",
        "        a = re.sub(r'\\*([^*]+)\\*', r'\\1', a)\n",
        "\n",
        "        # collapse multiple spaces again (in case replacements introduced them)\n",
        "        a = re.sub(r'\\s+', ' ', a).strip()\n",
        "\n",
        "        # trim trailing punctuation/words\n",
        "        a = a.rstrip(' \\t\\n.,;:')\n",
        "\n",
        "        # remove trailing words like \"proved\" or \"the answer\" (English & Finnish)\n",
        "        a = re.sub(r'\\b(proved|completed|finished|the answer|todistettu|todistus|vastaus|vastaus on)\\b[.\\s]*$', '', a, flags=re.IGNORECASE).strip()\n",
        "\n",
        "        return a\n",
        "\n",
        "    @staticmethod\n",
        "    def _is_valid_answer(answer: str) -> bool:\n",
        "        if not answer:\n",
        "            return False\n",
        "        # not only punctuation\n",
        "        if re.match(r'^[\\W_]+$', answer):\n",
        "            return False\n",
        "        # contains at least some alphanumeric characters (or common math symbols)\n",
        "        if not re.search(r'[0-9A-Za-zÀ-ÖØ-öø-ÿÄäÖöÅå\\\\]', answer):\n",
        "            return False\n",
        "        # length sanity\n",
        "        if len(answer) > 1000:\n",
        "            return False\n",
        "        # avoid answers that end with only concluding words (English & Finnish)\n",
        "        blacklist = [r'therefore$', r'thus$', r'hence$', r'so$', r'we get$', r'we have$', r'siksi$', r'joten$', r'näin ollen$']\n",
        "        for b in blacklist:\n",
        "            if re.search(b, answer.strip(), flags=re.IGNORECASE):\n",
        "                return False\n",
        "        return True\n",
        "\n",
        "    @staticmethod\n",
        "    def extract_final_answer_simple(text: str) -> str:\n",
        "        \"\"\"\n",
        "        Primary method: Extract final answer using the last lines approach,\n",
        "        with fallback to pattern-based extraction.\n",
        "        \"\"\"\n",
        "        if not text:\n",
        "            return \"\"\n",
        "\n",
        "        # Clean the text and split into lines\n",
        "        lines = [line.strip() for line in text.strip().split('\\n') if line.strip()]\n",
        "\n",
        "        # Strategy 1: Try last two lines combined\n",
        "        if len(lines) >= 2:\n",
        "            last_two = ' '.join(lines[-2:])\n",
        "            cleaned = EnhancedAnswerExtractor._clean_answer(last_two)\n",
        "            if EnhancedAnswerExtractor._is_valid_answer(cleaned):\n",
        "                return cleaned\n",
        "\n",
        "        # Strategy 2: Try last line only\n",
        "        if lines:\n",
        "            cleaned = EnhancedAnswerExtractor._clean_answer(lines[-1])\n",
        "            if EnhancedAnswerExtractor._is_valid_answer(cleaned):\n",
        "                return cleaned\n",
        "\n",
        "        # Strategy 3: Try last 3 lines if we have them (sometimes answers span multiple lines)\n",
        "        if len(lines) >= 3:\n",
        "            last_three = ' '.join(lines[-3:])\n",
        "            cleaned = EnhancedAnswerExtractor._clean_answer(last_three)\n",
        "            if EnhancedAnswerExtractor._is_valid_answer(cleaned) and len(cleaned) < 500:\n",
        "                return cleaned\n",
        "\n",
        "        # Strategy 4: Fallback to pattern-based extraction\n",
        "        return EnhancedAnswerExtractor._extract_with_patterns(text)\n",
        "\n",
        "    @staticmethod\n",
        "    def _extract_with_patterns(text: str) -> str:\n",
        "        \"\"\"\n",
        "        Pattern-based extraction as fallback method.\n",
        "        Recognizes both English and Finnish answer/conclusion patterns.\n",
        "        \"\"\"\n",
        "        # Check for <final> tags\n",
        "        raw_matches = re.findall(r'<final>(.*?)</final>', text, re.DOTALL | re.IGNORECASE)\n",
        "        for m in raw_matches:\n",
        "            c = EnhancedAnswerExtractor._clean_answer(m)\n",
        "            if EnhancedAnswerExtractor._is_valid_answer(c):\n",
        "                return c\n",
        "\n",
        "        # Try common answer patterns (English + Finnish)\n",
        "        patterns = [\n",
        "            r'\\*\\*Final Answer:\\*\\*\\s*(.+?)(?:\\n|$)',\n",
        "            r'Final Answer:\\s*(.+?)(?:\\n|$)',\n",
        "            r'Final Answer\\s*[:\\-]\\s*(.+?)(?:\\n|$)',\n",
        "\n",
        "            # Finnish patterns\n",
        "            r'\\*\\*Lopullinen vastaus:\\*\\*\\s*(.+?)(?:\\n|$)',\n",
        "            r'Lopullinen vastaus[:\\s]*(.+?)(?:\\n|$)',\n",
        "            r'Vastaus[:\\s]*(.+?)(?:\\n|$)',\n",
        "            r'Vastaus on[:\\s]*(.+?)(?:\\n|$)',\n",
        "            r'Johtopäätös[:\\s]*(.+?)(?:\\n|$)',\n",
        "            r'Näin ollen[,:\\s]*(.+?)(?:\\.|$|\\n)',\n",
        "\n",
        "            # English conclusion markers\n",
        "            r'Therefore[,:\\s]*(.+?)(?:\\.|$|\\n)',\n",
        "            r'Hence[,:\\s]*(.+?)(?:\\.|$|\\n)',\n",
        "            r'Thus[,:\\s]*(.+?)(?:\\.|$|\\n)',\n",
        "            r'∴\\s*(.+?)(?:\\.|$|\\n)',\n",
        "\n",
        "            # Finnish conclusion markers\n",
        "            r'Siksi[,:\\s]*(.+?)(?:\\.|$|\\n)',\n",
        "            r'Joten[,:\\s]*(.+?)(?:\\.|$|\\n)',\n",
        "\n",
        "            r'Answer[:\\s]*(.+?)(?:\\n|$)',\n",
        "            r'Result[:\\s]*(.+?)(?:\\n|$)',\n",
        "            r'Solution[:\\s]*(.+?)(?:\\n|$)',\n",
        "        ]\n",
        "\n",
        "        for pat in patterns:\n",
        "            matches = re.findall(pat, text, re.MULTILINE | re.DOTALL | re.IGNORECASE)\n",
        "            if matches:\n",
        "                answer = matches[-1].strip()\n",
        "                cleaned = EnhancedAnswerExtractor._clean_answer(answer)\n",
        "                if EnhancedAnswerExtractor._is_valid_answer(cleaned):\n",
        "                    return cleaned\n",
        "\n",
        "        # Try boxed math expressions\n",
        "        boxed_patterns = [\n",
        "            r'\\$\\$\\s*(?:\\\\){0,3}boxed\\{(.+?)\\}\\s*\\$\\$',\n",
        "            r'\\$\\s*(?:\\\\){0,3}boxed\\{(.+?)\\}\\s*\\$',\n",
        "            r'(?:\\\\){0,3}boxed\\{(.+?)\\}',\n",
        "        ]\n",
        "\n",
        "        for pat in boxed_patterns:\n",
        "            m = re.search(pat, text, re.DOTALL | re.IGNORECASE)\n",
        "            if m:\n",
        "                cand = EnhancedAnswerExtractor._clean_answer(m.group(1))\n",
        "                if EnhancedAnswerExtractor._is_valid_answer(cand):\n",
        "                    return cand\n",
        "\n",
        "        return \"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def extract_all_final_answers(generated_solution: str) -> list:\n",
        "        \"\"\"\n",
        "        Extract multiple final answers using simplified approach.\n",
        "        Returns a list (possibly empty) of cleaned answers found inside all <final>...</final> tags.\n",
        "        Falls back to the single simplified extraction if no tags are found.\n",
        "        \"\"\"\n",
        "        if not generated_solution:\n",
        "            return []\n",
        "\n",
        "        # Find all <final>...</final> (non-greedy)\n",
        "        raw_matches = re.findall(r'<final>(.*?)</final>', generated_solution, re.DOTALL | re.IGNORECASE)\n",
        "        cleaned = []\n",
        "        for m in raw_matches:\n",
        "            c = EnhancedAnswerExtractor._clean_answer(m)\n",
        "            if EnhancedAnswerExtractor._is_valid_answer(c):\n",
        "                cleaned.append(c)\n",
        "\n",
        "        if cleaned:\n",
        "            return cleaned\n",
        "\n",
        "        # Fallback: try to extract a single final using the simpler logic\n",
        "        simple_answer = EnhancedAnswerExtractor.extract_final_answer_simple(generated_solution)\n",
        "        if simple_answer:\n",
        "            return [simple_answer]\n",
        "\n",
        "        return []\n",
        "\n",
        "    @staticmethod\n",
        "    def extract_final_answer(generated_solution: str) -> str:\n",
        "        \"\"\"\n",
        "        Backwards-compatible extractor that delegates to the simplified extraction.\n",
        "        If multiple <final> tags exist, returns a JSON array string of cleaned answers.\n",
        "        \"\"\"\n",
        "        if not generated_solution:\n",
        "            return \"\"\n",
        "\n",
        "        # Prefer explicit <final> tags (can be multiple)\n",
        "        raw_matches = re.findall(r'<final>(.*?)</final>', generated_solution, re.DOTALL | re.IGNORECASE)\n",
        "        if raw_matches:\n",
        "            cleaned = []\n",
        "            for m in raw_matches:\n",
        "                c = EnhancedAnswerExtractor._clean_answer(m)\n",
        "                if EnhancedAnswerExtractor._is_valid_answer(c):\n",
        "                    cleaned.append(c)\n",
        "            if not cleaned:\n",
        "                # fall through to simpler single extraction\n",
        "                return EnhancedAnswerExtractor.extract_final_answer_simple(generated_solution)\n",
        "            if len(cleaned) == 1:\n",
        "                return cleaned[0]\n",
        "            try:\n",
        "                return json.dumps(cleaned, ensure_ascii=False)\n",
        "            except Exception:\n",
        "                return \" ||| \".join(cleaned)\n",
        "\n",
        "        # No explicit finals: use simplified single extraction\n",
        "        return EnhancedAnswerExtractor.extract_final_answer_simple(generated_solution)\n",
        "\n",
        "# -------------------------\n",
        "# Ollama-based Math Solver (ZERO-SHOT) — PROMPTS IN ENGLISH (problem is Finnish)\n",
        "# -------------------------\n",
        "class OllamaZeroShotMathSolver:\n",
        "    \"\"\"\n",
        "    Zero-shot math solver that uses the Ollama daemon via the Python client.\n",
        "    Prompts/instructions are written in English (as requested), but the solver is informed that\n",
        "    the problem text will be in FINNISH and is instructed to provide a concise final answer in FINNISH.\n",
        "    - Zero-shot prompt: forbids chain-of-thought and requests concise final <final> tag\n",
        "    - Single-pass only.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model_name=\"qwen3:8b\"):\n",
        "        \"\"\"\n",
        "        model_name: the Ollama model reference (e.g., \"qwen3:8b\")\n",
        "        \"\"\"\n",
        "        self.model_name = model_name\n",
        "        self.client = self._load_client()\n",
        "\n",
        "    def _load_client(self):\n",
        "        print(f\"Initializing Ollama client for model: {self.model_name}\")\n",
        "        client = ollama.Client()\n",
        "        return client\n",
        "\n",
        "    def cleanup(self):\n",
        "        if hasattr(self, 'client'):\n",
        "            del self.client\n",
        "\n",
        "    def _get_format_instructions(self, answer_type):\n",
        "        \"\"\"\n",
        "        Zero-shot formatting instructions (WRITTEN IN ENGLISH).\n",
        "        The model is explicitly informed that the problem text is in FINNISH and that the concise final\n",
        "        answer should be provided in FINNISH. Examples/formats are shown in English but demonstrate\n",
        "        that the final tag must contain the concise Finnish answer.\n",
        "        \"\"\"\n",
        "        t = (answer_type or \"symbolic\").strip().lower()\n",
        "        if t not in _CANONICAL_TYPES:\n",
        "            t = \"symbolic\"\n",
        "\n",
        "        base = (\n",
        "            \"CRITICAL FORMATTING REQUIREMENTS (ZERO-SHOT):\\n\"\n",
        "            \"- The math problem you will receive is written in FINNISH. Provide your concise FINAL ANSWER in FINNISH.\\n\"\n",
        "            \"- DO NOT provide chain-of-thought or step-by-step internal reasoning. Do NOT reveal private chain-of-thought.\\n\"\n",
        "            \"- If a very short justification is necessary, include a single-line 'Explanation:' with at most one sentence (in Finnish).\\n\"\n",
        "            \"- Always end with a machine-readable final tag <final>...</final> containing ONLY the concise final answer in FINNISH (no extra reasoning inside the tag).\\n\"\n",
        "        )\n",
        "\n",
        "        if t == \"proof\":\n",
        "            return base + (\n",
        "                \"FOR PROOFS (zero-shot):\\n\"\n",
        "                \"- Provide a concise conclusion or a one-sentence proof sketch (in FINNISH) labeled 'Johtopäätös:' or 'Esitys:' if needed. Do NOT provide a full step-by-step proof.\\n\"\n",
        "                \"Format example (English instructions):\\n\"\n",
        "                \"Final Answer (in Finnish):\\n\"\n",
        "                \"[Concise Finnish conclusion or one-sentence sketch]\\n\\n\"\n",
        "                \"<final>[Concise Finnish conclusion]</final>\\n\"\n",
        "            )\n",
        "        elif t == \"numerical\":\n",
        "            return base + (\n",
        "                \"FOR NUMERICAL RESULTS:\\n\"\n",
        "                \"- Provide the numeric result in exact form if available (fractions/radicals). Otherwise provide a decimal rounded to 4 decimal places.\\n\"\n",
        "                \"Format example (English instructions):\\n\"\n",
        "                \"Final Answer (in Finnish):\\n\"\n",
        "                \"[Numeric result]\\n\\n\"\n",
        "                \"<final>[Numeric result]</final>\\n\"\n",
        "            )\n",
        "        else:  # symbolic\n",
        "            return base + (\n",
        "                \"FOR SYMBOLIC RESULTS:\\n\"\n",
        "                \"- Provide the final symbolic expression (LaTeX allowed) in a concise form. The expression may be LaTeX but any wording should be in Finnish if used.\\n\"\n",
        "                \"Format example (English instructions):\\n\"\n",
        "                \"Final Answer (in Finnish):\\n\"\n",
        "                \"[Final symbolic expression]\\n\\n\"\n",
        "                \"<final>[LaTeX expression or concise symbolic expression — in Finnish if words are used]</final>\\n\"\n",
        "            )\n",
        "\n",
        "    def _create_prompt(self, question, answer_type=\"symbolic\"):\n",
        "        format_instructions = self._get_format_instructions(answer_type)\n",
        "\n",
        "        # The main instruction is in English (per your requirement), but it states the problem language and required answer language.\n",
        "        prompt = f\"\"\"You are an expert mathematician. The following math problem is written in FINNISH.\n",
        "Provide a concise final answer in FINNISH. DO NOT produce chain-of-thought or step-by-step internal reasoning.\n",
        "If you include a justification, it must be one short sentence and labeled 'Explanation:' (in Finnish).\n",
        "\n",
        "MATH PROBLEM (in Finnish):\n",
        "{question}\n",
        "\n",
        "{format_instructions}\n",
        "\n",
        "Begin your concise answer (in Finnish) now:\n",
        "\"\"\"\n",
        "        return prompt\n",
        "\n",
        "    def _generate_once(self, prompt_text: str, enable_thinking: bool = False) -> str:\n",
        "        \"\"\"\n",
        "        Call ollama.Client.chat WITHOUT temperature/max_tokens.\n",
        "        Handles several possible response shapes.\n",
        "        \"\"\"\n",
        "        messages = [{\"role\": \"user\", \"content\": prompt_text}]\n",
        "\n",
        "        # Call Ollama client.chat without temperature/max_tokens\n",
        "        try:\n",
        "            resp = self.client.chat(model=self.model_name, messages=messages, think=enable_thinking)\n",
        "        except TypeError:\n",
        "            # Some client versions have different signatures\n",
        "            try:\n",
        "                resp = self.client.chat(self.model_name, messages=messages, think=enable_thinking)\n",
        "            except Exception:\n",
        "                resp = self.client.chat(self.model_name, messages)\n",
        "\n",
        "        # Normalize response into a string\n",
        "        full_output = \"\"\n",
        "        if isinstance(resp, dict):\n",
        "            if 'message' in resp and isinstance(resp['message'], dict) and 'content' in resp['message']:\n",
        "                full_output = resp['message']['content']\n",
        "            elif 'choices' in resp and isinstance(resp['choices'], (list, tuple)) and resp['choices']:\n",
        "                choice = resp['choices'][0]\n",
        "                if isinstance(choice, dict) and 'message' in choice and isinstance(choice['message'], dict):\n",
        "                    full_output = choice['message'].get('content', '')\n",
        "                else:\n",
        "                    full_output = str(choice)\n",
        "            else:\n",
        "                full_output = str(resp)\n",
        "        else:\n",
        "            # resp might be an object with .message.content\n",
        "            try:\n",
        "                full_output = resp.message.content\n",
        "            except Exception:\n",
        "                full_output = str(resp)\n",
        "\n",
        "        if isinstance(full_output, bytes):\n",
        "            full_output = full_output.decode('utf-8', errors='ignore')\n",
        "        return (full_output or \"\").strip()\n",
        "\n",
        "    def solve_problem(self, question, answer_type=\"symbolic\"):\n",
        "        \"\"\"\n",
        "        Zero-shot single-pass solve via Ollama.\n",
        "        \"\"\"\n",
        "        prompt = self._create_prompt(question, answer_type)\n",
        "        full_output = self._generate_once(prompt, enable_thinking=False)\n",
        "\n",
        "        # No thinking parsing for zero-shot mode\n",
        "        thinking_content = \"\"\n",
        "        generated_answer = full_output\n",
        "        final_tag_output = \"\"  # no second pass\n",
        "\n",
        "        extracted_final_answer = EnhancedAnswerExtractor.extract_final_answer(generated_answer)\n",
        "\n",
        "        return {\n",
        "            \"thinking_content\": thinking_content,\n",
        "            \"generated_answer\": generated_answer,\n",
        "            \"final_tag_output\": final_tag_output,\n",
        "            \"extracted_final_answer\": extracted_final_answer\n",
        "        }\n",
        "\n",
        "# -------------------------\n",
        "# Dataset Processor\n",
        "# -------------------------\n",
        "class DatasetProcessor:\n",
        "    def __init__(self, solver: OllamaZeroShotMathSolver, failed_folder=None):\n",
        "        self.solver = solver\n",
        "        self.extractor = EnhancedAnswerExtractor()\n",
        "        self.failed_folder = failed_folder or \"failed_extractions\"\n",
        "        os.makedirs(self.failed_folder, exist_ok=True)\n",
        "\n",
        "    def process_dataset(self, dataset_path, output_base_path, start_idx=0, end_idx=None,\n",
        "                        folder_name=None, create_timestamped_folder=True):\n",
        "        dataset = self._load_dataset(dataset_path)\n",
        "        if end_idx is None:\n",
        "            end_idx = len(dataset)\n",
        "\n",
        "        output_folder = self._create_output_folder(output_base_path, folder_name, start_idx, end_idx, create_timestamped_folder)\n",
        "        results = []\n",
        "\n",
        "        print(f\"Processing problems {start_idx} to {end_idx-1} ({end_idx-start_idx} total)\")\n",
        "        print(f\"Output will be saved in: {output_folder}\")\n",
        "\n",
        "        for idx in tqdm(range(start_idx, min(end_idx, len(dataset)))):\n",
        "            problem = dataset[idx]\n",
        "            try:\n",
        "                result_entry = self._process_single_problem(idx, problem)\n",
        "                results.append(result_entry)\n",
        "                self._print_progress(idx, result_entry)\n",
        "                if (idx - start_idx + 1) % 10 == 0:\n",
        "                    self._save_intermediate_results(results, output_folder, idx - start_idx + 1)\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing problem {idx+1}: {str(e)}\")\n",
        "                error_entry = self._create_error_entry(idx, problem, str(e))\n",
        "                results.append(error_entry)\n",
        "\n",
        "        final_output_path = self._save_final_results(results, output_folder, start_idx, end_idx)\n",
        "        self._create_summary_file(results, output_folder, dataset_path, start_idx, end_idx)\n",
        "        return results, output_folder\n",
        "\n",
        "    def _create_output_folder(self, base_path, folder_name, start_idx, end_idx, add_timestamp):\n",
        "        if folder_name is None:\n",
        "            folder_name = f\"results_{start_idx}_to_{end_idx-1}\"\n",
        "        if add_timestamp:\n",
        "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "            folder_name = f\"{folder_name}_{timestamp}\"\n",
        "        output_folder = os.path.join(base_path, folder_name)\n",
        "        os.makedirs(output_folder, exist_ok=True)\n",
        "        return output_folder\n",
        "\n",
        "    def _load_dataset(self, dataset_path):\n",
        "        dataset = []\n",
        "        with open(dataset_path, 'r', encoding='utf-8') as f:\n",
        "            for line in f:\n",
        "                if line.strip():\n",
        "                    dataset.append(json.loads(line))\n",
        "        return dataset\n",
        "\n",
        "    def _process_single_problem(self, idx, problem):\n",
        "        language = problem.get(\"Language\", \"\")\n",
        "        chapter_num = problem.get(\"Chapter Number\", \"\")\n",
        "        example_num = problem.get(\"Example Number\", \"\")\n",
        "        question = problem.get(\"Question\", \"\")\n",
        "        exact_answer = problem.get(\"Exact Answer\", \"\")\n",
        "        raw_answer_type = problem.get(\"Answer Type\", \"\") or \"\"\n",
        "\n",
        "        # Normalize/infer canonical answer type: 'symbolic', 'numerical', 'proof'\n",
        "        canonical_type = normalize_answer_type(raw_answer_type, question_text=question, exact_answer=exact_answer)\n",
        "\n",
        "        # If exact_answer strongly indicates numeric, prefer numerical\n",
        "        if exact_answer and re.search(r'\\d', str(exact_answer)):\n",
        "            # if exact contains LaTeX expressions like \\frac or \\sqrt, keep symbolic\n",
        "            if re.search(r'\\\\frac|\\\\sqrt|\\\\boxed', str(exact_answer)):\n",
        "                pass\n",
        "            else:\n",
        "                canonical_type = \"numerical\"\n",
        "\n",
        "        print(f\"\\nProcessing Problem {idx+1}: Chapter {chapter_num}, Example {example_num}\")\n",
        "        print(f\"Raw Answer Type: '{raw_answer_type}'  --> canonical: '{canonical_type}'\")\n",
        "\n",
        "        # Generate solution (use canonical_type) -- zero-shot, single pass\n",
        "        solution_result = self.solver.solve_problem(question, answer_type=canonical_type)\n",
        "        generated_answer = solution_result.get('generated_answer', '')\n",
        "        thinking_content = solution_result.get('thinking_content', '')  # will be empty\n",
        "        final_tag_output = solution_result.get('final_tag_output', '')\n",
        "\n",
        "        # --- NEW extraction logic: keep both forms (single string & list) ---\n",
        "        # Try to get all <final> answers first (preferred)\n",
        "        all_finals = EnhancedAnswerExtractor.extract_all_final_answers(generated_answer)\n",
        "        extracted_final_answer = \"\"\n",
        "        extracted_final_answers = []\n",
        "\n",
        "        # If none found in generated_answer, try final_tag_output (unused here)\n",
        "        if not all_finals and final_tag_output:\n",
        "            all_finals = EnhancedAnswerExtractor.extract_all_final_answers(final_tag_output)\n",
        "\n",
        "        # If still none, fall back to single-answer extractor\n",
        "        if not all_finals:\n",
        "            single = EnhancedAnswerExtractor.extract_final_answer(generated_answer)\n",
        "            if single:\n",
        "                extracted_final_answer = single\n",
        "                extracted_final_answers = [single]\n",
        "            else:\n",
        "                # try whole combined text (thinking + generated + final_tag)\n",
        "                combined = \"\\n\".join([thinking_content or \"\", generated_answer or \"\", final_tag_output or \"\"])\n",
        "                single = EnhancedAnswerExtractor.extract_final_answer(combined)\n",
        "                if single:\n",
        "                    extracted_final_answer = single\n",
        "                    extracted_final_answers = [single]\n",
        "                else:\n",
        "                    extracted_final_answer = \"\"\n",
        "                    extracted_final_answers = []\n",
        "        else:\n",
        "            # we have one or more finals\n",
        "            extracted_final_answers = all_finals\n",
        "            if len(all_finals) == 1:\n",
        "                extracted_final_answer = all_finals[0]\n",
        "            else:\n",
        "                # store a machine-readable concatenation: JSON array string\n",
        "                try:\n",
        "                    extracted_final_answer = json.dumps(all_finals, ensure_ascii=False)\n",
        "                except Exception:\n",
        "                    extracted_final_answer = \" ||| \".join(all_finals)\n",
        "\n",
        "        # If still empty, save a failed extraction example for inspection\n",
        "        if not extracted_final_answer:\n",
        "            fname = f\"failed_{idx}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
        "            fpath = os.path.join(self.failed_folder, fname)\n",
        "            with open(fpath, 'w', encoding='utf-8') as f:\n",
        "                json.dump({\n",
        "                    \"index\": idx,\n",
        "                    \"question\": question,\n",
        "                    \"generated_answer\": generated_answer,\n",
        "                    \"thinking_content\": thinking_content,\n",
        "                    \"final_tag_output\": final_tag_output,\n",
        "                    \"exact_answer\": exact_answer,\n",
        "                    \"canonical_type\": canonical_type,\n",
        "                    \"extracted_final_answer\": extracted_final_answer,\n",
        "                    \"extracted_final_answers\": extracted_final_answers\n",
        "                }, f, ensure_ascii=False, indent=2)\n",
        "            print(f\"Saved failed extraction example to {fpath}\")\n",
        "\n",
        "        result_entry = {\n",
        "            \"problem_index\": idx,\n",
        "            \"language\": language,\n",
        "            \"chapter_number\": chapter_num,\n",
        "            \"example_number\": example_num,\n",
        "            \"question\": question,\n",
        "            \"generated_answer\": generated_answer,\n",
        "            \"thinking_content\": thinking_content,\n",
        "            \"final_tag_output\": final_tag_output,\n",
        "            \"extracted_final_answer\": extracted_final_answer,       # string (or JSON array string)\n",
        "            \"extracted_final_answers\": extracted_final_answers,     # list (empty / single / many)\n",
        "            \"exact_answer\": exact_answer,\n",
        "            \"raw_answer_type\": raw_answer_type,\n",
        "            \"canonical_answer_type\": canonical_type,\n",
        "            \"evaluation_method\": problem.get(\"Evaluation Method\", \"\")\n",
        "        }\n",
        "        return result_entry\n",
        "\n",
        "    def _create_error_entry(self, idx, problem, error_msg):\n",
        "        return {\n",
        "            \"problem_index\": idx,\n",
        "            \"language\": problem.get(\"Language\", \"\"),\n",
        "            \"chapter_number\": problem.get(\"Chapter Number\", \"\"),\n",
        "            \"example_number\": problem.get(\"Example Number\", \"\"),\n",
        "            \"question\": problem.get(\"Question\", \"\"),\n",
        "            \"generated_answer\": f\"ERROR: {error_msg}\",\n",
        "            \"thinking_content\": \"\",\n",
        "            \"final_tag_output\": \"\",\n",
        "            \"extracted_final_answer\": \"\",\n",
        "            \"extracted_final_answers\": [],\n",
        "            \"exact_answer\": problem.get(\"Exact Answer\", \"\"),\n",
        "            \"raw_answer_type\": problem.get(\"Answer Type\", \"\"),\n",
        "            \"canonical_answer_type\": \"\",\n",
        "            \"evaluation_method\": problem.get(\"Evaluation Method\", \"\")\n",
        "        }\n",
        "\n",
        "    def _print_progress(self, idx, result_entry):\n",
        "        print(f\"Generated answer length: {len(result_entry['generated_answer']) if result_entry['generated_answer'] else 0}\")\n",
        "        print(f\"Extracted final answer: '{result_entry['extracted_final_answer']}'\")\n",
        "        print(f\"Extracted final answers (list): {result_entry.get('extracted_final_answers', [])}\")\n",
        "        print(f\"Expected answer: '{result_entry['exact_answer']}'\")\n",
        "\n",
        "    def _save_intermediate_results(self, results, output_folder, count):\n",
        "        temp_filename = f'intermediate_results_{count}.json'\n",
        "        temp_output_path = os.path.join(output_folder, temp_filename)\n",
        "        with open(temp_output_path, 'w', encoding='utf-8') as f:\n",
        "            json.dump(results, f, ensure_ascii=False, indent=2)\n",
        "        print(f\"Saved intermediate results to {temp_output_path}\")\n",
        "\n",
        "    def _save_final_results(self, results, output_folder, start_idx, end_idx):\n",
        "        final_filename = f'final_results_{start_idx}_to_{end_idx-1}.json'\n",
        "        final_output_path = os.path.join(output_folder, final_filename)\n",
        "        with open(final_output_path, 'w', encoding='utf-8') as f:\n",
        "            json.dump(results, f, ensure_ascii=False, indent=2)\n",
        "        print(f\"\\nProcessing complete. Results saved to {final_output_path}\")\n",
        "        print(f\"Total problems processed: {len(results)}\")\n",
        "        return final_output_path\n",
        "\n",
        "    def _create_summary_file(self, results, output_folder, dataset_path, start_idx, end_idx):\n",
        "        successful_extractions = len([r for r in results if r.get('extracted_final_answer', '').strip()])\n",
        "        summary_data = {\n",
        "            \"processing_info\": {\n",
        "                \"dataset_path\": dataset_path,\n",
        "                \"start_index\": start_idx,\n",
        "                \"end_index\": end_idx - 1,\n",
        "                \"total_processed\": len(results),\n",
        "                \"processing_timestamp\": datetime.now().isoformat(),\n",
        "                \"output_folder\": output_folder\n",
        "            },\n",
        "            \"statistics\": {\n",
        "                \"successful_problems\": len([r for r in results if not r['generated_answer'].startswith('ERROR:')]),\n",
        "                \"failed_problems\": len([r for r in results if r['generated_answer'].startswith('ERROR:')]),\n",
        "                \"successful_extractions\": successful_extractions,\n",
        "                \"extraction_success_rate\": f\"{(successful_extractions/len(results)*100):.1f}%\" if results else \"0%\",\n",
        "                \"average_answer_length\": sum(len(r['generated_answer']) for r in results) / len(results) if results else 0,\n",
        "                \"chapters_processed\": list(set(r['chapter_number'] for r in results if r['chapter_number'])),\n",
        "                \"raw_answer_types\": list(set(r['raw_answer_type'] for r in results if r.get('raw_answer_type'))),\n",
        "                \"canonical_answer_types\": list(set(r['canonical_answer_type'] for r in results if r.get('canonical_answer_type')))\n",
        "            }\n",
        "        }\n",
        "        summary_path = os.path.join(output_folder, 'processing_summary.json')\n",
        "        with open(summary_path, 'w', encoding='utf-8') as f:\n",
        "            json.dump(summary_data, f, ensure_ascii=False, indent=2)\n",
        "        print(f\"Processing summary saved to {summary_path}\")\n",
        "        print(f\"Answer extraction success rate: {summary_data['statistics']['extraction_success_rate']}\")\n",
        "\n",
        "# -------------------------\n",
        "# Main (example usage)\n",
        "# -------------------------\n",
        "def main():\n",
        "    # NOTE: update dataset_path and output_base_path to match your environment.\n",
        "    # Ensure your dataset's \"Question\" fields are in Finnish.\n",
        "    dataset_path = \"/kaggle/input/nctb-dataset/Finnish_Final_Corpus.jsonl\"\n",
        "    output_base_path = \"/kaggle/working/\"\n",
        "\n",
        "    # Use the Ollama zero-shot solver (ensure the specified model is available in Ollama)\n",
        "    solver = OllamaZeroShotMathSolver(model_name=\"qwen3:8b\")\n",
        "    processor = DatasetProcessor(solver, failed_folder=os.path.join(output_base_path, \"failed_extractions\"))\n",
        "\n",
        "    # For quick testing, process only first few problems\n",
        "    results, out_folder = processor.process_dataset(\n",
        "        dataset_path,\n",
        "        output_base_path,\n",
        "        start_idx=0,\n",
        "        end_idx=100  # smaller quick test\n",
        "    )\n",
        "    print(\"Done. Results saved to:\", out_folder)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "4lHbiO5hcPV8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Lithuanian**"
      ],
      "metadata": {
        "id": "tzssxW2FcyzQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "import re\n",
        "from datetime import datetime\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Ollama client\n",
        "try:\n",
        "    import ollama\n",
        "except Exception as e:\n",
        "    raise ImportError(\"The 'ollama' package is required. Install it and make sure the Ollama daemon is running.\") from e\n",
        "\n",
        "# -------------------------\n",
        "# Answer type normalization\n",
        "# -------------------------\n",
        "# Canonical set\n",
        "_CANONICAL_TYPES = {\"symbolic\", \"numerical\", \"proof\"}\n",
        "\n",
        "# mapping common noisy labels to canonical (English + Lithuanian variants)\n",
        "_ANSWER_TYPE_MAP_SIMPLE = {\n",
        "    # Proof variants (English -> Lithuanian)\n",
        "    \"proof\": \"proof\", \"prove\": \"proof\",\n",
        "    \"įrodyti\": \"proof\", \"įrodymas\": \"proof\", \"įrodinėti\": \"proof\", \"parodyti\": \"proof\", \"įrodyk\": \"proof\",\n",
        "\n",
        "    # Numerical variants\n",
        "    \"numerical\": \"numerical\", \"numeric\": \"numerical\", \"number\": \"numerical\", \"calculation\": \"numerical\",\n",
        "    \"skaitinis\": \"numerical\", \"skaičius\": \"numerical\", \"apskaičiuoti\": \"numerical\", \"apskaičiuokite\": \"numerical\",\n",
        "    \"rasti\": \"numerical\", \"raskite\": \"numerical\",\n",
        "\n",
        "    # Symbolic variants\n",
        "    \"symbolic\": \"symbolic\", \"symbol\": \"symbolic\", \"equation\": \"symbolic\", \"algebraic\": \"symbolic\",\n",
        "    \"simbolinis\": \"symbolic\", \"lygtis\": \"symbolic\", \"lygtys\": \"symbolic\", \"algebrinis\": \"symbolic\",\n",
        "}\n",
        "\n",
        "\n",
        "def normalize_answer_type(raw_label: str, question_text: str = \"\", exact_answer: str = \"\") -> str:\n",
        "    \"\"\"\n",
        "    Normalize a dataset label to one of: 'symbolic', 'numerical', 'proof'.\n",
        "    Heuristics expanded to handle Lithuanian phrases and labels (plus English).\n",
        "    \"\"\"\n",
        "    # Helper to clean label\n",
        "    def _clean_label(lbl: str) -> str:\n",
        "        if not lbl:\n",
        "            return \"\"\n",
        "        s = lbl.strip().lower()\n",
        "        # keep unicode letters (Latin extended), digits and spaces\n",
        "        s = re.sub(r'[^0-9\\w\\s\\u0100-\\u017F-]', ' ', s, flags=re.UNICODE)\n",
        "        s = re.sub(r'\\s+', ' ', s).strip()\n",
        "        return s\n",
        "\n",
        "    s = _clean_label(raw_label)\n",
        "\n",
        "    # direct mapping\n",
        "    if s in _ANSWER_TYPE_MAP_SIMPLE:\n",
        "        return _ANSWER_TYPE_MAP_SIMPLE[s]\n",
        "\n",
        "    # partial matches (allow English or Lithuanian keywords appearing)\n",
        "    for k, v in _ANSWER_TYPE_MAP_SIMPLE.items():\n",
        "        if k in s:\n",
        "            return v\n",
        "\n",
        "    # heuristics using question or exact_answer (both English & Lithuanian checks)\n",
        "    q = (question_text or \"\").lower()\n",
        "    a = (exact_answer or \"\").lower()\n",
        "\n",
        "    # Proof indicators (English + Lithuanian)\n",
        "    if re.search(r'\\b(prove|show that|prove that|proof)\\b', q) or re.search(r'\\b(įrodyti|įrodymas|parodyti|įrodyk|įrodinėti)\\b', q, flags=re.IGNORECASE):\n",
        "        return \"proof\"\n",
        "\n",
        "    # logarithm related: English/Lithuanian\n",
        "    if re.search(r'\\b(log|ln|logarithm)\\b', q) or re.search(r'\\b(log|ln|logaritmas)\\b', q) or re.search(r'\\blog\\b', a):\n",
        "        # prefer numerical if exact answer contains digits\n",
        "        if re.search(r'\\d', a):\n",
        "            return \"numerical\"\n",
        "        return \"symbolic\"\n",
        "\n",
        "    # set theory indicators: English / Lithuanian ('aibė' = set)\n",
        "    if re.search(r'\\b(set|subset|union|intersection)\\b', q) or re.search(r'\\b(aibė|poaibis|sąjunga|sankirta|sandūra)\\b', q, flags=re.IGNORECASE):\n",
        "        return \"symbolic\"\n",
        "\n",
        "    # units (English + Lithuanian)\n",
        "    if re.search(r'\\bmeter\\b|\\bm\\b|\\bcm\\b|\\bkg\\b|\\bliter\\b|\\bl\\b|\\bkm\\b|\\bmile\\b', q + \" \" + a) or \\\n",
        "       re.search(r'\\bmetras\\b|\\bcm\\b|\\bkg\\b|\\bliktras\\b|\\bliktr\\b|\\bkm\\b', q + \" \" + a, flags=re.IGNORECASE):\n",
        "        return \"numerical\"\n",
        "\n",
        "    # equation-solving heuristics (English + Lithuanian)\n",
        "    if re.search(r'\\bequation\\b|solve for|solve|= x|x\\s*=', q) or re.search(r'\\b(lygtis|lygti|lygti|išspręsti|spręsti|išspręskite)\\b', q, flags=re.IGNORECASE):\n",
        "        return \"symbolic\"\n",
        "\n",
        "    # trig / geometry indicators (English + Lithuanian)\n",
        "    if re.search(r'\\b(trig|sin|cos|tan|geometry|triangle|circle)\\b', q) or re.search(r'\\b(trigonometr|sin|cos|tan|geometrija|trikampis|apskritimas|ratas)\\b', q, flags=re.IGNORECASE):\n",
        "        if re.search(r'\\d', a):\n",
        "            return \"numerical\"\n",
        "        return \"symbolic\"\n",
        "\n",
        "    # numeric indicators (English + Lithuanian) -> numerical\n",
        "    if re.search(r'\\d', q) or re.search(r'find the value|compute|calculate|evaluate', q) or \\\n",
        "       re.search(r'rasti|raskite|apskaičiuoti|apskaičiuokite|skaičiuoti|skaičiuokite', q, flags=re.IGNORECASE):\n",
        "        return \"numerical\"\n",
        "\n",
        "    # If exact_answer looks numeric, prefer numerical (but check for LaTeX)\n",
        "    if re.search(r'[0-9]|\\\\frac|\\\\sqrt', a):\n",
        "        if re.search(r'\\\\frac|\\\\sqrt|\\{|\\\\', a):\n",
        "            return \"symbolic\"\n",
        "        return \"numerical\"\n",
        "\n",
        "    # fallback\n",
        "    return \"symbolic\"\n",
        "\n",
        "# -------------------------\n",
        "# EnhancedAnswerExtractor (adapted to behave like SimplifiedAnswerExtractor)\n",
        "# and now handles Lithuanian markers as well\n",
        "# -------------------------\n",
        "class EnhancedAnswerExtractor:\n",
        "    \"\"\"\n",
        "    Adapter that implements the simplified extraction behavior (ported from SimplifiedAnswerExtractor),\n",
        "    extended to recognize Lithuanian formatting/conclusion words as well.\n",
        "    Provides:\n",
        "      - extract_final_answer(text) -> str\n",
        "      - extract_all_final_answers(generated_solution) -> list\n",
        "    and internal helpers _clean_answer and _is_valid_answer.\n",
        "    \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def _clean_answer(answer: str) -> str:\n",
        "        if not answer:\n",
        "            return \"\"\n",
        "        # Start with a trimmed answer and normalize whitespace\n",
        "        a = answer.strip()\n",
        "        # collapse whitespace\n",
        "        a = re.sub(r'\\s+', ' ', a)\n",
        "\n",
        "        # remove outer $$ if present (multiline)\n",
        "        a = re.sub(r'^\\$\\$(.*)\\$\\$$', r'\\1', a, flags=re.DOTALL)\n",
        "        # remove surrounding single $ if the whole string is wrapped\n",
        "        a = re.sub(r'^\\$(.*)\\$$', r'\\1', a, flags=re.DOTALL)\n",
        "\n",
        "        # strip standalone leading/trailing $ characters and spaces\n",
        "        a = a.strip('$ ')\n",
        "\n",
        "        # Remove common prefixes (kept after stripping $ to catch cases like \"$Final Answer: ...$\")\n",
        "        prefixes_to_remove = [\n",
        "            # English\n",
        "            r'Final Answer:\\s*', r'Answer:\\s*', r'The answer is\\s*',\n",
        "            r'Therefore,?\\s*', r'Thus,?\\s*', r'Hence,?\\s*', r'So,?\\s*', r'∴\\s*',\n",
        "\n",
        "            # Lithuanian\n",
        "            r'Galutinis atsakymas[:\\s]*', r'Galutinis[:\\s]*',\n",
        "            r'Atsakymas[:\\s]*', r'Atsakymas yra\\s*', r'Išvada[:\\s]*',\n",
        "            r'Todėl,?\\s*', r'Taigi,?\\s*', r'Taigi,?\\s*', r'Iš to,?\\s*',\n",
        "        ]\n",
        "        for prefix in prefixes_to_remove:\n",
        "            a = re.sub(f'^{prefix}', '', a, flags=re.IGNORECASE)\n",
        "\n",
        "        # remove various boxed wrappers with optional backslashes and optional surrounding $\n",
        "        # e.g. $$\\boxed{...}$$, $\\boxed{...}$, \\boxed{...}\n",
        "        a = re.sub(r'\\$?\\s*(?:\\\\){0,3}boxed\\{([^}]*)\\}\\s*\\$?', r'\\1', a, flags=re.DOTALL | re.IGNORECASE)\n",
        "        # also ensure plain \\boxed{...} is unwrapped (redundant but safe)\n",
        "        a = re.sub(r'\\\\boxed\\{([^}]*)\\}', r'\\1', a)\n",
        "\n",
        "        # convert common LaTeX to readable forms\n",
        "        a = re.sub(r'\\\\frac\\{([^}]*)\\}\\{([^}]*)\\}', r'(\\1)/(\\2)', a)\n",
        "        a = re.sub(r'\\\\sqrt\\{([^}]*)\\}', r'√(\\1)', a)\n",
        "\n",
        "        # remove bold/italic wrappers\n",
        "        a = re.sub(r'\\*\\*([^*]+)\\*\\*', r'\\1', a)\n",
        "        a = re.sub(r'\\*([^*]+)\\*', r'\\1', a)\n",
        "\n",
        "        # collapse multiple spaces again (in case replacements introduced them)\n",
        "        a = re.sub(r'\\s+', ' ', a).strip()\n",
        "\n",
        "        # trim trailing punctuation/words\n",
        "        a = a.rstrip(' \\t\\n.,;:')\n",
        "\n",
        "        # remove trailing words like \"proved\" or \"the answer\" (English & Lithuanian)\n",
        "        a = re.sub(r'\\b(proved|completed|finished|the answer|įrodyta|įrodymas|atsakymas|atsakyti)\\b[.\\s]*$', '', a, flags=re.IGNORECASE).strip()\n",
        "\n",
        "        return a\n",
        "\n",
        "    @staticmethod\n",
        "    def _is_valid_answer(answer: str) -> bool:\n",
        "        if not answer:\n",
        "            return False\n",
        "        # not only punctuation\n",
        "        if re.match(r'^[\\W_]+$', answer):\n",
        "            return False\n",
        "        # contains at least some alphanumeric characters (or common math symbols)\n",
        "        if not re.search(r'[0-9A-Za-z\\u0100-\\u017F\\\\]', answer):\n",
        "            return False\n",
        "        # length sanity\n",
        "        if len(answer) > 1000:\n",
        "            return False\n",
        "        # avoid answers that end with only concluding words (English & Lithuanian)\n",
        "        blacklist = [r'therefore$', r'thus$', r'hence$', r'so$', r'we get$', r'we have$', r'todėl$', r'taigi$', r'išvada$']\n",
        "        for b in blacklist:\n",
        "            if re.search(b, answer.strip(), flags=re.IGNORECASE):\n",
        "                return False\n",
        "        return True\n",
        "\n",
        "    @staticmethod\n",
        "    def extract_final_answer_simple(text: str) -> str:\n",
        "        \"\"\"\n",
        "        Primary method: Extract final answer using the last lines approach,\n",
        "        with fallback to pattern-based extraction.\n",
        "        \"\"\"\n",
        "        if not text:\n",
        "            return \"\"\n",
        "\n",
        "        # Clean the text and split into lines\n",
        "        lines = [line.strip() for line in text.strip().split('\\n') if line.strip()]\n",
        "\n",
        "        # Strategy 1: Try last two lines combined\n",
        "        if len(lines) >= 2:\n",
        "            last_two = ' '.join(lines[-2:])\n",
        "            cleaned = EnhancedAnswerExtractor._clean_answer(last_two)\n",
        "            if EnhancedAnswerExtractor._is_valid_answer(cleaned):\n",
        "                return cleaned\n",
        "\n",
        "        # Strategy 2: Try last line only\n",
        "        if lines:\n",
        "            cleaned = EnhancedAnswerExtractor._clean_answer(lines[-1])\n",
        "            if EnhancedAnswerExtractor._is_valid_answer(cleaned):\n",
        "                return cleaned\n",
        "\n",
        "        # Strategy 3: Try last 3 lines if we have them (sometimes answers span multiple lines)\n",
        "        if len(lines) >= 3:\n",
        "            last_three = ' '.join(lines[-3:])\n",
        "            cleaned = EnhancedAnswerExtractor._clean_answer(last_three)\n",
        "            if EnhancedAnswerExtractor._is_valid_answer(cleaned) and len(cleaned) < 500:\n",
        "                return cleaned\n",
        "\n",
        "        # Strategy 4: Fallback to pattern-based extraction\n",
        "        return EnhancedAnswerExtractor._extract_with_patterns(text)\n",
        "\n",
        "    @staticmethod\n",
        "    def _extract_with_patterns(text: str) -> str:\n",
        "        \"\"\"\n",
        "        Pattern-based extraction as fallback method.\n",
        "        Recognizes both English and Lithuanian answer/conclusion patterns.\n",
        "        \"\"\"\n",
        "        # Check for <final> tags\n",
        "        raw_matches = re.findall(r'<final>(.*?)</final>', text, re.DOTALL | re.IGNORECASE)\n",
        "        for m in raw_matches:\n",
        "            c = EnhancedAnswerExtractor._clean_answer(m)\n",
        "            if EnhancedAnswerExtractor._is_valid_answer(c):\n",
        "                return c\n",
        "\n",
        "        # Try common answer patterns (English + Lithuanian)\n",
        "        patterns = [\n",
        "            r'\\*\\*Final Answer:\\*\\*\\s*(.+?)(?:\\n|$)',\n",
        "            r'Final Answer:\\s*(.+?)(?:\\n|$)',\n",
        "            r'Final Answer\\s*[:\\-]\\s*(.+?)(?:\\n|$)',\n",
        "\n",
        "            # Lithuanian patterns\n",
        "            r'\\*\\*Galutinis atsakymas:\\*\\*\\s*(.+?)(?:\\n|$)',\n",
        "            r'Galutinis atsakymas[:\\s]*(.+?)(?:\\n|$)',\n",
        "            r'Atsakymas[:\\s]*(.+?)(?:\\n|$)',\n",
        "            r'Atsakymas yra[:\\s]*(.+?)(?:\\n|$)',\n",
        "            r'Išvada[:\\s]*(.+?)(?:\\n|$)',\n",
        "\n",
        "            # English conclusion markers\n",
        "            r'Therefore[,:\\s]*(.+?)(?:\\.|$|\\n)',\n",
        "            r'Hence[,:\\s]*(.+?)(?:\\.|$|\\n)',\n",
        "            r'Thus[,:\\s]*(.+?)(?:\\.|$|\\n)',\n",
        "            r'∴\\s*(.+?)(?:\\.|$|\\n)',\n",
        "\n",
        "            # Lithuanian conclusion markers\n",
        "            r'Todėl[,:\\s]*(.+?)(?:\\.|$|\\n)',\n",
        "            r'Taigi[,:\\s]*(.+?)(?:\\.|$|\\n)',\n",
        "            r'Iš to[,:\\s]*(.+?)(?:\\.|$|\\n)',\n",
        "\n",
        "            r'Answer[:\\s]*(.+?)(?:\\n|$)',\n",
        "            r'Result[:\\s]*(.+?)(?:\\n|$)',\n",
        "            r'Solution[:\\s]*(.+?)(?:\\n|$)',\n",
        "        ]\n",
        "\n",
        "        for pat in patterns:\n",
        "            matches = re.findall(pat, text, re.MULTILINE | re.DOTALL | re.IGNORECASE)\n",
        "            if matches:\n",
        "                answer = matches[-1].strip()\n",
        "                cleaned = EnhancedAnswerExtractor._clean_answer(answer)\n",
        "                if EnhancedAnswerExtractor._is_valid_answer(cleaned):\n",
        "                    return cleaned\n",
        "\n",
        "        # Try boxed math expressions\n",
        "        boxed_patterns = [\n",
        "            r'\\$\\$\\s*(?:\\\\){0,3}boxed\\{(.+?)\\}\\s*\\$\\$',\n",
        "            r'\\$\\s*(?:\\\\){0,3}boxed\\{(.+?)\\}\\s*\\$',\n",
        "            r'(?:\\\\){0,3}boxed\\{(.+?)\\}',\n",
        "        ]\n",
        "\n",
        "        for pat in boxed_patterns:\n",
        "            m = re.search(pat, text, re.DOTALL | re.IGNORECASE)\n",
        "            if m:\n",
        "                cand = EnhancedAnswerExtractor._clean_answer(m.group(1))\n",
        "                if EnhancedAnswerExtractor._is_valid_answer(cand):\n",
        "                    return cand\n",
        "\n",
        "        return \"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def extract_all_final_answers(generated_solution: str) -> list:\n",
        "        \"\"\"\n",
        "        Extract multiple final answers using simplified approach.\n",
        "        Returns a list (possibly empty) of cleaned answers found inside all <final>...</final> tags.\n",
        "        Falls back to the single simplified extraction if no tags are found.\n",
        "        \"\"\"\n",
        "        if not generated_solution:\n",
        "            return []\n",
        "\n",
        "        # Find all <final>...</final> (non-greedy)\n",
        "        raw_matches = re.findall(r'<final>(.*?)</final>', generated_solution, re.DOTALL | re.IGNORECASE)\n",
        "        cleaned = []\n",
        "        for m in raw_matches:\n",
        "            c = EnhancedAnswerExtractor._clean_answer(m)\n",
        "            if EnhancedAnswerExtractor._is_valid_answer(c):\n",
        "                cleaned.append(c)\n",
        "\n",
        "        if cleaned:\n",
        "            return cleaned\n",
        "\n",
        "        # Fallback: try to extract a single final using the simpler logic\n",
        "        simple_answer = EnhancedAnswerExtractor.extract_final_answer_simple(generated_solution)\n",
        "        if simple_answer:\n",
        "            return [simple_answer]\n",
        "\n",
        "        return []\n",
        "\n",
        "    @staticmethod\n",
        "    def extract_final_answer(generated_solution: str) -> str:\n",
        "        \"\"\"\n",
        "        Backwards-compatible extractor that delegates to the simplified extraction.\n",
        "        If multiple <final> tags exist, returns a JSON array string of cleaned answers.\n",
        "        \"\"\"\n",
        "        if not generated_solution:\n",
        "            return \"\"\n",
        "\n",
        "        # Prefer explicit <final> tags (can be multiple)\n",
        "        raw_matches = re.findall(r'<final>(.*?)</final>', generated_solution, re.DOTALL | re.IGNORECASE)\n",
        "        if raw_matches:\n",
        "            cleaned = []\n",
        "            for m in raw_matches:\n",
        "                c = EnhancedAnswerExtractor._clean_answer(m)\n",
        "                if EnhancedAnswerExtractor._is_valid_answer(c):\n",
        "                    cleaned.append(c)\n",
        "            if not cleaned:\n",
        "                # fall through to simpler single extraction\n",
        "                return EnhancedAnswerExtractor.extract_final_answer_simple(generated_solution)\n",
        "            if len(cleaned) == 1:\n",
        "                return cleaned[0]\n",
        "            try:\n",
        "                return json.dumps(cleaned, ensure_ascii=False)\n",
        "            except Exception:\n",
        "                return \" ||| \".join(cleaned)\n",
        "\n",
        "        # No explicit finals: use simplified single extraction\n",
        "        return EnhancedAnswerExtractor.extract_final_answer_simple(generated_solution)\n",
        "\n",
        "# -------------------------\n",
        "# Ollama-based Math Solver (ZERO-SHOT) — PROMPTS IN ENGLISH (problem is Lithuanian)\n",
        "# -------------------------\n",
        "class OllamaZeroShotMathSolver:\n",
        "    \"\"\"\n",
        "    Zero-shot math solver that uses the Ollama daemon via the Python client.\n",
        "    Prompts/instructions are written in English (as requested), but the solver is informed that\n",
        "    the problem text will be in LITHUANIAN and is instructed to provide a concise final answer in LITHUANIAN.\n",
        "    - Zero-shot prompt: forbids chain-of-thought and requests concise final <final> tag\n",
        "    - Single-pass only.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model_name=\"qwen3:8b\"):\n",
        "        \"\"\"\n",
        "        model_name: the Ollama model reference (e.g., \"qwen3:8b\")\n",
        "        \"\"\"\n",
        "        self.model_name = model_name\n",
        "        self.client = self._load_client()\n",
        "\n",
        "    def _load_client(self):\n",
        "        print(f\"Initializing Ollama client for model: {self.model_name}\")\n",
        "        client = ollama.Client()\n",
        "        return client\n",
        "\n",
        "    def cleanup(self):\n",
        "        if hasattr(self, 'client'):\n",
        "            del self.client\n",
        "\n",
        "    def _get_format_instructions(self, answer_type):\n",
        "        \"\"\"\n",
        "        Zero-shot formatting instructions (WRITTEN IN ENGLISH).\n",
        "        The model is explicitly informed that the problem text is in LITHUANIAN and that the concise final\n",
        "        answer should be provided in LITHUANIAN. Examples/formats are shown in English but demonstrate\n",
        "        that the final tag must contain the concise Lithuanian answer.\n",
        "        \"\"\"\n",
        "        t = (answer_type or \"symbolic\").strip().lower()\n",
        "        if t not in _CANONICAL_TYPES:\n",
        "            t = \"symbolic\"\n",
        "\n",
        "        base = (\n",
        "            \"CRITICAL FORMATTING REQUIREMENTS (ZERO-SHOT):\\n\"\n",
        "            \"- The math problem you will receive is written in LITHUANIAN. Provide your concise FINAL ANSWER in LITHUANIAN.\\n\"\n",
        "            \"- DO NOT provide chain-of-thought or step-by-step internal reasoning. Do NOT reveal private chain-of-thought.\\n\"\n",
        "            \"- If a very short justification is necessary, include a single-line 'Explanation:' with at most one sentence (in Lithuanian).\\n\"\n",
        "            \"- Always end with a machine-readable final tag <final>...</final> containing ONLY the concise final answer in LITHUANIAN (no extra reasoning inside the tag).\\n\"\n",
        "        )\n",
        "\n",
        "        if t == \"proof\":\n",
        "            return base + (\n",
        "                \"FOR PROOFS (zero-shot):\\n\"\n",
        "                \"- Provide a concise conclusion or a one-sentence proof sketch (in LITHUANIAN) labeled 'Išvada:' or 'Įrodymas:' if needed. Do NOT provide a full step-by-step proof.\\n\"\n",
        "                \"Format example (English instructions):\\n\"\n",
        "                \"Final Answer (in Lithuanian):\\n\"\n",
        "                \"[Concise Lithuanian conclusion or one-sentence sketch]\\n\\n\"\n",
        "                \"<final>[Concise Lithuanian conclusion]</final>\\n\"\n",
        "            )\n",
        "        elif t == \"numerical\":\n",
        "            return base + (\n",
        "                \"FOR NUMERICAL RESULTS:\\n\"\n",
        "                \"- Provide the numeric result in exact form if available (fractions/radicals). Otherwise provide a decimal rounded to 4 decimal places.\\n\"\n",
        "                \"Format example (English instructions):\\n\"\n",
        "                \"Final Answer (in Lithuanian):\\n\"\n",
        "                \"[Numeric result]\\n\\n\"\n",
        "                \"<final>[Numeric result]</final>\\n\"\n",
        "            )\n",
        "        else:  # symbolic\n",
        "            return base + (\n",
        "                \"FOR SYMBOLIC RESULTS:\\n\"\n",
        "                \"- Provide the final symbolic expression (LaTeX allowed) in a concise form. The expression may be LaTeX but any wording should be in Lithuanian if used.\\n\"\n",
        "                \"Format example (English instructions):\\n\"\n",
        "                \"Final Answer (in Lithuanian):\\n\"\n",
        "                \"[Final symbolic expression]\\n\\n\"\n",
        "                \"<final>[LaTeX expression or concise symbolic expression — in Lithuanian if words are used]</final>\\n\"\n",
        "            )\n",
        "\n",
        "    def _create_prompt(self, question, answer_type=\"symbolic\"):\n",
        "        format_instructions = self._get_format_instructions(answer_type)\n",
        "\n",
        "        # The main instruction is in English (per your requirement), but it states the problem language and required answer language.\n",
        "        prompt = f\"\"\"You are an expert mathematician. The following math problem is written in LITHUANIAN.\n",
        "Provide a concise final answer in LITHUANIAN. DO NOT produce chain-of-thought or step-by-step internal reasoning.\n",
        "If you include a justification, it must be one short sentence and labeled 'Explanation:' (in Lithuanian).\n",
        "\n",
        "MATH PROBLEM (in Lithuanian):\n",
        "{question}\n",
        "\n",
        "{format_instructions}\n",
        "\n",
        "Begin your concise answer (in Lithuanian) now:\n",
        "\"\"\"\n",
        "        return prompt\n",
        "\n",
        "    def _generate_once(self, prompt_text: str, enable_thinking: bool = False) -> str:\n",
        "        \"\"\"\n",
        "        Call ollama.Client.chat WITHOUT temperature/max_tokens.\n",
        "        Handles several possible response shapes.\n",
        "        \"\"\"\n",
        "        messages = [{\"role\": \"user\", \"content\": prompt_text}]\n",
        "\n",
        "        # Call Ollama client.chat without temperature/max_tokens\n",
        "        try:\n",
        "            resp = self.client.chat(model=self.model_name, messages=messages, think=enable_thinking)\n",
        "        except TypeError:\n",
        "            # Some client versions have different signatures\n",
        "            try:\n",
        "                resp = self.client.chat(self.model_name, messages=messages, think=enable_thinking)\n",
        "            except Exception:\n",
        "                resp = self.client.chat(self.model_name, messages)\n",
        "\n",
        "        # Normalize response into a string\n",
        "        full_output = \"\"\n",
        "        if isinstance(resp, dict):\n",
        "            if 'message' in resp and isinstance(resp['message'], dict) and 'content' in resp['message']:\n",
        "                full_output = resp['message']['content']\n",
        "            elif 'choices' in resp and isinstance(resp['choices'], (list, tuple)) and resp['choices']:\n",
        "                choice = resp['choices'][0]\n",
        "                if isinstance(choice, dict) and 'message' in choice and isinstance(choice['message'], dict):\n",
        "                    full_output = choice['message'].get('content', '')\n",
        "                else:\n",
        "                    full_output = str(choice)\n",
        "            else:\n",
        "                full_output = str(resp)\n",
        "        else:\n",
        "            # resp might be an object with .message.content\n",
        "            try:\n",
        "                full_output = resp.message.content\n",
        "            except Exception:\n",
        "                full_output = str(resp)\n",
        "\n",
        "        if isinstance(full_output, bytes):\n",
        "            full_output = full_output.decode('utf-8', errors='ignore')\n",
        "        return (full_output or \"\").strip()\n",
        "\n",
        "    def solve_problem(self, question, answer_type=\"symbolic\"):\n",
        "        \"\"\"\n",
        "        Zero-shot single-pass solve via Ollama.\n",
        "        \"\"\"\n",
        "        prompt = self._create_prompt(question, answer_type)\n",
        "        full_output = self._generate_once(prompt, enable_thinking=False)\n",
        "\n",
        "        # No thinking parsing for zero-shot mode\n",
        "        thinking_content = \"\"\n",
        "        generated_answer = full_output\n",
        "        final_tag_output = \"\"  # no second pass\n",
        "\n",
        "        extracted_final_answer = EnhancedAnswerExtractor.extract_final_answer(generated_answer)\n",
        "\n",
        "        return {\n",
        "            \"thinking_content\": thinking_content,\n",
        "            \"generated_answer\": generated_answer,\n",
        "            \"final_tag_output\": final_tag_output,\n",
        "            \"extracted_final_answer\": extracted_final_answer\n",
        "        }\n",
        "\n",
        "# -------------------------\n",
        "# Dataset Processor\n",
        "# -------------------------\n",
        "class DatasetProcessor:\n",
        "    def __init__(self, solver: OllamaZeroShotMathSolver, failed_folder=None):\n",
        "        self.solver = solver\n",
        "        self.extractor = EnhancedAnswerExtractor()\n",
        "        self.failed_folder = failed_folder or \"failed_extractions\"\n",
        "        os.makedirs(self.failed_folder, exist_ok=True)\n",
        "\n",
        "    def process_dataset(self, dataset_path, output_base_path, start_idx=0, end_idx=None,\n",
        "                        folder_name=None, create_timestamped_folder=True):\n",
        "        dataset = self._load_dataset(dataset_path)\n",
        "        if end_idx is None:\n",
        "            end_idx = len(dataset)\n",
        "\n",
        "        output_folder = self._create_output_folder(output_base_path, folder_name, start_idx, end_idx, create_timestamped_folder)\n",
        "        results = []\n",
        "\n",
        "        print(f\"Processing problems {start_idx} to {end_idx-1} ({end_idx-start_idx} total)\")\n",
        "        print(f\"Output will be saved in: {output_folder}\")\n",
        "\n",
        "        for idx in tqdm(range(start_idx, min(end_idx, len(dataset)))):\n",
        "            problem = dataset[idx]\n",
        "            try:\n",
        "                result_entry = self._process_single_problem(idx, problem)\n",
        "                results.append(result_entry)\n",
        "                self._print_progress(idx, result_entry)\n",
        "                if (idx - start_idx + 1) % 10 == 0:\n",
        "                    self._save_intermediate_results(results, output_folder, idx - start_idx + 1)\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing problem {idx+1}: {str(e)}\")\n",
        "                error_entry = self._create_error_entry(idx, problem, str(e))\n",
        "                results.append(error_entry)\n",
        "\n",
        "        final_output_path = self._save_final_results(results, output_folder, start_idx, end_idx)\n",
        "        self._create_summary_file(results, output_folder, dataset_path, start_idx, end_idx)\n",
        "        return results, output_folder\n",
        "\n",
        "    def _create_output_folder(self, base_path, folder_name, start_idx, end_idx, add_timestamp):\n",
        "        if folder_name is None:\n",
        "            folder_name = f\"results_{start_idx}_to_{end_idx-1}\"\n",
        "        if add_timestamp:\n",
        "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "            folder_name = f\"{folder_name}_{timestamp}\"\n",
        "        output_folder = os.path.join(base_path, folder_name)\n",
        "        os.makedirs(output_folder, exist_ok=True)\n",
        "        return output_folder\n",
        "\n",
        "    def _load_dataset(self, dataset_path):\n",
        "        dataset = []\n",
        "        with open(dataset_path, 'r', encoding='utf-8') as f:\n",
        "            for line in f:\n",
        "                if line.strip():\n",
        "                    dataset.append(json.loads(line))\n",
        "        return dataset\n",
        "\n",
        "    def _process_single_problem(self, idx, problem):\n",
        "        language = problem.get(\"Language\", \"\")\n",
        "        chapter_num = problem.get(\"Chapter Number\", \"\")\n",
        "        example_num = problem.get(\"Example Number\", \"\")\n",
        "        question = problem.get(\"Question\", \"\")\n",
        "        exact_answer = problem.get(\"Exact Answer\", \"\")\n",
        "        raw_answer_type = problem.get(\"Answer Type\", \"\") or \"\"\n",
        "\n",
        "        # Normalize/infer canonical answer type: 'symbolic', 'numerical', 'proof'\n",
        "        canonical_type = normalize_answer_type(raw_answer_type, question_text=question, exact_answer=exact_answer)\n",
        "\n",
        "        # If exact_answer strongly indicates numeric, prefer numerical\n",
        "        if exact_answer and re.search(r'\\d', str(exact_answer)):\n",
        "            # if exact contains LaTeX expressions like \\frac or \\sqrt, keep symbolic\n",
        "            if re.search(r'\\\\frac|\\\\sqrt|\\\\boxed', str(exact_answer)):\n",
        "                pass\n",
        "            else:\n",
        "                canonical_type = \"numerical\"\n",
        "\n",
        "        print(f\"\\nProcessing Problem {idx+1}: Chapter {chapter_num}, Example {example_num}\")\n",
        "        print(f\"Raw Answer Type: '{raw_answer_type}'  --> canonical: '{canonical_type}'\")\n",
        "\n",
        "        # Generate solution (use canonical_type) -- zero-shot, single pass\n",
        "        solution_result = self.solver.solve_problem(question, answer_type=canonical_type)\n",
        "        generated_answer = solution_result.get('generated_answer', '')\n",
        "        thinking_content = solution_result.get('thinking_content', '')  # will be empty\n",
        "        final_tag_output = solution_result.get('final_tag_output', '')\n",
        "\n",
        "        # --- NEW extraction logic: keep both forms (single string & list) ---\n",
        "        # Try to get all <final> answers first (preferred)\n",
        "        all_finals = EnhancedAnswerExtractor.extract_all_final_answers(generated_answer)\n",
        "        extracted_final_answer = \"\"\n",
        "        extracted_final_answers = []\n",
        "\n",
        "        # If none found in generated_answer, try final_tag_output (unused here)\n",
        "        if not all_finals and final_tag_output:\n",
        "            all_finals = EnhancedAnswerExtractor.extract_all_final_answers(final_tag_output)\n",
        "\n",
        "        # If still none, fall back to single-answer extractor\n",
        "        if not all_finals:\n",
        "            single = EnhancedAnswerExtractor.extract_final_answer(generated_answer)\n",
        "            if single:\n",
        "                extracted_final_answer = single\n",
        "                extracted_final_answers = [single]\n",
        "            else:\n",
        "                # try whole combined text (thinking + generated + final_tag)\n",
        "                combined = \"\\n\".join([thinking_content or \"\", generated_answer or \"\", final_tag_output or \"\"])\n",
        "                single = EnhancedAnswerExtractor.extract_final_answer(combined)\n",
        "                if single:\n",
        "                    extracted_final_answer = single\n",
        "                    extracted_final_answers = [single]\n",
        "                else:\n",
        "                    extracted_final_answer = \"\"\n",
        "                    extracted_final_answers = []\n",
        "        else:\n",
        "            # we have one or more finals\n",
        "            extracted_final_answers = all_finals\n",
        "            if len(all_finals) == 1:\n",
        "                extracted_final_answer = all_finals[0]\n",
        "            else:\n",
        "                # store a machine-readable concatenation: JSON array string\n",
        "                try:\n",
        "                    extracted_final_answer = json.dumps(all_finals, ensure_ascii=False)\n",
        "                except Exception:\n",
        "                    extracted_final_answer = \" ||| \".join(all_finals)\n",
        "\n",
        "        # If still empty, save a failed extraction example for inspection\n",
        "        if not extracted_final_answer:\n",
        "            fname = f\"failed_{idx}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
        "            fpath = os.path.join(self.failed_folder, fname)\n",
        "            with open(fpath, 'w', encoding='utf-8') as f:\n",
        "                json.dump({\n",
        "                    \"index\": idx,\n",
        "                    \"question\": question,\n",
        "                    \"generated_answer\": generated_answer,\n",
        "                    \"thinking_content\": thinking_content,\n",
        "                    \"final_tag_output\": final_tag_output,\n",
        "                    \"exact_answer\": exact_answer,\n",
        "                    \"canonical_type\": canonical_type,\n",
        "                    \"extracted_final_answer\": extracted_final_answer,\n",
        "                    \"extracted_final_answers\": extracted_final_answers\n",
        "                }, f, ensure_ascii=False, indent=2)\n",
        "            print(f\"Saved failed extraction example to {fpath}\")\n",
        "\n",
        "        result_entry = {\n",
        "            \"problem_index\": idx,\n",
        "            \"language\": language,\n",
        "            \"chapter_number\": chapter_num,\n",
        "            \"example_number\": example_num,\n",
        "            \"question\": question,\n",
        "            \"generated_answer\": generated_answer,\n",
        "            \"thinking_content\": thinking_content,\n",
        "            \"final_tag_output\": final_tag_output,\n",
        "            \"extracted_final_answer\": extracted_final_answer,       # string (or JSON array string)\n",
        "            \"extracted_final_answers\": extracted_final_answers,     # list (empty / single / many)\n",
        "            \"exact_answer\": exact_answer,\n",
        "            \"raw_answer_type\": raw_answer_type,\n",
        "            \"canonical_answer_type\": canonical_type,\n",
        "            \"evaluation_method\": problem.get(\"Evaluation Method\", \"\")\n",
        "        }\n",
        "        return result_entry\n",
        "\n",
        "    def _create_error_entry(self, idx, problem, error_msg):\n",
        "        return {\n",
        "            \"problem_index\": idx,\n",
        "            \"language\": problem.get(\"Language\", \"\"),\n",
        "            \"chapter_number\": problem.get(\"Chapter Number\", \"\"),\n",
        "            \"example_number\": problem.get(\"Example Number\", \"\"),\n",
        "            \"question\": problem.get(\"Question\", \"\"),\n",
        "            \"generated_answer\": f\"ERROR: {error_msg}\",\n",
        "            \"thinking_content\": \"\",\n",
        "            \"final_tag_output\": \"\",\n",
        "            \"extracted_final_answer\": \"\",\n",
        "            \"extracted_final_answers\": [],\n",
        "            \"exact_answer\": problem.get(\"Exact Answer\", \"\"),\n",
        "            \"raw_answer_type\": problem.get(\"Answer Type\", \"\"),\n",
        "            \"canonical_answer_type\": \"\",\n",
        "            \"evaluation_method\": problem.get(\"Evaluation Method\", \"\")\n",
        "        }\n",
        "\n",
        "    def _print_progress(self, idx, result_entry):\n",
        "        print(f\"Generated answer length: {len(result_entry['generated_answer']) if result_entry['generated_answer'] else 0}\")\n",
        "        print(f\"Extracted final answer: '{result_entry['extracted_final_answer']}'\")\n",
        "        print(f\"Extracted final answers (list): {result_entry.get('extracted_final_answers', [])}\")\n",
        "        print(f\"Expected answer: '{result_entry['exact_answer']}'\")\n",
        "\n",
        "    def _save_intermediate_results(self, results, output_folder, count):\n",
        "        temp_filename = f'intermediate_results_{count}.json'\n",
        "        temp_output_path = os.path.join(output_folder, temp_filename)\n",
        "        with open(temp_output_path, 'w', encoding='utf-8') as f:\n",
        "            json.dump(results, f, ensure_ascii=False, indent=2)\n",
        "        print(f\"Saved intermediate results to {temp_output_path}\")\n",
        "\n",
        "    def _save_final_results(self, results, output_folder, start_idx, end_idx):\n",
        "        final_filename = f'final_results_{start_idx}_to_{end_idx-1}.json'\n",
        "        final_output_path = os.path.join(output_folder, final_filename)\n",
        "        with open(final_output_path, 'w', encoding='utf-8') as f:\n",
        "            json.dump(results, f, ensure_ascii=False, indent=2)\n",
        "        print(f\"\\nProcessing complete. Results saved to {final_output_path}\")\n",
        "        print(f\"Total problems processed: {len(results)}\")\n",
        "        return final_output_path\n",
        "\n",
        "    def _create_summary_file(self, results, output_folder, dataset_path, start_idx, end_idx):\n",
        "        successful_extractions = len([r for r in results if r.get('extracted_final_answer', '').strip()])\n",
        "        summary_data = {\n",
        "            \"processing_info\": {\n",
        "                \"dataset_path\": dataset_path,\n",
        "                \"start_index\": start_idx,\n",
        "                \"end_index\": end_idx - 1,\n",
        "                \"total_processed\": len(results),\n",
        "                \"processing_timestamp\": datetime.now().isoformat(),\n",
        "                \"output_folder\": output_folder\n",
        "            },\n",
        "            \"statistics\": {\n",
        "                \"successful_problems\": len([r for r in results if not r['generated_answer'].startswith('ERROR:')]),\n",
        "                \"failed_problems\": len([r for r in results if r['generated_answer'].startswith('ERROR:')]),\n",
        "                \"successful_extractions\": successful_extractions,\n",
        "                \"extraction_success_rate\": f\"{(successful_extractions/len(results)*100):.1f}%\" if results else \"0%\",\n",
        "                \"average_answer_length\": sum(len(r['generated_answer']) for r in results) / len(results) if results else 0,\n",
        "                \"chapters_processed\": list(set(r['chapter_number'] for r in results if r['chapter_number'])),\n",
        "                \"raw_answer_types\": list(set(r['raw_answer_type'] for r in results if r.get('raw_answer_type'))),\n",
        "                \"canonical_answer_types\": list(set(r['canonical_answer_type'] for r in results if r.get('canonical_answer_type')))\n",
        "            }\n",
        "        }\n",
        "        summary_path = os.path.join(output_folder, 'processing_summary.json')\n",
        "        with open(summary_path, 'w', encoding='utf-8') as f:\n",
        "            json.dump(summary_data, f, ensure_ascii=False, indent=2)\n",
        "        print(f\"Processing summary saved to {summary_path}\")\n",
        "        print(f\"Answer extraction success rate: {summary_data['statistics']['extraction_success_rate']}\")\n",
        "\n",
        "# -------------------------\n",
        "# Main (example usage)\n",
        "# -------------------------\n",
        "def main():\n",
        "    # NOTE: update dataset_path and output_base_path to match your environment.\n",
        "    # Ensure your dataset's \"Question\" fields are in Lithuanian.\n",
        "    dataset_path = \"/kaggle/input/nctb-dataset/Lithuanian_Final_Corpus.jsonl\"\n",
        "    output_base_path = \"/kaggle/working/\"\n",
        "\n",
        "    # Use the Ollama zero-shot solver (ensure the specified model is available in Ollama)\n",
        "    solver = OllamaZeroShotMathSolver(model_name=\"qwen3:8b\")\n",
        "    processor = DatasetProcessor(solver, failed_folder=os.path.join(output_base_path, \"failed_extractions\"))\n",
        "\n",
        "    # For quick testing, process only first few problems\n",
        "    results, out_folder = processor.process_dataset(\n",
        "        dataset_path,\n",
        "        output_base_path,\n",
        "        start_idx=0,\n",
        "        end_idx=100  # smaller quick test\n",
        "    )\n",
        "    print(\"Done. Results saved to:\", out_folder)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "tAarPml6c0S0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Turkish**"
      ],
      "metadata": {
        "id": "ugm2WDM5fPSA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "import re\n",
        "from datetime import datetime\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Ollama client\n",
        "try:\n",
        "    import ollama\n",
        "except Exception as e:\n",
        "    raise ImportError(\"The 'ollama' package is required. Install it and make sure the Ollama daemon is running.\") from e\n",
        "\n",
        "# -------------------------\n",
        "# Answer type normalization\n",
        "# -------------------------\n",
        "# Canonical set\n",
        "_CANONICAL_TYPES = {\"symbolic\", \"numerical\", \"proof\"}\n",
        "\n",
        "# mapping common noisy labels to canonical (English + Turkish variants)\n",
        "_ANSWER_TYPE_MAP_SIMPLE = {\n",
        "    # Proof variants (English -> Turkish)\n",
        "    \"proof\": \"proof\", \"prove\": \"proof\",\n",
        "    \"kanıt\": \"proof\", \"kanıtla\": \"proof\", \"kanıtlamak\": \"proof\", \"ispat\": \"proof\", \"kanıt göster\": \"proof\", \"göster\": \"proof\",\n",
        "\n",
        "    # Numerical variants\n",
        "    \"numerical\": \"numerical\", \"numeric\": \"numerical\", \"number\": \"numerical\", \"calculation\": \"numerical\",\n",
        "    \"sayısal\": \"numerical\", \"sayı\": \"numerical\", \"hesaplama\": \"numerical\", \"hesapla\": \"numerical\", \"bul\": \"numerical\",\n",
        "\n",
        "    # Symbolic variants\n",
        "    \"symbolic\": \"symbolic\", \"symbol\": \"symbolic\", \"equation\": \"symbolic\", \"algebraic\": \"symbolic\",\n",
        "    \"sembolik\": \"symbolic\", \"denklem\": \"symbolic\", \"yazılım\": \"symbolic\", \"cebirsel\": \"symbolic\",\n",
        "}\n",
        "\n",
        "\n",
        "def normalize_answer_type(raw_label: str, question_text: str = \"\", exact_answer: str = \"\") -> str:\n",
        "    \"\"\"\n",
        "    Normalize a dataset label to one of: 'symbolic', 'numerical', 'proof'.\n",
        "    Heuristics expanded to handle Turkish phrases and labels (plus English).\n",
        "    \"\"\"\n",
        "    # Helper to clean label\n",
        "    def _clean_label(lbl: str) -> str:\n",
        "        if not lbl:\n",
        "            return \"\"\n",
        "        s = lbl.strip().lower()\n",
        "        # keep unicode letters (Latin-1 and extended), digits and spaces (includes Turkish chars)\n",
        "        s = re.sub(r'[^0-9\\w\\s\\u00C0-\\u017F-]', ' ', s, flags=re.UNICODE)\n",
        "        s = re.sub(r'\\s+', ' ', s).strip()\n",
        "        return s\n",
        "\n",
        "    s = _clean_label(raw_label)\n",
        "\n",
        "    # direct mapping\n",
        "    if s in _ANSWER_TYPE_MAP_SIMPLE:\n",
        "        return _ANSWER_TYPE_MAP_SIMPLE[s]\n",
        "\n",
        "    # partial matches (allow English or Turkish keywords appearing)\n",
        "    for k, v in _ANSWER_TYPE_MAP_SIMPLE.items():\n",
        "        if k in s:\n",
        "            return v\n",
        "\n",
        "    # heuristics using question or exact_answer (both English & Turkish checks)\n",
        "    q = (question_text or \"\").lower()\n",
        "    a = (exact_answer or \"\").lower()\n",
        "\n",
        "    # Proof indicators (English + Turkish)\n",
        "    if re.search(r'\\b(prove|show that|prove that|proof)\\b', q) or re.search(r'\\b(kanıtla|kanıt|kanıtlamak|göster|ispat|kanıt göster)\\b', q, flags=re.IGNORECASE):\n",
        "        return \"proof\"\n",
        "\n",
        "    # logarithm related: English/Turkish\n",
        "    if re.search(r'\\b(log|ln|logarithm)\\b', q) or re.search(r'\\b(log|ln|logaritma)\\b', q) or re.search(r'\\blog\\b', a):\n",
        "        # prefer numerical if exact answer contains digits\n",
        "        if re.search(r'\\d', a):\n",
        "            return \"numerical\"\n",
        "        return \"symbolic\"\n",
        "\n",
        "    # set theory indicators: English / Turkish (küme = set)\n",
        "    if re.search(r'\\b(set|subset|union|intersection)\\b', q) or re.search(r'\\b(küme|altküme|birleşim|kesişim|kesi\\u015Fim)\\b', q, flags=re.IGNORECASE):\n",
        "        return \"symbolic\"\n",
        "\n",
        "    # units (English + Turkish)\n",
        "    if re.search(r'\\bmeter\\b|\\bm\\b|\\bcm\\b|\\bkg\\b|\\bliter\\b|\\bl\\b|\\bkm\\b|\\bmile\\b', q + \" \" + a) or \\\n",
        "       re.search(r'\\bmetre\\b|\\bcm\\b|\\bkg\\b|\\blitre\\b|\\bl\\b|\\bkm\\b', q + \" \" + a, flags=re.IGNORECASE):\n",
        "        return \"numerical\"\n",
        "\n",
        "    # equation-solving heuristics (English + Turkish)\n",
        "    if re.search(r'\\bequation\\b|solve for|solve|= x|x\\s*=', q) or re.search(r'\\b(denklem|çöz(ün|ün|mek)|çöz|çözün)\\b', q, flags=re.IGNORECASE):\n",
        "        return \"symbolic\"\n",
        "\n",
        "    # trig / geometry indicators (English + Turkish)\n",
        "    if re.search(r'\\b(trig|sin|cos|tan|geometry|triangle|circle)\\b', q) or re.search(r'\\b(trigonometr|sin|cos|tan|geometri|üçgen|daire|çember)\\b', q, flags=re.IGNORECASE):\n",
        "        if re.search(r'\\d', a):\n",
        "            return \"numerical\"\n",
        "        return \"symbolic\"\n",
        "\n",
        "    # numeric indicators (English + Turkish) -> numerical\n",
        "    if re.search(r'\\d', q) or re.search(r'find the value|compute|calculate|evaluate', q) or \\\n",
        "       re.search(r'değerini bul|bulun|hesapla|hesaplayın|hesaplama|sayısını bulun|kaç)', q, flags=re.IGNORECASE):\n",
        "        return \"numerical\"\n",
        "\n",
        "    # If exact_answer looks numeric, prefer numerical (but check for LaTeX)\n",
        "    if re.search(r'[0-9]|\\\\frac|\\\\sqrt', a):\n",
        "        if re.search(r'\\\\frac|\\\\sqrt|\\{|\\\\', a):\n",
        "            return \"symbolic\"\n",
        "        return \"numerical\"\n",
        "\n",
        "    # fallback\n",
        "    return \"symbolic\"\n",
        "\n",
        "# -------------------------\n",
        "# EnhancedAnswerExtractor (adapted to behave like SimplifiedAnswerExtractor)\n",
        "# and now handles Turkish markers as well\n",
        "# -------------------------\n",
        "class EnhancedAnswerExtractor:\n",
        "    \"\"\"\n",
        "    Adapter that implements the simplified extraction behavior,\n",
        "    extended to recognize Turkish formatting/conclusion words as well.\n",
        "    Provides:\n",
        "      - extract_final_answer(text) -> str\n",
        "      - extract_all_final_answers(generated_solution) -> list\n",
        "    and internal helpers _clean_answer and _is_valid_answer.\n",
        "    \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def _clean_answer(answer: str) -> str:\n",
        "        if not answer:\n",
        "            return \"\"\n",
        "        # Start with a trimmed answer and normalize whitespace\n",
        "        a = answer.strip()\n",
        "        # collapse whitespace\n",
        "        a = re.sub(r'\\s+', ' ', a)\n",
        "\n",
        "        # remove outer $$ if present (multiline)\n",
        "        a = re.sub(r'^\\$\\$(.*)\\$\\$$', r'\\1', a, flags=re.DOTALL)\n",
        "        # remove surrounding single $ if the whole string is wrapped\n",
        "        a = re.sub(r'^\\$(.*)\\$$', r'\\1', a, flags=re.DOTALL)\n",
        "\n",
        "        # strip standalone leading/trailing $ characters and spaces\n",
        "        a = a.strip('$ ')\n",
        "\n",
        "        # Remove common prefixes (kept after stripping $ to catch cases like \"$Final Answer: ...$\")\n",
        "        prefixes_to_remove = [\n",
        "            # English\n",
        "            r'Final Answer:\\s*', r'Answer:\\s*', r'The answer is\\s*',\n",
        "            r'Therefore,?\\s*', r'Thus,?\\s*', r'Hence,?\\s*', r'So,?\\s*', r'∴\\s*',\n",
        "\n",
        "            # Turkish\n",
        "            r'Final Cevap[:\\s]*', r'Final cevap[:\\s]*', r'Sonuç[:\\s]*', r'Son cevap[:\\s]*',\n",
        "            r'Cevap[:\\s]*', r'Cevap olarak[:\\s]*', r'Netice[:\\s]*',\n",
        "            r'Dolayısıyla,?\\s*', r'Böylece,?\\s*', r'Bu nedenle,?\\s*', r'O halde,?\\s*', r'Öyleyse,?\\s*',\n",
        "        ]\n",
        "        for prefix in prefixes_to_remove:\n",
        "            a = re.sub(f'^{prefix}', '', a, flags=re.IGNORECASE)\n",
        "\n",
        "        # remove various boxed wrappers with optional backslashes and optional surrounding $\n",
        "        # e.g. $$\\boxed{...}$$, $\\boxed{...}$, \\boxed{...}\n",
        "        a = re.sub(r'\\$?\\s*(?:\\\\){0,3}boxed\\{([^}]*)\\}\\s*\\$?', r'\\1', a, flags=re.DOTALL | re.IGNORECASE)\n",
        "        # also ensure plain \\boxed{...} is unwrapped (redundant but safe)\n",
        "        a = re.sub(r'\\\\boxed\\{([^}]*)\\}', r'\\1', a)\n",
        "\n",
        "        # convert common LaTeX to readable forms\n",
        "        a = re.sub(r'\\\\frac\\{([^}]*)\\}\\{([^}]*)\\}', r'(\\1)/(\\2)', a)\n",
        "        a = re.sub(r'\\\\sqrt\\{([^}]*)\\}', r'√(\\1)', a)\n",
        "\n",
        "        # remove bold/italic wrappers\n",
        "        a = re.sub(r'\\*\\*([^*]+)\\*\\*', r'\\1', a)\n",
        "        a = re.sub(r'\\*([^*]+)\\*', r'\\1', a)\n",
        "\n",
        "        # collapse multiple spaces again (in case replacements introduced them)\n",
        "        a = re.sub(r'\\s+', ' ', a).strip()\n",
        "\n",
        "        # trim trailing punctuation/words\n",
        "        a = a.rstrip(' \\t\\n.,;:')\n",
        "\n",
        "        # remove trailing words like \"proved\" or \"the answer\" (English & Turkish)\n",
        "        a = re.sub(r'\\b(proved|completed|finished|the answer|kanıtlandı|kanıt|cevap|sonuç)\\b[.\\s]*$', '', a, flags=re.IGNORECASE).strip()\n",
        "\n",
        "        return a\n",
        "\n",
        "    @staticmethod\n",
        "    def _is_valid_answer(answer: str) -> bool:\n",
        "        if not answer:\n",
        "            return False\n",
        "        # not only punctuation\n",
        "        if re.match(r'^[\\W_]+$', answer):\n",
        "            return False\n",
        "        # contains at least some alphanumeric characters (or common math symbols)\n",
        "        if not re.search(r'[0-9A-Za-z\\u00C0-\\u017F\\\\]', answer):\n",
        "            return False\n",
        "        # length sanity\n",
        "        if len(answer) > 1000:\n",
        "            return False\n",
        "        # avoid answers that end with only concluding words (English & Turkish)\n",
        "        blacklist = [r'therefore$', r'thus$', r'hence$', r'so$', r'we get$', r'we have$', r'dolayısıyla$', r'böylece$', r'bu nedenle$']\n",
        "        for b in blacklist:\n",
        "            if re.search(b, answer.strip(), flags=re.IGNORECASE):\n",
        "                return False\n",
        "        return True\n",
        "\n",
        "    @staticmethod\n",
        "    def extract_final_answer_simple(text: str) -> str:\n",
        "        \"\"\"\n",
        "        Primary method: Extract final answer using the last lines approach,\n",
        "        with fallback to pattern-based extraction.\n",
        "        \"\"\"\n",
        "        if not text:\n",
        "            return \"\"\n",
        "\n",
        "        # Clean the text and split into lines\n",
        "        lines = [line.strip() for line in text.strip().split('\\n') if line.strip()]\n",
        "\n",
        "        # Strategy 1: Try last two lines combined\n",
        "        if len(lines) >= 2:\n",
        "            last_two = ' '.join(lines[-2:])\n",
        "            cleaned = EnhancedAnswerExtractor._clean_answer(last_two)\n",
        "            if EnhancedAnswerExtractor._is_valid_answer(cleaned):\n",
        "                return cleaned\n",
        "\n",
        "        # Strategy 2: Try last line only\n",
        "        if lines:\n",
        "            cleaned = EnhancedAnswerExtractor._clean_answer(lines[-1])\n",
        "            if EnhancedAnswerExtractor._is_valid_answer(cleaned):\n",
        "                return cleaned\n",
        "\n",
        "        # Strategy 3: Try last 3 lines if we have them (sometimes answers span multiple lines)\n",
        "        if len(lines) >= 3:\n",
        "            last_three = ' '.join(lines[-3:])\n",
        "            cleaned = EnhancedAnswerExtractor._clean_answer(last_three)\n",
        "            if EnhancedAnswerExtractor._is_valid_answer(cleaned) and len(cleaned) < 500:\n",
        "                return cleaned\n",
        "\n",
        "        # Strategy 4: Fallback to pattern-based extraction\n",
        "        return EnhancedAnswerExtractor._extract_with_patterns(text)\n",
        "\n",
        "    @staticmethod\n",
        "    def _extract_with_patterns(text: str) -> str:\n",
        "        \"\"\"\n",
        "        Pattern-based extraction as fallback method.\n",
        "        Recognizes both English and Turkish answer/conclusion patterns.\n",
        "        \"\"\"\n",
        "        # Check for <final> tags\n",
        "        raw_matches = re.findall(r'<final>(.*?)</final>', text, re.DOTALL | re.IGNORECASE)\n",
        "        for m in raw_matches:\n",
        "            c = EnhancedAnswerExtractor._clean_answer(m)\n",
        "            if EnhancedAnswerExtractor._is_valid_answer(c):\n",
        "                return c\n",
        "\n",
        "        # Try common answer patterns (English + Turkish)\n",
        "        patterns = [\n",
        "            r'\\*\\*Final Answer:\\*\\*\\s*(.+?)(?:\\n|$)',\n",
        "            r'Final Answer:\\s*(.+?)(?:\\n|$)',\n",
        "            r'Final Answer\\s*[:\\-]\\s*(.+?)(?:\\n|$)',\n",
        "\n",
        "            # Turkish patterns\n",
        "            r'\\*\\*Sonuç:\\*\\*\\s*(.+?)(?:\\n|$)',\n",
        "            r'Sonuç[:\\s]*(.+?)(?:\\n|$)',\n",
        "            r'Son cevap[:\\s]*(.+?)(?:\\n|$)',\n",
        "            r'Cevap[:\\s]*(.+?)(?:\\n|$)',\n",
        "            r'Nihai cevap[:\\s]*(.+?)(?:\\n|$)',\n",
        "\n",
        "            # English conclusion markers\n",
        "            r'Therefore[,:\\s]*(.+?)(?:\\.|$|\\n)',\n",
        "            r'Hence[,:\\s]*(.+?)(?:\\.|$|\\n)',\n",
        "            r'Thus[,:\\s]*(.+?)(?:\\.|$|\\n)',\n",
        "            r'∴\\s*(.+?)(?:\\.|$|\\n)',\n",
        "\n",
        "            # Turkish conclusion markers\n",
        "            r'Dolayısıyla[,:\\s]*(.+?)(?:\\.|$|\\n)',\n",
        "            r'Böylece[,:\\s]*(.+?)(?:\\.|$|\\n)',\n",
        "            r'Bu nedenle[,:\\s]*(.+?)(?:\\.|$|\\n)',\n",
        "            r'O halde[,:\\s]*(.+?)(?:\\.|$|\\n)',\n",
        "            r'Öyleyse[,:\\s]*(.+?)(?:\\.|$|\\n)',\n",
        "\n",
        "            r'Answer[:\\s]*(.+?)(?:\\n|$)',\n",
        "            r'Result[:\\s]*(.+?)(?:\\n|$)',\n",
        "            r'Solution[:\\s]*(.+?)(?:\\n|$)',\n",
        "        ]\n",
        "\n",
        "        for pat in patterns:\n",
        "            matches = re.findall(pat, text, re.MULTILINE | re.DOTALL | re.IGNORECASE)\n",
        "            if matches:\n",
        "                answer = matches[-1].strip()\n",
        "                cleaned = EnhancedAnswerExtractor._clean_answer(answer)\n",
        "                if EnhancedAnswerExtractor._is_valid_answer(cleaned):\n",
        "                    return cleaned\n",
        "\n",
        "        # Try boxed math expressions (LaTeX boxed)\n",
        "        boxed_patterns = [\n",
        "            r'\\$\\$\\s*(?:\\\\){0,3}boxed\\{(.+?)\\}\\s*\\$\\$',\n",
        "            r'\\$\\s*(?:\\\\){0,3}boxed\\{(.+?)\\}\\s*\\$',\n",
        "            r'(?:\\\\){0,3}boxed\\{(.+?)\\}',\n",
        "        ]\n",
        "\n",
        "        for pat in boxed_patterns:\n",
        "            m = re.search(pat, text, re.DOTALL | re.IGNORECASE)\n",
        "            if m:\n",
        "                cand = EnhancedAnswerExtractor._clean_answer(m.group(1))\n",
        "                if EnhancedAnswerExtractor._is_valid_answer(cand):\n",
        "                    return cand\n",
        "\n",
        "        return \"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def extract_all_final_answers(generated_solution: str) -> list:\n",
        "        \"\"\"\n",
        "        Extract multiple final answers using simplified approach.\n",
        "        Returns a list (possibly empty) of cleaned answers found inside all <final>...</final> tags.\n",
        "        Falls back to the single simplified extraction if no tags are found.\n",
        "        \"\"\"\n",
        "        if not generated_solution:\n",
        "            return []\n",
        "\n",
        "        # Find all <final>...</final> (non-greedy)\n",
        "        raw_matches = re.findall(r'<final>(.*?)</final>', generated_solution, re.DOTALL | re.IGNORECASE)\n",
        "        cleaned = []\n",
        "        for m in raw_matches:\n",
        "            c = EnhancedAnswerExtractor._clean_answer(m)\n",
        "            if EnhancedAnswerExtractor._is_valid_answer(c):\n",
        "                cleaned.append(c)\n",
        "\n",
        "        if cleaned:\n",
        "            return cleaned\n",
        "\n",
        "        # Fallback: try to extract a single final using the simpler logic\n",
        "        simple_answer = EnhancedAnswerExtractor.extract_final_answer_simple(generated_solution)\n",
        "        if simple_answer:\n",
        "            return [simple_answer]\n",
        "\n",
        "        return []\n",
        "\n",
        "    @staticmethod\n",
        "    def extract_final_answer(generated_solution: str) -> str:\n",
        "        \"\"\"\n",
        "        Backwards-compatible extractor that delegates to the simplified extraction.\n",
        "        If multiple <final> tags exist, returns a JSON array string of cleaned answers.\n",
        "        \"\"\"\n",
        "        if not generated_solution:\n",
        "            return \"\"\n",
        "\n",
        "        # Prefer explicit <final> tags (can be multiple)\n",
        "        raw_matches = re.findall(r'<final>(.*?)</final>', generated_solution, re.DOTALL | re.IGNORECASE)\n",
        "        if raw_matches:\n",
        "            cleaned = []\n",
        "            for m in raw_matches:\n",
        "                c = EnhancedAnswerExtractor._clean_answer(m)\n",
        "                if EnhancedAnswerExtractor._is_valid_answer(c):\n",
        "                    cleaned.append(c)\n",
        "            if not cleaned:\n",
        "                # fall through to simpler single extraction\n",
        "                return EnhancedAnswerExtractor.extract_final_answer_simple(generated_solution)\n",
        "            if len(cleaned) == 1:\n",
        "                return cleaned[0]\n",
        "            try:\n",
        "                return json.dumps(cleaned, ensure_ascii=False)\n",
        "            except Exception:\n",
        "                return \" ||| \".join(cleaned)\n",
        "\n",
        "        # No explicit finals: use simplified single extraction\n",
        "        return EnhancedAnswerExtractor.extract_final_answer_simple(generated_solution)\n",
        "\n",
        "# -------------------------\n",
        "# Ollama-based Math Solver (ZERO-SHOT) — PROMPTS IN ENGLISH (problem is Turkish)\n",
        "# -------------------------\n",
        "class OllamaZeroShotMathSolver:\n",
        "    \"\"\"\n",
        "    Zero-shot math solver that uses the Ollama daemon via the Python client.\n",
        "    Prompts/instructions are written in English (as requested), but the solver is informed that\n",
        "    the problem text will be in TURKISH and is instructed to provide a concise final answer in TURKISH.\n",
        "    - Zero-shot prompt: forbids chain-of-thought and requests concise final <final> tag\n",
        "    - Single-pass only.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model_name=\"qwen3:8b\"):\n",
        "        \"\"\"\n",
        "        model_name: the Ollama model reference (e.g., \"qwen3:8b\")\n",
        "        \"\"\"\n",
        "        self.model_name = model_name\n",
        "        self.client = self._load_client()\n",
        "\n",
        "    def _load_client(self):\n",
        "        print(f\"Initializing Ollama client for model: {self.model_name}\")\n",
        "        client = ollama.Client()\n",
        "        return client\n",
        "\n",
        "    def cleanup(self):\n",
        "        if hasattr(self, 'client'):\n",
        "            del self.client\n",
        "\n",
        "    def _get_format_instructions(self, answer_type):\n",
        "        \"\"\"\n",
        "        Zero-shot formatting instructions (WRITTEN IN ENGLISH).\n",
        "        The model is explicitly informed that the problem text is in TURKISH and that the concise final\n",
        "        answer should be provided in TURKISH. Examples/formats are shown in English but demonstrate\n",
        "        that the final tag must contain the concise Turkish answer.\n",
        "        \"\"\"\n",
        "        t = (answer_type or \"symbolic\").strip().lower()\n",
        "        if t not in _CANONICAL_TYPES:\n",
        "            t = \"symbolic\"\n",
        "\n",
        "        base = (\n",
        "            \"CRITICAL FORMATTING REQUIREMENTS (ZERO-SHOT):\\n\"\n",
        "            \"- The math problem you will receive is written in TURKISH. Provide your concise FINAL ANSWER in TURKISH.\\n\"\n",
        "            \"- DO NOT provide chain-of-thought or step-by-step internal reasoning. Do NOT reveal private chain-of-thought.\\n\"\n",
        "            \"- If a very short justification is necessary, include a single-line 'Explanation:' with at most one sentence (in Turkish).\\n\"\n",
        "            \"- Always end with a machine-readable final tag <final>...</final> containing ONLY the concise final answer in TURKISH (no extra reasoning inside the tag).\\n\"\n",
        "        )\n",
        "\n",
        "        if t == \"proof\":\n",
        "            return base + (\n",
        "                \"FOR PROOFS (zero-shot):\\n\"\n",
        "                \"- Provide a concise conclusion or a one-sentence proof sketch (in TURKISH) labeled 'Sonuç:' or 'İspat özeti:' if needed. Do NOT provide a full step-by-step proof.\\n\"\n",
        "                \"Format example (English instructions):\\n\"\n",
        "                \"Final Answer (in Turkish):\\n\"\n",
        "                \"[Concise Turkish conclusion or one-sentence sketch]\\n\\n\"\n",
        "                \"<final>[Concise Turkish conclusion]</final>\\n\"\n",
        "            )\n",
        "        elif t == \"numerical\":\n",
        "            return base + (\n",
        "                \"FOR NUMERICAL RESULTS:\\n\"\n",
        "                \"- Provide the numeric result in exact form if available (fractions/radicals). Otherwise provide a decimal rounded to 4 decimal places.\\n\"\n",
        "                \"Format example (English instructions):\\n\"\n",
        "                \"Final Answer (in Turkish):\\n\"\n",
        "                \"[Numeric result]\\n\\n\"\n",
        "                \"<final>[Numeric result]</final>\\n\"\n",
        "            )\n",
        "        else:  # symbolic\n",
        "            return base + (\n",
        "                \"FOR SYMBOLIC RESULTS:\\n\"\n",
        "                \"- Provide the final symbolic expression (LaTeX allowed) in a concise form. The expression may be LaTeX but any wording should be in Turkish if used.\\n\"\n",
        "                \"Format example (English instructions):\\n\"\n",
        "                \"Final Answer (in Turkish):\\n\"\n",
        "                \"[Final symbolic expression]\\n\\n\"\n",
        "                \"<final>[LaTeX expression or concise symbolic expression — in Turkish if words are used]</final>\\n\"\n",
        "            )\n",
        "\n",
        "    def _create_prompt(self, question, answer_type=\"symbolic\"):\n",
        "        format_instructions = self._get_format_instructions(answer_type)\n",
        "\n",
        "        # The main instruction is in English (per your requirement), but it states the problem language and required answer language.\n",
        "        prompt = f\"\"\"You are an expert mathematician. The following math problem is written in TURKISH.\n",
        "Provide a concise final answer in TURKISH. DO NOT produce chain-of-thought or step-by-step internal reasoning.\n",
        "If you include a justification, it must be one short sentence and labeled 'Explanation:' (in Turkish).\n",
        "\n",
        "MATH PROBLEM (in Turkish):\n",
        "{question}\n",
        "\n",
        "{format_instructions}\n",
        "\n",
        "Begin your concise answer (in Turkish) now:\n",
        "\"\"\"\n",
        "        return prompt\n",
        "\n",
        "    def _generate_once(self, prompt_text: str, enable_thinking: bool = False) -> str:\n",
        "        \"\"\"\n",
        "        Call ollama.Client.chat WITHOUT temperature/max_tokens.\n",
        "        Handles several possible response shapes.\n",
        "        \"\"\"\n",
        "        messages = [{\"role\": \"user\", \"content\": prompt_text}]\n",
        "\n",
        "        # Call Ollama client.chat without temperature/max_tokens\n",
        "        try:\n",
        "            resp = self.client.chat(model=self.model_name, messages=messages, think=enable_thinking)\n",
        "        except TypeError:\n",
        "            # Some client versions have different signatures\n",
        "            try:\n",
        "                resp = self.client.chat(self.model_name, messages=messages, think=enable_thinking)\n",
        "            except Exception:\n",
        "                resp = self.client.chat(self.model_name, messages)\n",
        "\n",
        "        # Normalize response into a string\n",
        "        full_output = \"\"\n",
        "        if isinstance(resp, dict):\n",
        "            if 'message' in resp and isinstance(resp['message'], dict) and 'content' in resp['message']:\n",
        "                full_output = resp['message']['content']\n",
        "            elif 'choices' in resp and isinstance(resp['choices'], (list, tuple)) and resp['choices']:\n",
        "                choice = resp['choices'][0]\n",
        "                if isinstance(choice, dict) and 'message' in choice and isinstance(choice['message'], dict):\n",
        "                    full_output = choice['message'].get('content', '')\n",
        "                else:\n",
        "                    full_output = str(choice)\n",
        "            else:\n",
        "                full_output = str(resp)\n",
        "        else:\n",
        "            # resp might be an object with .message.content\n",
        "            try:\n",
        "                full_output = resp.message.content\n",
        "            except Exception:\n",
        "                full_output = str(resp)\n",
        "\n",
        "        if isinstance(full_output, bytes):\n",
        "            full_output = full_output.decode('utf-8', errors='ignore')\n",
        "        return (full_output or \"\").strip()\n",
        "\n",
        "    def solve_problem(self, question, answer_type=\"symbolic\"):\n",
        "        \"\"\"\n",
        "        Zero-shot single-pass solve via Ollama.\n",
        "        \"\"\"\n",
        "        prompt = self._create_prompt(question, answer_type)\n",
        "        full_output = self._generate_once(prompt, enable_thinking=False)\n",
        "\n",
        "        # No thinking parsing for zero-shot mode\n",
        "        thinking_content = \"\"\n",
        "        generated_answer = full_output\n",
        "        final_tag_output = \"\"  # no second pass\n",
        "\n",
        "        extracted_final_answer = EnhancedAnswerExtractor.extract_final_answer(generated_answer)\n",
        "\n",
        "        return {\n",
        "            \"thinking_content\": thinking_content,\n",
        "            \"generated_answer\": generated_answer,\n",
        "            \"final_tag_output\": final_tag_output,\n",
        "            \"extracted_final_answer\": extracted_final_answer\n",
        "        }\n",
        "\n",
        "# -------------------------\n",
        "# Dataset Processor\n",
        "# -------------------------\n",
        "class DatasetProcessor:\n",
        "    def __init__(self, solver: OllamaZeroShotMathSolver, failed_folder=None):\n",
        "        self.solver = solver\n",
        "        self.extractor = EnhancedAnswerExtractor()\n",
        "        self.failed_folder = failed_folder or \"failed_extractions\"\n",
        "        os.makedirs(self.failed_folder, exist_ok=True)\n",
        "\n",
        "    def process_dataset(self, dataset_path, output_base_path, start_idx=0, end_idx=None,\n",
        "                        folder_name=None, create_timestamped_folder=True):\n",
        "        dataset = self._load_dataset(dataset_path)\n",
        "        if end_idx is None:\n",
        "            end_idx = len(dataset)\n",
        "\n",
        "        output_folder = self._create_output_folder(output_base_path, folder_name, start_idx, end_idx, create_timestamped_folder)\n",
        "        results = []\n",
        "\n",
        "        print(f\"Processing problems {start_idx} to {end_idx-1} ({end_idx-start_idx} total)\")\n",
        "        print(f\"Output will be saved in: {output_folder}\")\n",
        "\n",
        "        for idx in tqdm(range(start_idx, min(end_idx, len(dataset)))):\n",
        "            problem = dataset[idx]\n",
        "            try:\n",
        "                result_entry = self._process_single_problem(idx, problem)\n",
        "                results.append(result_entry)\n",
        "                self._print_progress(idx, result_entry)\n",
        "                if (idx - start_idx + 1) % 10 == 0:\n",
        "                    self._save_intermediate_results(results, output_folder, idx - start_idx + 1)\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing problem {idx+1}: {str(e)}\")\n",
        "                error_entry = self._create_error_entry(idx, problem, str(e))\n",
        "                results.append(error_entry)\n",
        "\n",
        "        final_output_path = self._save_final_results(results, output_folder, start_idx, end_idx)\n",
        "        self._create_summary_file(results, output_folder, dataset_path, start_idx, end_idx)\n",
        "        return results, output_folder\n",
        "\n",
        "    def _create_output_folder(self, base_path, folder_name, start_idx, end_idx, add_timestamp):\n",
        "        if folder_name is None:\n",
        "            folder_name = f\"results_{start_idx}_to_{end_idx-1}\"\n",
        "        if add_timestamp:\n",
        "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "            folder_name = f\"{folder_name}_{timestamp}\"\n",
        "        output_folder = os.path.join(base_path, folder_name)\n",
        "        os.makedirs(output_folder, exist_ok=True)\n",
        "        return output_folder\n",
        "\n",
        "    def _load_dataset(self, dataset_path):\n",
        "        dataset = []\n",
        "        with open(dataset_path, 'r', encoding='utf-8') as f:\n",
        "            for line in f:\n",
        "                if line.strip():\n",
        "                    dataset.append(json.loads(line))\n",
        "        return dataset\n",
        "\n",
        "    def _process_single_problem(self, idx, problem):\n",
        "        language = problem.get(\"Language\", \"\")\n",
        "        chapter_num = problem.get(\"Chapter Number\", \"\")\n",
        "        example_num = problem.get(\"Example Number\", \"\")\n",
        "        question = problem.get(\"Question\", \"\")\n",
        "        exact_answer = problem.get(\"Exact Answer\", \"\")\n",
        "        raw_answer_type = problem.get(\"Answer Type\", \"\") or \"\"\n",
        "\n",
        "        # Normalize/infer canonical answer type: 'symbolic', 'numerical', 'proof'\n",
        "        canonical_type = normalize_answer_type(raw_answer_type, question_text=question, exact_answer=exact_answer)\n",
        "\n",
        "        # If exact_answer strongly indicates numeric, prefer numerical\n",
        "        if exact_answer and re.search(r'\\d', str(exact_answer)):\n",
        "            # if exact contains LaTeX expressions like \\frac or \\sqrt, keep symbolic\n",
        "            if re.search(r'\\\\frac|\\\\sqrt|\\\\boxed', str(exact_answer)):\n",
        "                pass\n",
        "            else:\n",
        "                canonical_type = \"numerical\"\n",
        "\n",
        "        print(f\"\\nProcessing Problem {idx+1}: Chapter {chapter_num}, Example {example_num}\")\n",
        "        print(f\"Raw Answer Type: '{raw_answer_type}'  --> canonical: '{canonical_type}'\")\n",
        "\n",
        "        # Generate solution (use canonical_type) -- zero-shot, single pass\n",
        "        solution_result = self.solver.solve_problem(question, answer_type=canonical_type)\n",
        "        generated_answer = solution_result.get('generated_answer', '')\n",
        "        thinking_content = solution_result.get('thinking_content', '')  # will be empty\n",
        "        final_tag_output = solution_result.get('final_tag_output', '')\n",
        "\n",
        "        # --- NEW extraction logic: keep both forms (single string & list) ---\n",
        "        # Try to get all <final> answers first (preferred)\n",
        "        all_finals = EnhancedAnswerExtractor.extract_all_final_answers(generated_answer)\n",
        "        extracted_final_answer = \"\"\n",
        "        extracted_final_answers = []\n",
        "\n",
        "        # If none found in generated_answer, try final_tag_output (unused here)\n",
        "        if not all_finals and final_tag_output:\n",
        "            all_finals = EnhancedAnswerExtractor.extract_all_final_answers(final_tag_output)\n",
        "\n",
        "        # If still none, fall back to single-answer extractor\n",
        "        if not all_finals:\n",
        "            single = EnhancedAnswerExtractor.extract_final_answer(generated_answer)\n",
        "            if single:\n",
        "                extracted_final_answer = single\n",
        "                extracted_final_answers = [single]\n",
        "            else:\n",
        "                # try whole combined text (thinking + generated + final_tag)\n",
        "                combined = \"\\n\".join([thinking_content or \"\", generated_answer or \"\", final_tag_output or \"\"])\n",
        "                single = EnhancedAnswerExtractor.extract_final_answer(combined)\n",
        "                if single:\n",
        "                    extracted_final_answer = single\n",
        "                    extracted_final_answers = [single]\n",
        "                else:\n",
        "                    extracted_final_answer = \"\"\n",
        "                    extracted_final_answers = []\n",
        "        else:\n",
        "            # we have one or more finals\n",
        "            extracted_final_answers = all_finals\n",
        "            if len(all_finals) == 1:\n",
        "                extracted_final_answer = all_finals[0]\n",
        "            else:\n",
        "                # store a machine-readable concatenation: JSON array string\n",
        "                try:\n",
        "                    extracted_final_answer = json.dumps(all_finals, ensure_ascii=False)\n",
        "                except Exception:\n",
        "                    extracted_final_answer = \" ||| \".join(all_finals)\n",
        "\n",
        "        # If still empty, save a failed extraction example for inspection\n",
        "        if not extracted_final_answer:\n",
        "            fname = f\"failed_{idx}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
        "            fpath = os.path.join(self.failed_folder, fname)\n",
        "            with open(fpath, 'w', encoding='utf-8') as f:\n",
        "                json.dump({\n",
        "                    \"index\": idx,\n",
        "                    \"question\": question,\n",
        "                    \"generated_answer\": generated_answer,\n",
        "                    \"thinking_content\": thinking_content,\n",
        "                    \"final_tag_output\": final_tag_output,\n",
        "                    \"exact_answer\": exact_answer,\n",
        "                    \"canonical_type\": canonical_type,\n",
        "                    \"extracted_final_answer\": extracted_final_answer,\n",
        "                    \"extracted_final_answers\": extracted_final_answers\n",
        "                }, f, ensure_ascii=False, indent=2)\n",
        "            print(f\"Saved failed extraction example to {fpath}\")\n",
        "\n",
        "        result_entry = {\n",
        "            \"problem_index\": idx,\n",
        "            \"language\": language,\n",
        "            \"chapter_number\": chapter_num,\n",
        "            \"example_number\": example_num,\n",
        "            \"question\": question,\n",
        "            \"generated_answer\": generated_answer,\n",
        "            \"thinking_content\": thinking_content,\n",
        "            \"final_tag_output\": final_tag_output,\n",
        "            \"extracted_final_answer\": extracted_final_answer,       # string (or JSON array string)\n",
        "            \"extracted_final_answers\": extracted_final_answers,     # list (empty / single / many)\n",
        "            \"exact_answer\": exact_answer,\n",
        "            \"raw_answer_type\": raw_answer_type,\n",
        "            \"canonical_answer_type\": canonical_type,\n",
        "            \"evaluation_method\": problem.get(\"Evaluation Method\", \"\")\n",
        "        }\n",
        "        return result_entry\n",
        "\n",
        "    def _create_error_entry(self, idx, problem, error_msg):\n",
        "        return {\n",
        "            \"problem_index\": idx,\n",
        "            \"language\": problem.get(\"Language\", \"\"),\n",
        "            \"chapter_number\": problem.get(\"Chapter Number\", \"\"),\n",
        "            \"example_number\": problem.get(\"Example Number\", \"\"),\n",
        "            \"question\": problem.get(\"Question\", \"\"),\n",
        "            \"generated_answer\": f\"ERROR: {error_msg}\",\n",
        "            \"thinking_content\": \"\",\n",
        "            \"final_tag_output\": \"\",\n",
        "            \"extracted_final_answer\": \"\",\n",
        "            \"extracted_final_answers\": [],\n",
        "            \"exact_answer\": problem.get(\"Exact Answer\", \"\"),\n",
        "            \"raw_answer_type\": problem.get(\"Answer Type\", \"\"),\n",
        "            \"canonical_answer_type\": \"\",\n",
        "            \"evaluation_method\": problem.get(\"Evaluation Method\", \"\")\n",
        "        }\n",
        "\n",
        "    def _print_progress(self, idx, result_entry):\n",
        "        print(f\"Generated answer length: {len(result_entry['generated_answer']) if result_entry['generated_answer'] else 0}\")\n",
        "        print(f\"Extracted final answer: '{result_entry['extracted_final_answer']}'\")\n",
        "        print(f\"Extracted final answers (list): {result_entry.get('extracted_final_answers', [])}\")\n",
        "        print(f\"Expected answer: '{result_entry['exact_answer']}'\")\n",
        "\n",
        "    def _save_intermediate_results(self, results, output_folder, count):\n",
        "        temp_filename = f'intermediate_results_{count}.json'\n",
        "        temp_output_path = os.path.join(output_folder, temp_filename)\n",
        "        with open(temp_output_path, 'w', encoding='utf-8') as f:\n",
        "            json.dump(results, f, ensure_ascii=False, indent=2)\n",
        "        print(f\"Saved intermediate results to {temp_output_path}\")\n",
        "\n",
        "    def _save_final_results(self, results, output_folder, start_idx, end_idx):\n",
        "        final_filename = f'final_results_{start_idx}_to_{end_idx-1}.json'\n",
        "        final_output_path = os.path.join(output_folder, final_filename)\n",
        "        with open(final_output_path, 'w', encoding='utf-8') as f:\n",
        "            json.dump(results, f, ensure_ascii=False, indent=2)\n",
        "        print(f\"\\nProcessing complete. Results saved to {final_output_path}\")\n",
        "        print(f\"Total problems processed: {len(results)}\")\n",
        "        return final_output_path\n",
        "\n",
        "    def _create_summary_file(self, results, output_folder, dataset_path, start_idx, end_idx):\n",
        "        successful_extractions = len([r for r in results if r.get('extracted_final_answer', '').strip()])\n",
        "        summary_data = {\n",
        "            \"processing_info\": {\n",
        "                \"dataset_path\": dataset_path,\n",
        "                \"start_index\": start_idx,\n",
        "                \"end_index\": end_idx - 1,\n",
        "                \"total_processed\": len(results),\n",
        "                \"processing_timestamp\": datetime.now().isoformat(),\n",
        "                \"output_folder\": output_folder\n",
        "            },\n",
        "            \"statistics\": {\n",
        "                \"successful_problems\": len([r for r in results if not r['generated_answer'].startswith('ERROR:')]),\n",
        "                \"failed_problems\": len([r for r in results if r['generated_answer'].startswith('ERROR:')]),\n",
        "                \"successful_extractions\": successful_extractions,\n",
        "                \"extraction_success_rate\": f\"{(successful_extractions/len(results)*100):.1f}%\" if results else \"0%\",\n",
        "                \"average_answer_length\": sum(len(r['generated_answer']) for r in results) / len(results) if results else 0,\n",
        "                \"chapters_processed\": list(set(r['chapter_number'] for r in results if r['chapter_number'])),\n",
        "                \"raw_answer_types\": list(set(r['raw_answer_type'] for r in results if r.get('raw_answer_type'))),\n",
        "                \"canonical_answer_types\": list(set(r['canonical_answer_type'] for r in results if r.get('canonical_answer_type')))\n",
        "            }\n",
        "        }\n",
        "        summary_path = os.path.join(output_folder, 'processing_summary.json')\n",
        "        with open(summary_path, 'w', encoding='utf-8') as f:\n",
        "            json.dump(summary_data, f, ensure_ascii=False, indent=2)\n",
        "        print(f\"Processing summary saved to {summary_path}\")\n",
        "        print(f\"Answer extraction success rate: {summary_data['statistics']['extraction_success_rate']}\")\n",
        "\n",
        "# -------------------------\n",
        "# Main (example usage)\n",
        "# -------------------------\n",
        "def main():\n",
        "    # NOTE: update dataset_path and output_base_path to match your environment.\n",
        "    # Ensure your dataset's \"Question\" fields are in Turkish.\n",
        "    dataset_path = \"/kaggle/input/nctb-dataset/Turkish_Final_Corpus.jsonl\"\n",
        "    output_base_path = \"/kaggle/working/\"\n",
        "\n",
        "    # Use the Ollama zero-shot solver (ensure the specified model is available in Ollama)\n",
        "    solver = OllamaZeroShotMathSolver(model_name=\"qwen3:8b\")\n",
        "    processor = DatasetProcessor(solver, failed_folder=os.path.join(output_base_path, \"failed_extractions\"))\n",
        "\n",
        "    # For quick testing, process only first few problems\n",
        "    results, out_folder = processor.process_dataset(\n",
        "        dataset_path,\n",
        "        output_base_path,\n",
        "        start_idx=0,\n",
        "        end_idx=100  # smaller quick test\n",
        "    )\n",
        "    print(\"Done. Results saved to:\", out_folder)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "1bx0veGQfQ4Y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}