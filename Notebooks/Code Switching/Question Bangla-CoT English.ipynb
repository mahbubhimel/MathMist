{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":13119734,"sourceType":"datasetVersion","datasetId":8147915}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-21T19:05:26.297861Z","iopub.execute_input":"2025-09-21T19:05:26.298541Z","iopub.status.idle":"2025-09-21T19:05:26.556243Z","shell.execute_reply.started":"2025-09-21T19:05:26.298488Z","shell.execute_reply":"2025-09-21T19:05:26.555533Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!curl -fsSL https://ollama.com/install.sh | sh","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-21T18:36:36.627937Z","iopub.execute_input":"2025-09-21T18:36:36.628387Z","iopub.status.idle":"2025-09-21T18:37:20.084812Z","shell.execute_reply.started":"2025-09-21T18:36:36.628359Z","shell.execute_reply":"2025-09-21T18:37:20.084124Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import subprocess\nprocess = subprocess.Popen(\"ollama serve\", shell=True) #runs on a different thread\n#Download model\n!pip install ollama","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-21T18:37:20.085710Z","iopub.execute_input":"2025-09-21T18:37:20.085962Z","iopub.status.idle":"2025-09-21T18:37:24.205621Z","shell.execute_reply.started":"2025-09-21T18:37:20.085929Z","shell.execute_reply":"2025-09-21T18:37:24.204919Z"},"scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!ollama pull gpt-oss:20b","metadata":{"trusted":true,"scrolled":true,"execution":{"iopub.status.busy":"2025-09-21T18:37:24.207284Z","iopub.execute_input":"2025-09-21T18:37:24.207583Z","iopub.status.idle":"2025-09-21T18:38:02.154131Z","shell.execute_reply.started":"2025-09-21T18:37:24.207554Z","shell.execute_reply":"2025-09-21T18:38:02.153395Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import json\nimport os\nimport re\nfrom datetime import datetime\nfrom tqdm import tqdm\n\n# Replace Hugging Face with Ollama\ntry:\n    import ollama\nexcept Exception as e:\n    raise ImportError(\"The 'ollama' package is required. Install it and make sure the Ollama daemon is running.\") from e\n\n# -------------------------\n# Answer type normalization\n# -------------------------\n_CANONICAL_TYPES = {\"symbolic\", \"numerical\", \"proof\"}\n\n_ANSWER_TYPE_MAP_SIMPLE = {\n    # Proof variants\n    \"proof\": \"proof\", \"prove\": \"proof\",\n    # Numerical variants\n    \"numerical\": \"numerical\", \"numeric\": \"numerical\", \"number\": \"numerical\", \"calculation\": \"numerical\",\n    # Symbolic variants\n    \"symbolic\": \"symbolic\", \"symbol\": \"symbolic\", \"equation\": \"symbolic\", \"algebraic\": \"symbolic\",\n}\n\n\ndef normalize_answer_type(raw_label: str, question_text: str = \"\", exact_answer: str = \"\") -> str:\n    def _clean_label(lbl: str) -> str:\n        if not lbl:\n            return \"\"\n        s = lbl.strip().lower()\n        s = re.sub(r'[^0-9a-z\\s]', ' ', s)\n        s = re.sub(r'\\s+', ' ', s).strip()\n        return s\n\n    s = _clean_label(raw_label)\n\n    if s in _ANSWER_TYPE_MAP_SIMPLE:\n        return _ANSWER_TYPE_MAP_SIMPLE[s]\n\n    for k, v in _ANSWER_TYPE_MAP_SIMPLE.items():\n        if k in s:\n            return v\n\n    q = (question_text or \"\").lower()\n    a = (exact_answer or \"\").lower()\n\n    if re.search(r'prove|show that|prove that', q) or 'proof' in s:\n        return \"proof\"\n\n    if re.search(r'\\b(log|ln|logarithm)\\b', q) or re.search(r'\\blog\\b', a):\n        if re.search(r'\\d', a):\n            return \"numerical\"\n        return \"symbolic\"\n\n    if re.search(r'set|subset|\\bunion\\b|\\bintersection\\b', q):\n        return \"symbolic\"\n\n    if re.search(r'meter|m\\b|cm|kg|liter|l\\b|unit|units|km|mile', q + \" \" + a):\n        return \"numerical\"\n\n    if re.search(r'equation|solve for|solve|= x|x\\s*=', q) or re.search(r'= x|= \\d', a):\n        return \"symbolic\"\n\n    if re.search(r'trig|sin|cos|tan|geometry|triangle|circle', q):\n        if re.search(r'\\d', a):\n            return \"numerical\"\n        return \"symbolic\"\n\n    if re.search(r'\\d', q) or re.search(r'find the value|compute|calculate|evaluate', q):\n        return \"numerical\"\n\n    if re.search(r'[0-9]|\\\\frac|\\\\sqrt', a):\n        if re.search(r'\\\\frac|\\\\sqrt|\\{|\\\\', a):\n            return \"symbolic\"\n        return \"numerical\"\n\n    return \"symbolic\"\n\n\n# -------------------------\n# Simplified Answer Extractor (merged cleaning improvements)\n# -------------------------\nclass SimplifiedAnswerExtractor:\n    @staticmethod\n    def _clean_answer(answer: str) -> str:\n        if not answer:\n            return \"\"\n        # Start with a trimmed answer and normalize whitespace\n        a = answer.strip()\n        # collapse whitespace\n        a = re.sub(r'\\s+', ' ', a)\n\n        # remove outer $$ if present (multiline)\n        a = re.sub(r'^\\$\\$(.*)\\$\\$$', r'\\1', a, flags=re.DOTALL)\n        # remove surrounding single $ if the whole string is wrapped\n        a = re.sub(r'^\\$(.*)\\$$', r'\\1', a, flags=re.DOTALL)\n\n        # strip standalone leading/trailing $ characters and spaces\n        a = a.strip('$ ')\n\n        # Remove common prefixes (kept after stripping $ to catch cases like \"$Final Answer: ...$\")\n        prefixes_to_remove = [\n            r'Final Answer:\\s*',\n            r'Answer:\\s*',\n            r'The answer is\\s*',\n            r'Therefore,?\\s*',\n            r'Thus,?\\s*',\n            r'Hence,?\\s*',\n            r'So,?\\s*',\n            r'∴\\s*',\n        ]\n        for prefix in prefixes_to_remove:\n            a = re.sub(f'^{prefix}', '', a, flags=re.IGNORECASE)\n\n        # remove various boxed wrappers with optional backslashes and optional surrounding $\n        # e.g. $$\\boxed{...}$$, $\\boxed{...}$, \\boxed{...}\n        a = re.sub(r'\\$?\\s*(?:\\\\){0,3}boxed\\{([^}]*)\\}\\s*\\$?', r'\\1', a, flags=re.DOTALL | re.IGNORECASE)\n        # also ensure plain \\boxed{...} is unwrapped (redundant but safe)\n        a = re.sub(r'\\\\boxed\\{([^}]*)\\}', r'\\1', a)\n\n        # convert common LaTeX to readable forms\n        a = re.sub(r'\\\\frac\\{([^}]*)\\}\\{([^}]*)\\}', r'(\\1)/(\\2)', a)\n        a = re.sub(r'\\\\sqrt\\{([^}]*)\\}', r'√(\\1)', a)\n\n        # remove bold/italic wrappers\n        a = re.sub(r'\\*\\*([^*]+)\\*\\*', r'\\1', a)\n        a = re.sub(r'\\*([^*]+)\\*', r'\\1', a)\n\n        # collapse multiple spaces again (in case replacements introduced them)\n        a = re.sub(r'\\s+', ' ', a).strip()\n\n        # trim trailing punctuation/words\n        a = a.rstrip(' \\t\\n.,;:')\n\n        # remove trailing words like \"proved\" or \"the answer\"\n        a = re.sub(r'\\b(proved|completed|finished|the answer)\\b[.\\s]*$', '', a, flags=re.IGNORECASE).strip()\n\n        return a\n\n    @staticmethod\n    def _is_valid_answer(answer: str) -> bool:\n        if not answer:\n            return False\n        if re.match(r'^[\\W_]+$', answer):\n            return False\n        if not re.search(r'[0-9A-Za-z\\\\]', answer):\n            return False\n        if len(answer) > 1000:\n            return False\n        blacklist = [r'therefore$', r'thus$', r'hence$', r'so$', r'we get$', r'we have$']\n        for b in blacklist:\n            if re.search(b, answer.strip(), flags=re.IGNORECASE):\n                return False\n        return True\n\n    @staticmethod\n    def extract_final_answer_simple(text: str) -> str:\n        \"\"\"\n        Primary method: Extract final answer using the last lines approach,\n        with fallback to pattern-based extraction.\n        \"\"\"\n        if not text:\n            return \"\"\n        \n        # Clean the text and split into lines\n        lines = [line.strip() for line in text.strip().split('\\n') if line.strip()]\n        \n        # Strategy 1: Try last two lines combined\n        if len(lines) >= 2:\n            last_two = ' '.join(lines[-2:])\n            cleaned = SimplifiedAnswerExtractor._clean_answer(last_two)\n            if SimplifiedAnswerExtractor._is_valid_answer(cleaned):\n                return cleaned\n        \n        # Strategy 2: Try last line only\n        if lines:\n            cleaned = SimplifiedAnswerExtractor._clean_answer(lines[-1])\n            if SimplifiedAnswerExtractor._is_valid_answer(cleaned):\n                return cleaned\n        \n        # Strategy 3: Try last 3 lines if we have them (sometimes answers span multiple lines)\n        if len(lines) >= 3:\n            last_three = ' '.join(lines[-3:])\n            cleaned = SimplifiedAnswerExtractor._clean_answer(last_three)\n            if SimplifiedAnswerExtractor._is_valid_answer(cleaned) and len(cleaned) < 500:\n                return cleaned\n        \n        # Strategy 4: Fallback to pattern-based extraction\n        return SimplifiedAnswerExtractor._extract_with_patterns(text)\n\n    @staticmethod\n    def _extract_with_patterns(text: str) -> str:\n        \"\"\"\n        Pattern-based extraction as fallback method.\n        \"\"\"\n        # Check for <final> tags\n        raw_matches = re.findall(r'<final>(.*?)</final>', text, re.DOTALL | re.IGNORECASE)\n        for m in raw_matches:\n            c = SimplifiedAnswerExtractor._clean_answer(m)\n            if SimplifiedAnswerExtractor._is_valid_answer(c):\n                return c\n\n        # Try common answer patterns\n        patterns = [\n            r'\\*\\*Final Answer:\\*\\*\\s*(.+?)(?:\\n|$)',\n            r'Final Answer:\\s*(.+?)(?:\\n|$)',\n            r'Therefore[,:\\s]*(.+?)(?:\\.|$|\\n)',\n            r'Hence[,:\\s]*(.+?)(?:\\.|$|\\n)',\n            r'Thus[,:\\s]*(.+?)(?:\\.|$|\\n)',\n            r'Answer[:\\s]*(.+?)(?:\\n|$)',\n            r'∴\\s*(.+?)(?:\\.|$|\\n)',\n        ]\n        \n        for pat in patterns:\n            matches = re.findall(pat, text, re.MULTILINE | re.DOTALL | re.IGNORECASE)\n            if matches:\n                answer = matches[-1].strip()\n                cleaned = SimplifiedAnswerExtractor._clean_answer(answer)\n                if SimplifiedAnswerExtractor._is_valid_answer(cleaned):\n                    return cleaned\n\n        # Try boxed math expressions\n        boxed_patterns = [\n            r'\\$\\$\\s*(?:\\\\){0,3}boxed\\{(.+?)\\}\\s*\\$\\$',\n            r'\\$\\s*(?:\\\\){0,3}boxed\\{(.+?)\\}\\s*\\$',\n            r'(?:\\\\){0,3}boxed\\{(.+?)\\}',\n        ]\n        \n        for pat in boxed_patterns:\n            m = re.search(pat, text, re.DOTALL | re.IGNORECASE)\n            if m:\n                cand = SimplifiedAnswerExtractor._clean_answer(m.group(1))\n                if SimplifiedAnswerExtractor._is_valid_answer(cand):\n                    return cand\n        \n        return \"\"\n\n    @staticmethod\n    def extract_all_final_answers(generated_solution: str) -> list:\n        \"\"\"\n        Extract multiple final answers using simplified approach.\n        Returns a list (possibly empty) of cleaned answers found inside all <final>...</final> tags.\n        Falls back to the single simplified extraction if no tags are found.\n        \"\"\"\n        if not generated_solution:\n            return []\n\n        # Find all <final>...</final> (non-greedy)\n        raw_matches = re.findall(r'<final>(.*?)</final>', generated_solution, re.DOTALL | re.IGNORECASE)\n        cleaned = []\n        for m in raw_matches:\n            c = SimplifiedAnswerExtractor._clean_answer(m)\n            if SimplifiedAnswerExtractor._is_valid_answer(c):\n                cleaned.append(c)\n\n        if cleaned:\n            return cleaned\n\n        # Fallback: try to extract a single final using the simpler logic\n        simple_answer = SimplifiedAnswerExtractor.extract_final_answer_simple(generated_solution)\n        if simple_answer:\n            return [simple_answer]\n\n        return []\n\n\n# -------------------------\n# Adapter / compatibility layer\n# So existing code that expects methods like extract_final_answer and extract_all_final_answers\n# can use the simplified extractor transparently.\n# -------------------------\nclass AnswerExtractor(SimplifiedAnswerExtractor):\n    @staticmethod\n    def extract_final_answer(text: str) -> str:\n        return SimplifiedAnswerExtractor.extract_final_answer_simple(text)\n\n    @staticmethod\n    def extract_all_final_answers(text: str) -> list:\n        return SimplifiedAnswerExtractor.extract_all_final_answers(text)\n\n\n# -------------------------\n# Ollama-based English Math Solver (no temperature/max_tokens passed)\n# -------------------------\nclass OllamaMathSolver:\n    \"\"\"\n    Chain-of-Thought English math solver using Ollama.\n    Same behavior as before, but prompts and format instructions now require English explanatory text.\n    \"\"\"\n\n    def __init__(self, model_name=\"gpt-oss:20b\", max_tokens=2048):\n        self.model_name = model_name\n        self.client = self._init_client()\n        self.max_tokens = max_tokens\n\n    def _init_client(self):\n        print(f\"Initializing Ollama client for model: {self.model_name}\")\n        return ollama.Client()\n\n    def cleanup(self):\n        if hasattr(self, 'client'):\n            del self.client\n\n    def _get_format_instructions(self, answer_type):\n        t = (answer_type or \"symbolic\").strip().lower()\n        if t not in _CANONICAL_TYPES:\n            t = \"symbolic\"\n\n        base = \"\"\"\nCRITICAL ANSWER FORMATTING REQUIREMENTS:\nYou MUST end your solution with the final answer in the exact format below.\nFirst provide a human-readable final line starting with 'Final Answer:'.\nImmediately after that line, include a machine-readable final tag: <final>...</final>.\nThe content inside <final> should be concise and contain only the final answer (no extra reasoning).\n\"\"\"\n\n        if t == \"proof\":\n            return base + \"\"\"\nFINAL ANSWER FORMAT FOR PROOFS:\nAfter the proof, write exactly:\n\nFinal Answer:\n[Concise English conclusion]\n\nThen the machine-readable tag on its own line:\n\n<final>[Concise English conclusion]</final>\n\"\"\"\n        elif t == \"numerical\":\n            return base + \"\"\"\nFINAL ANSWER FORMAT FOR NUMERICAL RESULTS:\nAfter the calculation, write exactly:\n\nFinal Answer:\n[Numeric result in exact form or decimal]\n\nThen the machine-readable tag on its own line:\n\n<final>[Numeric result]</final>\n\"\"\"\n        else:  # symbolic\n            return base + \"\"\"\nFINAL ANSWER FORMAT FOR SYMBOLIC RESULTS:\nAfter the manipulations, write exactly:\n\nFinal Answer:\n[Final symbolic expression; prefer LaTeX for clarity]\n\nThen the machine-readable tag on its own line:\n\n<final>[LaTeX expression or boxed LaTeX]</final>\n\"\"\"\n\n    def _create_prompt(self, question, answer_type=\"General\"):\n        format_instructions = self._get_format_instructions(answer_type)\n\n        required_order_block = \"\"\"\nREQUIRED OUTPUT ORDER - STRICT:\n1) Problem statement (brief, in English)\n2) Problem understanding (brief, in English)\n3) Mathematical analysis (relevant theorems/formulas, in English)\n4) Step-by-step solution (NUMBERED STEPS: 1., 2., ... - each step explained clearly in English)\n   - The 'Step-by-step solution' section must be present and include at least 3 numbered steps.\n5) Verification (solution check, in English)\n6) Final answer (human-readable, in English) starting with 'Final Answer:'\n7) <final>...</final> (machine-readable tag on its own line)\n\nIMPORTANT: Under no circumstances output 'Final Answer' or the '<final>' tag before steps 4 and 5 are completed. If you output <final> earlier, it will be considered INVALID output.\n\"\"\"\n\n        solution_approach_block = \"\"\"\nSOLUTION APPROACH (WRITE ALL REASONING IN ENGLISH ONLY):\n\n1. PROBLEM UNDERSTANDING:\n   - In English: Carefully read and restate the problem in English.\n2. MATHEMATICAL ANALYSIS:\n   - In English: Break down into subproblems and list relevant theorems/formulae.\n3. STEP-BY-STEP SOLUTION:\n   - In English: Provide numbered steps (1., 2., 3., ...). Show all algebraic/arithmetic work using LaTeX where helpful.\n4. VERIFICATION:\n   - In English: Briefly check correctness.\n\"\"\"\n\n        math_notation_block = r\"\"\"\nMATHEMATICAL NOTATION GUIDELINES:\n- Use $$ for displayed equations and $ for inline expressions.\n- Use LaTeX commands like \\\\frac{num}{den}, \\\\sqrt{...}, \\\\pm, \\\\le, \\\\ge where appropriate.\n\"\"\"\n\n        language_enforcement_block = \"\"\"\nCRITICAL LANGUAGE REQUIREMENTS - STRICTLY MANDATORY:\nYou MUST write your entire response in ENGLISH only, except for mathematical notation.\n- Do NOT write explanatory text in any other language.\n- Use English for all descriptive text. LaTeX mathematical notation is allowed.\n\"\"\"\n\n        prompt = (\n            f\"You are an expert mathematician. All explanatory text MUST be in ENGLISH. Mathematical notation (LaTeX) is allowed.\\n\\n\"\n            f\"MATHEMATICAL PROBLEM:\\n{question}\\n\\n\"\n            f\"{required_order_block}\\n\"\n            f\"{language_enforcement_block}\\n\\n\"\n            f\"{solution_approach_block}\\n\\n\"\n            f\"{math_notation_block}\\n\\n\"\n            f\"{format_instructions}\\n\\n\"\n            \"FINAL REMINDER: Follow the REQUIRED OUTPUT ORDER exactly. First produce the numbered 'Step-by-step solution' section, then Verification, and only after that print 'Final Answer:' followed by the <final> tag on its own line.\\n\\n\"\n            \"Begin your solution now (Start):\\n\"\n        )\n        return prompt\n\n    def _call_chat(self, messages, temperature=0.0, max_tokens=None):\n        kwargs = {\"model\": self.model_name, \"messages\": messages}\n        if max_tokens is None:\n            kwargs[\"max_tokens\"] = self.max_tokens\n        else:\n            kwargs[\"max_tokens\"] = max_tokens\n        kwargs[\"temperature\"] = float(temperature)\n\n        try:\n            resp = self.client.chat(**kwargs)\n            return resp\n        except TypeError:\n            try:\n                resp = self.client.chat(self.model_name, messages=messages, temperature=temperature, max_tokens=kwargs[\"max_tokens\"])\n                return resp\n            except Exception:\n                resp = self.client.chat(model=self.model_name, messages=messages)\n                return resp\n\n    def _extract_content_from_resp(self, resp):\n        content = \"\"\n        if isinstance(resp, dict):\n            if 'message' in resp:\n                m = resp['message']\n                if isinstance(m, dict) and 'content' in m:\n                    content = m['content']\n                else:\n                    content = str(m)\n            elif 'choices' in resp and resp['choices']:\n                choice = resp['choices'][0]\n                if isinstance(choice, dict) and 'message' in choice and isinstance(choice['message'], dict):\n                    content = choice['message'].get('content', '')\n                else:\n                    content = str(choice)\n            else:\n                content = str(resp)\n        else:\n            try:\n                content = resp.message.content\n            except Exception:\n                content = str(resp)\n        if isinstance(content, bytes):\n            content = content.decode('utf-8', errors='ignore')\n        return (content or \"\").strip()\n\n    def _generate_once(self, prompt_text: str, deterministic: bool = False) -> str:\n        final_prompt = prompt_text\n        if deterministic:\n            deterministic_header = (\n                \"DETERMINISTIC MODE: Respond deterministically in ENGLISH ONLY. Output ONLY the concise final answer inside a single <final>...</final> tag. \"\n                \"Do NOT include any other text or explanation. The content inside <final> must be the concise final answer in English.\\n\\n\"\n            )\n            final_prompt = deterministic_header + prompt_text\n\n        messages = [{\"role\": \"user\", \"content\": final_prompt}]\n        resp = self._call_chat(messages, temperature=0.0, max_tokens=self.max_tokens)\n        assistant_content = self._extract_content_from_resp(resp)\n        # print(f\"\\nGenerated assistant content:\\n{assistant_content}\\n\")\n        return assistant_content\n\n    def solve_problem(self, question, answer_type=\"symbolic\", two_pass=True):\n        prompt = self._create_prompt(question, answer_type)\n        raw_output = self._generate_once(prompt, deterministic=False)\n        generated_answer = raw_output\n\n        final_tag_output = \"\"\n        extracted_final_answer = None\n\n        # Use the global SimplifiedAnswerExtractor (removed nested duplicate)\n        extracted_final_answer = SimplifiedAnswerExtractor.extract_final_answer_simple(generated_answer)\n\n        if two_pass and not extracted_final_answer:\n            prompt2 = (\n                \"Below is the previously generated full solution (including reasoning).\\n\\n\"\n                \"Now output ONLY the concise final answer and nothing else, enclosed in a single machine-readable tag <final>...</final>. \"\n                \"Do not include any other text or explanation. The content inside <final> should be the concise final answer in English. \"\n                \"YOU MUST WRITE THE CONTENT INSIDE <final> IN ENGLISH ONLY.\\n\\n\"\n                \"PREVIOUS SOLUTION:\\n\\n\"\n                f\"{generated_answer}\\n\\n\"\n                \"OUTPUT EXAMPLE:\\n\"\n                \"<final>Answer: $\\\\sqrt{10}$ is irrational.</final>\\n\"\n            )\n            try:\n                final_tag_output = self._generate_once(prompt2, deterministic=True)\n                extracted_final_answer = SimplifiedAnswerExtractor.extract_final_answer_simple(final_tag_output)\n            except Exception as e:\n                print(f\"Deterministic second pass failed: {e}\")\n                final_tag_output = final_tag_output or \"\"\n\n        return {\n            \"thinking_content\": \"\",\n            \"generated_answer\": generated_answer,\n            \"final_tag_output\": final_tag_output,\n            \"extracted_final_answer\": extracted_final_answer\n        }\n\n# -------------------------\n# Dataset Processor\n# (uses SimplifiedAnswerExtractor via AnswerExtractor adapter)\n# -------------------------\nclass DatasetProcessor:\n    def __init__(self, solver: OllamaMathSolver, failed_folder=None):\n        self.solver = solver\n        self.extractor = AnswerExtractor  # static adapter\n        self.failed_folder = failed_folder or \"failed_extractions\"\n        os.makedirs(self.failed_folder, exist_ok=True)\n\n    def process_dataset(self, dataset_path, output_base_path, start_idx=0, end_idx=None,\n                        folder_name=None, create_timestamped_folder=True, two_pass=True):\n        dataset = self._load_dataset(dataset_path)\n        if end_idx is None:\n            end_idx = len(dataset)\n\n        output_folder = self._create_output_folder(output_base_path, folder_name, start_idx, end_idx, create_timestamped_folder)\n        results = []\n\n        print(f\"Processing problems {start_idx} to {end_idx-1} ({end_idx-start_idx} total)\")\n        print(f\"Output will be saved in: {output_folder}\")\n\n        for idx in tqdm(range(start_idx, min(end_idx, len(dataset)))):\n            problem = dataset[idx]\n            try:\n                result_entry = self._process_single_problem(idx, problem, two_pass=two_pass)\n                results.append(result_entry)\n                self._print_progress(idx, result_entry)\n                if (idx - start_idx + 1) % 10 == 0:\n                    self._save_intermediate_results(results, output_folder, idx - start_idx + 1)\n            except Exception as e:\n                print(f\"Error processing problem {idx+1}: {str(e)}\")\n                error_entry = self._create_error_entry(idx, problem, str(e))\n                results.append(error_entry)\n\n        final_output_path = self._save_final_results(results, output_folder, start_idx, end_idx)\n        self._create_summary_file(results, output_folder, dataset_path, start_idx, end_idx)\n        return results, output_folder\n\n    def _create_output_folder(self, base_path, folder_name, start_idx, end_idx, add_timestamp):\n        if folder_name is None:\n            folder_name = f\"results_{start_idx}_to_{end_idx-1}\"\n        if add_timestamp:\n            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n            folder_name = f\"{folder_name}_{timestamp}\"\n        output_folder = os.path.join(base_path, folder_name)\n        os.makedirs(output_folder, exist_ok=True)\n        return output_folder\n\n    def _load_dataset(self, dataset_path):\n        dataset = []\n        with open(dataset_path, 'r', encoding='utf-8') as f:\n            for line in f:\n                if line.strip():\n                    dataset.append(json.loads(line))\n        return dataset\n\n    def _process_single_problem(self, idx, problem, two_pass=True):\n        language = problem.get(\"Language\", \"\")\n        chapter_num = problem.get(\"Chapter Number\", \"\")\n        example_num = problem.get(\"Example Number\", \"\")\n        question = problem.get(\"Question\", \"\")\n        exact_answer = problem.get(\"Exact Answer\", \"\")\n        raw_answer_type = problem.get(\"Answer Type\", \"\") or \"\"\n\n        # Normalize/infer canonical answer type: 'symbolic', 'numerical', 'proof'\n        canonical_type = normalize_answer_type(raw_answer_type, question_text=question, exact_answer=exact_answer)\n\n        # If exact_answer strongly indicates numeric, prefer numerical\n        if exact_answer and re.search(r'\\d', str(exact_answer)):\n            # if exact contains LaTeX expressions like \\frac or \\sqrt, keep symbolic\n            if re.search(r'\\\\frac|\\\\sqrt|\\\\boxed', str(exact_answer)):\n                pass\n            else:\n                canonical_type = \"numerical\"\n\n        print(f\"\\nProcessing Problem {idx+1}: Chapter {chapter_num}, Example {example_num}\")\n        print(f\"Raw Answer Type: '{raw_answer_type}'  --> canonical: '{canonical_type}'\")\n\n        # Generate solution (use canonical_type)\n        solution_result = self.solver.solve_problem(question, answer_type=canonical_type, two_pass=two_pass)\n        generated_answer = solution_result.get('generated_answer', '')\n        thinking_content = solution_result.get('thinking_content', '')\n        final_tag_output = solution_result.get('final_tag_output', '')\n\n        # --- Use simplified extractor (supports single final & multi finals via adapter) ---\n        all_finals = AnswerExtractor.extract_all_final_answers(generated_answer)\n        extracted_final_answer = \"\"\n        extracted_final_answers = []\n\n        # If none found in generated_answer, try final_tag_output (second pass raw)\n        if not all_finals and final_tag_output:\n            all_finals = AnswerExtractor.extract_all_final_answers(final_tag_output)\n\n        # If still none, fall back to single-answer extractor (old behavior)\n        if not all_finals:\n            single = AnswerExtractor.extract_final_answer(generated_answer)\n            if single:\n                extracted_final_answer = single\n                extracted_final_answers = [single]\n            else:\n                # try whole combined text (thinking + generated + final_tag)\n                combined = \"\\n\".join([thinking_content or \"\", generated_answer or \"\", final_tag_output or \"\"])\n                single = AnswerExtractor.extract_final_answer(combined)\n                if single:\n                    extracted_final_answer = single\n                    extracted_final_answers = [single]\n                else:\n                    extracted_final_answer = \"\"\n                    extracted_final_answers = []\n        else:\n            # we have one or more finals\n            extracted_final_answers = all_finals\n            if len(all_finals) == 1:\n                extracted_final_answer = all_finals[0]\n            else:\n                # store a machine-readable concatenation: JSON array string\n                try:\n                    extracted_final_answer = json.dumps(all_finals, ensure_ascii=False)\n                except Exception:\n                    extracted_final_answer = \" ||| \".join(all_finals)\n\n        # If still empty, save a failed extraction example for inspection\n        if not extracted_final_answer:\n            fname = f\"failed_{idx}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n            fpath = os.path.join(self.failed_folder, fname)\n            with open(fpath, 'w', encoding='utf-8') as f:\n                json.dump({\n                    \"index\": idx,\n                    \"question\": question,\n                    \"generated_answer\": generated_answer,\n                    \"thinking_content\": thinking_content,\n                    \"final_tag_output\": final_tag_output,\n                    \"exact_answer\": exact_answer,\n                    \"canonical_type\": canonical_type,\n                    \"extracted_final_answer\": extracted_final_answer,\n                    \"extracted_final_answers\": extracted_final_answers\n                }, f, ensure_ascii=False, indent=2)\n            print(f\"Saved failed extraction example to {fpath}\")\n\n        result_entry = {\n            \"problem_index\": idx,\n            \"language\": language,\n            \"chapter_number\": chapter_num,\n            \"example_number\": example_num,\n            \"question\": question,\n            \"generated_answer\": generated_answer,\n            \"thinking_content\": thinking_content,\n            \"final_tag_output\": final_tag_output,\n            \"extracted_final_answer\": extracted_final_answer,       # string (or JSON array string)\n            \"extracted_final_answers\": extracted_final_answers,     # list (empty / single / many)\n            \"exact_answer\": exact_answer,\n            \"raw_answer_type\": raw_answer_type,\n            \"canonical_answer_type\": canonical_type,\n            \"evaluation_method\": problem.get(\"Evaluation Method\", \"\")\n        }\n        return result_entry\n\n    def _create_error_entry(self, idx, problem, error_msg):\n        return {\n            \"problem_index\": idx,\n            \"language\": problem.get(\"Language\", \"\"),\n            \"chapter_number\": problem.get(\"Chapter Number\", \"\"),\n            \"example_number\": problem.get(\"Example Number\", \"\"),\n            \"question\": problem.get(\"Question\", \"\"),\n            \"generated_answer\": f\"ERROR: {error_msg}\",\n            \"thinking_content\": \"\",\n            \"final_tag_output\": \"\",\n            \"extracted_final_answer\": \"\",\n            \"extracted_final_answers\": [],\n            \"exact_answer\": problem.get(\"Exact Answer\", \"\"),\n            \"raw_answer_type\": problem.get(\"Answer Type\", \"\"),\n            \"canonical_answer_type\": \"\",\n            \"evaluation_method\": problem.get(\"Evaluation Method\", \"\")\n        }\n\n    def _print_progress(self, idx, result_entry):\n        print(f\"Generated answer length: {len(result_entry['generated_answer']) if result_entry['generated_answer'] else 0}\")\n        print(f\"Extracted final answer: '{result_entry['extracted_final_answer']}'\")\n        print(f\"Extracted final answers (list): {result_entry.get('extracted_final_answers', [])}\")\n        print(f\"Expected answer: '{result_entry['exact_answer']}'\")\n\n    def _save_intermediate_results(self, results, output_folder, count):\n        temp_filename = f'intermediate_results_{count}.json'\n        temp_output_path = os.path.join(output_folder, temp_filename)\n        with open(temp_output_path, 'w', encoding='utf-8') as f:\n            json.dump(results, f, ensure_ascii=False, indent=2)\n        print(f\"Saved intermediate results to {temp_output_path}\")\n\n    def _save_final_results(self, results, output_folder, start_idx, end_idx):\n        final_filename = f'final_results_{start_idx}_to_{end_idx-1}.json'\n        final_output_path = os.path.join(output_folder, final_filename)\n        with open(final_output_path, 'w', encoding='utf-8') as f:\n            json.dump(results, f, ensure_ascii=False, indent=2)\n        print(f\"\\nProcessing complete. Results saved to {final_output_path}\")\n        print(f\"Total problems processed: {len(results)}\")\n        return final_output_path\n\n    def _create_summary_file(self, results, output_folder, dataset_path, start_idx, end_idx):\n        successful_extractions = len([r for r in results if r.get('extracted_final_answer', '').strip()])\n        summary_data = {\n            \"processing_info\": {\n                \"dataset_path\": dataset_path,\n                \"start_index\": start_idx,\n                \"end_index\": end_idx - 1,\n                \"total_processed\": len(results),\n                \"processing_timestamp\": datetime.now().isoformat(),\n                \"output_folder\": output_folder\n            },\n            \"statistics\": {\n                \"successful_problems\": len([r for r in results if not r['generated_answer'].startswith('ERROR:')]),\n                \"failed_problems\": len([r for r in results if r['generated_answer'].startswith('ERROR:')]),\n                \"successful_extractions\": successful_extractions,\n                \"extraction_success_rate\": f\"{(successful_extractions/len(results)*100):.1f}%\" if results else \"0%\",\n                \"average_answer_length\": sum(len(r['generated_answer']) for r in results) / len(results) if results else 0,\n                \"chapters_processed\": list(set(r['chapter_number'] for r in results if r['chapter_number'])),\n                \"raw_answer_types\": list(set(r['raw_answer_type'] for r in results if r.get('raw_answer_type'))),\n                \"canonical_answer_types\": list(set(r['canonical_answer_type'] for r in results if r.get('canonical_answer_type')))\n            }\n        }\n        summary_path = os.path.join(output_folder, 'processing_summary.json')\n        with open(summary_path, 'w', encoding='utf-8') as f:\n            json.dump(summary_data, f, ensure_ascii=False, indent=2)\n        print(f\"Processing summary saved to {summary_path}\")\n        print(f\"Answer extraction success rate: {summary_data['statistics']['extraction_success_rate']}\")\n\n\n# -------------------------\n# Main (example usage)\n# -------------------------\ndef main():\n    # NOTE: update dataset_path and output_base_path to match your environment\n    dataset_path = \"/kaggle/input/Bangla_Final_Corpus.jsonl\"  # source format unchanged; questions are English\n    output_base_path = \"/kaggle/working/\"\n\n    # Use OllamaMathSolver (model reference must match a model available locally via Ollama)\n    solver = OllamaMathSolver(model_name=\"gpt-oss:20b\")\n    processor = DatasetProcessor(solver, failed_folder=os.path.join(output_base_path, \"failed_extractions\"))\n\n    # For quick testing, process only first few problems\n    results, out_folder = processor.process_dataset(\n        dataset_path,\n        output_base_path,\n        start_idx=720,\n        end_idx=1445,\n        two_pass=True\n    )\n    print(\"Done. Results saved to:\", out_folder)\n\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-21T18:38:02.155275Z","iopub.execute_input":"2025-09-21T18:38:02.155519Z","iopub.status.idle":"2025-09-21T18:43:36.156143Z","shell.execute_reply.started":"2025-09-21T18:38:02.155496Z","shell.execute_reply":"2025-09-21T18:43:36.155437Z"},"scrolled":true},"outputs":[],"execution_count":null}]}